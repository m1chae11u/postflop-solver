December 2nd, 2024

Mastering Board Games by External and
Internal Planning with Language Models
John Schultz*,1 , Jakub Adamek*,1 , Matej Jusupâ€ ,3 , Marc Lanctot1 , Michael Kaisers1 , Sarah Perrin1 , Daniel
Hennes1 , Jeremy Shar1 , Cannada Lewis2 , Anian Ruoss1 , Tom Zahavy1 , Petar VeliÄkoviÄ‡1 , Laurel Prince1 ,
Satinder Singh1 , Eric Malmi**,1 and Nenad TomaÅ¡ev**,1
* Equal contributions, ** Equal senior authorship, â€  Research conducted during an internship at Google, 1 Google DeepMind, 2 Google,

arXiv:2412.12119v1 [cs.AI] 2 Dec 2024

3 ETH ZÃ¼rich

While large language models perform well on a range of complex tasks (e.g., text generation, question
answering, summarization), robust multi-step planning and reasoning remains a considerable challenge
for them. In this paper we show that search-based planning can significantly improve LLMsâ€™ playing
strength across several board games (Chess, Fischer Random / Chess960, Connect Four, and Hex). We
introduce, compare and contrast two major approaches: In external search, the model guides Monte Carlo
Tree Search (MCTS) rollouts and evaluations without calls to an external engine, and in internal search,
the model directly generates in-context a linearized tree of potential futures and a resulting final choice.
Both build on a language model pre-trained on relevant domain knowledge, capturing the transition and
value functions across these games. We find that our pre-training method minimizes hallucinations, as
our model is highly accurate regarding state prediction and legal moves. Additionally, both internal and
external search indeed improve win-rates against state-of-the-art bots, even reaching Grandmaster-level
performance in chess while operating on a similar move count search budget per decision as human
Grandmasters. The way we combine search with domain knowledge is not specific to board games,
suggesting direct extensions into more general language model inference and training techniques.

Keywords: Search, planning, language models, games, chess.

Introduction
With the recent advances in large language models (LLMs) and their widespread adoption across
diverse application domains and use cases, their
capabilities are under scrutiny. While LLMs perform fluently on text generation, language understanding and translation, they are prone to
hallucinations and reasoning errors, especially in
complex contexts (Chang et al., 2024; Hadi et al.,
2023). Hence, special attention has been given to
the development of planning and reasoning capabilities in LLMs (Minaee et al., 2024), and/or to
the agentic systems built on top of LLM subcomponents (Grosnit et al., 2024; Wang et al., 2024e).
This reflects both the increasing complexity of AI
application domains, as well as a recognition of
reasoning as a key capability on the path towards
more general artificial intelligence (Huang and
Chang, 2022). In terms of Kahnemanâ€™s cognitive
theory of two systems (Kahneman, 2011), prior

Corresponding author(s): emalmi@google.com, nenadt@google.com
Â© 2024 Google DeepMind. All rights reserved

work primarily improved associative System 1 inference in language models, whereas planning
and reasoning now focuses on improving the more
deliberate System 2 thinking (Plaat et al., 2024).
Reasoning in language models encompasses diverse techniques with the aim to improve LLM performance on reasoning benchmarks. Approaches
typically fall into one of two distinct categories: In
internal planning the LLM develops a plan in context, like Chain-of-Thought prompting (Wei et al.,
2022), by autoregressively considering possible
steps towards the goal and their consequences.
By contrast, external planning uses the LLM to
generate steps in a neurosymbolic system, such
as in Tree of Thought (Yao et al., 2024), where
an outer loop performs explicit search over possible sequences of steps. This paper presents how
language models can be trained for internal and
external planning to improve reasoning in sequential decision-making, using board games as an
experimental domain.

Mastering Board Games by External and Internal Planning with Language Models

Board games have historically played an important role in the development of automated
decision-making, with Torresâ€™ automaton El Ajedrecista playing three-piece chess end-games
before the advent of digital computation (tor,
November 1915). Games provide diverse reasoning challenges about both environment dynamics
and opponent strategies, and thus have gained
significant attention in pushing the boundaries
of LLM reasoning capabilities (Costarelli et al.,
2024; Duan et al., 2024; Hu et al., 2024b). LLMs
have incidentally been struggling with reliably
playing common board games, like chess or even
tic-tac-toe (Topsakal and Harper, 2024). This
may seem somewhat surprising, considering how
much headway has been made in other areas.
However, as games astutely expose the inability of
LLMs to consistently reason over possible futures
with world models, they make a great testbed
for planning and reasoning. Making progress in
game-playing could inform how to best instill this
ability in LLMs going forward. We present several
contributions towards this aspirational goal.
First, we have pre-trained a Transformer model,
the multi action-value (MAV) model, capable of
playing several board games (Chess, Fischer Random / Chess960, Connect Four, Hex) at a strong
level. Our evaluation shows that this model is capable of reliably tracking the board state throughout games, and makes (good) legal moves. We
observe nearly no hallucinations (cf. Table 3) with
this model for both in and out-of-distribution positions that are fairly distinct from anything the
model would have seen during training. Our MAV
model builds on top of prior work (Ruoss et al.,
2024) where the ability to train strong text-based
Transformer models in chess without search was
first demonstrated, though those methods would
still require an external tool for providing the list
of legal moves, querying for their values individually. Our MAV model generates all the values and
transitions in a single query, and proposes the list
of candidate moves itself without any external
tool calls. Second, we demonstrate that it is possible to utilize the proposed MAV model within
an external MCTS controller, as a value/implicit
policy and transition function. The MCTS-MAV
agent shows substantial improvements over the
base MAV model in playing strength, showcas-

ing the promise of MCTS as an external search
mechanism in a more general context. Our asynchronous MCTS implementation has been designed to reduce the number of queries to the
model, and we show a comprehensive evaluation
of different variants and scoring methods, in the
low-simulation regime (âˆ¼100 to âˆ¼1k simulations
compared to AlphaZero which used âˆ¼10k simulations or engines that use up to millions). Third,
we generalise the approach recently proposed in
Stream of Search (SoS) (Gandhi et al., 2024b)
and show that it is possible to distill the search
procedure directly into the LLM. The resulting
internal search MAV model has the ability to
infer the distilled search procedure in chess. Our
evaluation shows that this method is also capable
of delivering consistent improvements in playing
strength over the MAV baseline with the given
search/token budget. By training on tokens representing various search actions (such as expand,
evaluate, summarize) and game actions (moving
the state ahead), we show a significant improvement when comparing against training on game
actions only, elevating the modelâ€™s skill from imitating search to executing it. We summarize below
our main contributions:
Contribution 1: MAV model. We pre-train
a Transformer model, the multi action-value
model (MAV), capable of playing several
board games (Chess, Chess960, Connect
Four, Hex) at a strong level.
Contribution 2: External search. We
use the MAV model within an external
MCTS controller, as a value/implicit policy and transition function. The agent
reaches Grandmaster level with the number
of moves considered per decision comparable to human players.
Contribution 3: Internal search. We distill directly the search procedure into the
LLM. The resulting agent is able to infer the
search procedure and its performance scales
with the given search budget.

2

Mastering Board Games by External and Internal Planning with Language Models

Multi-action-value model
The first contribution of this work is to introduce
the multi-action-value (MAV) model, a Transformer model pre-trained exclusively on textual
game data that functions simultaneously as a: (ğ‘–)
world model, (ğ‘–ğ‘–) value function, and (ğ‘–ğ‘–ğ‘–) policy
function for multiple perfect-information board
games. Acting as world model further requires
the following capabilities: (ğ‘–) state-tracking (determining the new state of the game after a move
has been played in the previous state), (ğ‘–ğ‘–) legal
move prediction, (ğ‘–ğ‘–ğ‘–) terminal state detection. To
achieve this, the MAV model is trained on examples following a flexible format which provides
a strong learning signal and allows for a qualitycompute tradeoff at inference time while remaining in-distribution. An example illustrating the
MAV format can be found in Figure 1.

Command specification. The MAV model input starts with a configuration header containing a series of commands that inform how
to interpret the inputs that follow, and what
outputs are expected. In its simplest form,
this looks like <mav game=$game> %state
%top_1 </mav>, where %state and %top_1
are commands. This tells the model what game
is being played, that the next line ([%state
$state_string]) should be interpreted as the
current state of the game, and that it is responsible for predicting the output top_1 (i.e. the
single best move and its win probability).

State representation. Each game uses a different textual format to represent its state. These
representations are designed such that each
square of the board is tokenized separately, and
squares maintain constant relative positions in
token space. This makes it easier for the model to
navigate and manipulate the board. This is the
format used for the %state and %prev_state
commands. For convenience we also support
the %FEN and %prev_FEN commands for chess,
which instead use the standardized FEN representation. We train our models to be able to handle
%state and %FEN commands interchangeably,
or jointly as in Figure 1. For simplicity, in the

rest of this section we will only use the %state
command.
State tracking. State tracking is achieved
in the MAV model by using the series of
commands
%prev_state %prev_action
%state. These instruct the model that the
following input lines will be [%prev_state
$state_string] containing the previous state,
and [%prev_action $action_string] with
the move played in that state. The modelâ€™s task
is to act as a transition function and output
[%state $new_state_string], describing
the state after the transition.
In addition to predicting the state after the previous action, MAV can also output the state after
the action it decides to take (see %best_action
below).
Starting state. When state tracking is used, the
post-transition state is used as the starting state
for subsequent commands (e.g. %top_1 is evaluated in this state). Otherwise the starting state is
directly specified using the %state command.
Value function. The %top_k command instructs the model to output a list of ğ‘˜ legal moves
(or all legal moves if there are fewer than ğ‘˜). The
ability to configure ğ‘˜ is useful because it allows
for varying the amount of inference-time computation the MAV model performs. However, it is
also possible to specify ğ‘˜ = â€œğ‘ğ‘™ğ‘™ â€ in order for the
model to produce all legal moves.
Directly following each legal move the model
outputs its action value. This corresponds to the
predicted win probability for the player in the
current state if this move is taken. For chess, stateaction values are represented similarly to Ruoss
et al. (2024): Stockfish centipawn evaluations are
mapped to win probabilities using the formula


2
Win % = 50 + 50
âˆ’1
1 + ğ‘’âˆ’0.00368208Â·centipawns
obtained from https://lichess.org/page/
accuracy. Win probabilities are then mapped
to discrete non-overlapping buckets, making the

3

Mastering Board Games by External and Internal Planning with Language Models

Game name
(one of)
chess
chess960
hex
connect_four

Input spec
(one of)
current state, or
previous state +
action

Output spec
(all of)
current state (if input was previous state),
either top-k or all moves+values,
best move and state afterwards

prompt with input and output spec
<mav game=chess> %prev_FEN %prev_action %FEN %state %top_5 %best_action %FEN </mav>
[%prev_FEN r1b1nr2/pp1np1bk/2pp1pp1/q3P3/3P1P2/2NQB3/PPP1B1PP/R4RK1 w - - 0 13]
inputs in order from spec
[%prev_action e5e6]
[%FEN r1b1nr2/pp1np1bk/2ppPpp1/q7/3P1P2/2NQB3/PPP1B1PP/R4RK1 b - - 0 13]
[%state b || R . . . . R K . P P P . B . P P . . N Q B . . . . . . P . P . . q . . . . . . . . . p p P p p . p p . n p . b k r . b . n r . . |00000000013||]
[%top_5 d7b6:<ctrl28> f6f5:<ctrl33> d7c5:<ctrl28> f8h8:<ctrl29> a5f5:<ctrl29>]
outputs in order from spec
[%best_action f6f5]
[%FEN r1b1nr2/pp1np1bk/2ppP1p1/q4p2/3P1P2/2NQB3/PPP1B1PP/R4RK1 w - - 0 14]

Figure 1 | A complete example used for training the multi-action-value models. Robert J. Fischer
(2690) â€“ Mijo UdovÄiÄ‡ (2460), Bled 1961, 1/2â€“1/2.
value prediction problem a classification task
rather than a regression task. This has proven
to be beneficial in other works (Farebrother et al.,
2024). We use 64 buckets, each represented by a
different special token (e.g. <ctrl28> for bucket
28). Figure 2 shows two win probability distributions predicted by the MAV model. Connect Four
and Hex use game engines Fhourstones (Tromp)
and neurobenzene (Gao and Pawlewicz), respectively, to obtain state-action values, which are
similarly mapped to the same 64 bucket tokens.
When producing training examples, we randomly
vary ğ‘˜ and include both examples where ğ‘˜ is less
than the number of legal moves, and where ğ‘˜
is greater (this teaches the model to not hallucinate additional options). In the former case,
we teach the model to output the ğ‘˜ moves that
have the highest win probabilities as predicted by
the game engine. We make the deliberate choice
to randomize the order of the moves. This accomplishes two purposes: (ğ‘–) it encourages the
model to treat the moves independently, rather
than relying on a specific order, and (ğ‘–ğ‘–) it helps
to prevent hallucinations. If the moves were e.g.
sorted lexicographically from ğ‘1ğ‘2 to â„8â„7, then
(ğ‘–) if the model skips a legal move ğ‘1ğ‘4 and emits
ğ‘1ğ‘5, there is no hope that it will correct its mistake, and (ğ‘–ğ‘–) the model might learn to systematically lean on evaluations of previous moves
when considering â„8â„7, potentially causing the
model to play better/worse on the left side of the
board. Using randomised ordering of moves in
the training data, the model is steered towards
an approximate permutation symmetry (Bronstein
et al., 2021).

8

rZ0Z0skZ
opZ0lpop
0ZbZpZ0Z
Z0ZpO0Z0
0S0Z0ZQZ
O0ZBZ0Z0
0ZPZ0OPO
Z0ZRZ0J0

Bh7
Re1

0.25

7

6

5

4

0.20
0.15
0.10

3

2

1

a

b

c

d

e

f

g

h

0.05
0.00
0.0

0.2

0.4 0.6 0.8
Win probability

1.0

Figure 2 | For a safe positional move, such as Re1
MAV assigns little uncertainty and gives a win
probability of 40-45% since white is a pawn down.
In contrast, the bishop sacrifice Bxh7+ (best move
according to Stockfish) is a riskier attacking move
and thus has substantial probability mass around
low, equal, and high win probabilities.

Value Definition: Scoring Methods. As mentioned above, there are 64 buckets used to encode
the range of a value, each represented by a unique
token. As we reserve these 64 tokens exclusively
for encoding values, the actual state-action value
for a move is derived from its token distribution.
Hence, it can also be viewed as a decoding strategy for the values. We refer to different ways to
represent values as scoring methods. We experiment with two scoring methods: max scoring,
which corresponds to greedy decoding, uses the
mode of modelâ€™s distribution over the 64 buckets
to represent the value, and mean scoring, which
takes into account the whole distribution defining
the value as an expectation over buckets.
Mean scoring often enables us to differentiate

4

Mastering Board Games by External and Internal Planning with Language Models

between multiple candidate actions with equal
modes. For example, there are many positions
where multiple moves will likely result in a draw
but certain moves retain higher winning chances
than others. In such cases, max scoring would
not be able to differentiate between these moves,
while mean scoring would pick the move with the
highest expected winning chances.
The mean scoring method was also used in Ruoss et al. (2024); the main difference here is that
MAV does not take the move as an input to be
scored, but rather decodes the values for all moves
in a single output generation.
Legal moves and terminal states. Itâ€™s worth
noting that %top_k also handles functionality
specifically related to MAV being a world model.
First, the model does not need to be provided
with a list of legal moves, and instead predicts
the list by itself. Second, if the state is terminal,
the %top_k output specifies the game outcome
(e.g. [%top_1 invalid : "1-0"] when the
first player has won).
Best action prediction. In positions where the
acting player has a decisive advantage, multiple
moves may be assigned a 100% win probability,
and therefore all map to the same bucket. Some of
these moves may not directly lead to finishing the
game by checkmate, causing the model to play
aimlessly in winning positions. This problem was
encountered in Ruoss et al. (2024), which they
resolved by using Stockfish to break ties when
all top 5 moves lie above a win probability of
99%. We seek to completely eliminate reliance
on game engines at inference time. To accomplish this, we introduce the %best_action command, which must follow the %top_k command.
If present, the model outputs [%best_action
$move], where $move corresponds to Stockfishâ€™s chosen action in the position. Essentially,
the model learns the tie-breaking procedure described above.
Novelty. To summarize how the MAV model
differs from previous Transformer-based chess
engines, the MAV model makes four key improve-

ments over the existing state-of-the-art (Farebrother et al., 2024; Monroe and Leela Chess
Zero Team, 2024; Ruoss et al., 2024)
â€¢ First, it performs world modeling, policy and
action-value computation together in one
model.
â€¢ Second, it is trained to output the best action
at the end of action-value modeling. This
enables the model to finish games even in
the presence of multiple actions with equal
values but with some of the actions not bringing the game closer to a finish. Importantly,
these first two improvements enable the MAV
model to play complete games without relying on an external game engine for legal
moves or for finishing the game.
â€¢ Third, all of the above steps can be done in
a single model call without having to evaluate every action separatelyâ€”an important
feature that guided the design of the MAV
format to reduce the cost and infrastructural
complexity of inference.
â€¢ Fourth, the amount of compute performed
by the model at inference time can be varied. This enables us to achieve higher quality
at the cost of higher latency when performing both internal and external search, where
the performance increases as we scale the
planning.

Datasets. We curate a dataset of diverse, relevant positions in four games: Chess, FisherRandom Chess, Connect Four, and Hex. The statistics and sources for each of these datasets are
shown in Table 1. Each position is used to produce
a single training example, randomly varying (ğ‘–)
the ğ‘˜ action values in %top_k, (ğ‘–ğ‘–) the presence of
the initial or final state tracking commands, (ğ‘–ğ‘–ğ‘–)
the use and order of %state or %FEN representations in chess. Further details on the datasets
are provided in the Appendix.

Models. We train two randomly initialized
decoder-only Transformer models using the Gemini architecture (Gemini Team et al., 2024), called
MAV and MAVâ€“small, with 2.7 billion and 1 bil-

5

Mastering Board Games by External and Internal Planning with Language Models

Game
Chess
Chess960
Connect Four
Hex

Positions
3.1B
1.2B
21.8M
125.6M

Action values
54.3B
20.9B
110.5M
537.0M

Table 1 | Multi-action-value (MAV) model training
data statistics.
lion parameters respectively1 . They were trained
on 1.9 and 1.2 epochs of the dataset described
in Table 1. Except for the max scoring result for
MAVâ€“small in table 2, all other experiments and
results use the 2.7 billion MAVmodel. In order to
efficiently use our modelsâ€™ parameters, the input
part of each training example is masked out during loss computation. This means our models do
not waste capacity on learning to generate game
positions.

External Search
External search employs the MAV model to generate planning steps, and applies a search algorithm
to direct and optimise over sequences of planning
steps. In this paper, we evaluate planning on top
of the previously discussed MAV model, using
MCTS as the search procedure.
Algorithm 1 E x t e r nal - M C T S( ğ‘ 0 )
1: Input: Initial state ğ‘ 0 , active player ğ‘–, top ğ‘˜

values, num. simulations ğ‘€
2: Output: Recommended action ğ‘âˆ—
3: ğ’‚0ğ¿ , ğ‘¸ ( ğ‘– ) ( ğ‘ 0 , ğ’‚0ğ¿ ) = M AV ( ğ‘ 0 )
4: Compute prior ğ‘· ( ğ‘ 0 , ğ’‚0ğ¿ ; ğ‘˜) according to Eq. 1.
5: Initialize root node:
N0 ( ğ‘–) â† ğ‘–
N0 ( ğ‘ ) â† ğ‘ 0
N0 ( ğ’‚ğ¿ ) â† ğ’‚0ğ¿
6: Expand (N0 , ğ‘· )
7: for ğ‘š = 1, . . . , ğ‘€ do
8:
Simul at ion(N0 , M AV , ğ‘˜)
9: end for
10: ğ‘âˆ— â† Final Mov e Se l ec t ion(N0 )
11: return ğ‘âˆ—
External search is based on an AlphaZero-style
1 Note that in practice MAV and MAVâ€“small donâ€™t utilize

many natural-language specific parameters.

MCTS (Silver et al., 2017). There are two key ingredients: a prior function which returns a probability distribution over actions at each state, and
a value function returning a numerical value indicating value of a state or state-action pair, both
extracted from the MAV output. External search
is an adaptation of MCTS; in its most basic form,
as in AlphaZero, MCTS relies on an explicit world
model, querying a game engine (e.g., a chess implementation in OpenSpiel (Lanctot et al., 2019))
to provide legal actions, state transitions and terminal state signals. Inspired by MuZero (Schrittwieser et al., 2020), in a subsection below we
describe how we remove this dependency on the
game engine and instead use only the model to
track states, transitions, and provide legal actions
and game outcome during planning.
The external search algorithm guided by a
learned world model is summarized in Algorithm 1, with subroutines and details contained
in the Appendix. A search is started at an initial game state ğ‘ 0 . First, the legal actions ğ’‚0ğ¿ and
associated state-action values ğ‘¸ ( ğ‘– ) ( ğ‘ 0 , ğ’‚0ğ¿ ) from active playerâ€™s ğ‘– perspective are obtained from the
MAV model. The prior function is an ğœ€-greedy
policy, derived entirely from state-action values
comprised of a greedy softmax over the top ğ‘˜
values, mixed with a uniform distribution over
all actions to encourage exploration. Specifically,
let ğ’‚ğ‘”,ğ‘˜ âŠ† ğ’‚ğ¿ be the subset of legal actions ğ’‚ğ¿
whose values are among the top ğ‘˜-ranked values,
or equal to ğ’‚ğ¿ if | ğ’‚ğ¿ | â‰¤ ğ‘˜. Define the probability
of action ğ‘ in state ğ‘  under the greedy policy to
be

(
ğœ‹

ğ‘”,ğ‘˜

(ğ‘–)

( ğ‘ , ğ‘; ğ‘¸ ) =

Ã

0

exp 1ğœ ğ‘„ ( ğ‘– ) ( ğ‘ ,ğ‘ )
exp 1ğœ ğ‘„ ( ğ‘– ) ( ğ‘ ,ğ‘â€² )
ğ‘â€² âˆˆ ğ’‚ğ‘”,ğ‘˜

if ğ‘ âˆˆ ğ’‚ğ‘”,ğ‘˜ ;
otherwise.

where ğœ is a temperature parameter. In practice, we dynamically adapt the temperature
(VeliÄkoviÄ‡ et al., 2024) as a function of the number of moves played and transform state-action
values to win probabilities before computing softmax.
The probability of the uniform policy is
ğœ‹ ( ğ‘ , ğ‘; ğ’‚ ğ¿ ) = | ğ’‚1ğ¿ | . The prior probability of takğ‘¢

6

Mastering Board Games by External and Internal Planning with Language Models

Root node of search

ing action ğ‘ in state ğ‘  is then

8

rZbZ0jns
opZpo0Z0
0ZnZ0Zpo
Z0ZNZpZ0
0Z0Z0O0A
Z0Z0LNZ0
PZPZ0JPO
l0Z0ZBZR
7

ğ‘ƒ ( ğ‘ , ğ‘; ğ‘¸ ( ğ‘– ) , ğ’‚ ğ¿ , ğ‘˜) = (1 âˆ’ ğœ€) ğœ‹ğ‘”,ğ‘˜ ( ğ‘ , ğ‘; ğ‘¸ ( ğ‘– ) )

+ ğœ€ğœ‹ğ‘¢ ( ğ‘ , ğ‘; ğ’‚ğ¿ ) .

6

(1)

5

4

3

The root node N0 is then initialized with the
active player, string description of a state corresponding to the node, and legal actions (respectively: N0 ( ğ‘–), N0 ( ğ‘ ), N0 ( ğ’‚ğ¿ )). The node is then
expanded so that a child node is added for each
action and a prior probability attached to the action leading to the child. Then simulations are
run (Algorithm 3 in the Appendix): each simulation starts at the root node, actions and children
nodes are selected according to PUCT until a leaf
node is expanding and evaluated, and values are
backpropagated through the nodes that the simulation visited. After ğ¾ such simulations, a final
move ğ‘âˆ— is selected. Besides the integration of the
prior, value, and transition functions through the
MAV model, and the asynchronous simulations
described below, this most basic form of external search is based on a fairly common implementation of AlphaZero-style MCTS using PUCT
for action selection (Silver et al., 2017) adapted
from the generic one in OpenSpiel (Lanctot et al.,
2019).
External Search with State-Tracking MAV
Classical MCTS relies on several components of a
game engine to simulate the game. MAV replaces
these components by combining state tracking, legal action prediction, action value prediction, and
terminal state detection in a single model. This
allows us to remove the dependency on a game
engine, which results in a few benefits. First,
we use the board games to showcase that MCTS
achieves astonishing performance even without
access to an explicit world model, which is the
case for many interesting real-world problems.
Second, it is a step closer towards the internal
search with LLMs.
We adapt MCTS (see Algorithm 1) to use the
learned MAV model to predict the state transition from the string description of a parent node
Nğ‘¡ âˆ’1 ( ğ‘ ) and action ğ‘ğ‘¡ âˆ’1 to the child node Nğ‘¡ , as
shown in Figure 3. We use the obtained information to store a (predicted) string description ğ‘ ğ‘¡

2

1

a

b

c

d

Qa3

e

f

g

h

Bb5

qÃ—a2

Nc7

qÃ—h1

s
Qc3

MAV(s, a)
a = BXc6

BXc6

1. New state, sâ€²
2. Check if sâ€² is terminal

sâ€²

3. Legal moves a1 , . . . , an
4. Action values Q(b) (sâ€² , ai )

a1 = rh7

an = qa1

a2 = pg5
Â·Â·Â·

Figure 3 | State-tracking MCTS with a learned
world model.
of the child node, which is then expanded with
legal actions ğ’‚ğ‘¡ğ¿ and their associated state-action
values ğ‘¸ ( ğ‘– ) ( ğ‘ ğ‘¡ , ğ’‚ğ‘¡ğ¿ ) used to compute a prior according to Equation (1) and the childâ€™s value
as the maximum over all state-action values,
i.e., maxğ‘ğ‘¡ âˆˆ ğ’‚ğ‘¡ğ¿ ğ‘„ ( ğ‘– ) ( ğ‘ ğ‘¡ , ğ‘ğ‘¡ ).
The MAV model may hallucinate and return
responses that are improperly-formatted. To address this, for each game, a parser function is responsible for translating the output into the next
state, legal actions, and their values. If the parsing fails â€“ which can only happen if a response
violates a predefined format â€“ then the evaluation at the node is marked as a hallucination and
a special value of âˆ’âˆ is assigned to the node to
avoid future consideration. This procedure makes
state-tracking MCTS robust to hallucinations, by
explicitly avoiding states where the hallucination
occurred.
Performance Considerations and Async MCTS
Since modern large transformer models can take
orders of magnitude longer for a single inference

7

Mastering Board Games by External and Internal Planning with Language Models

Batch size, b:
1. Run b simulations
2. Queue b new evaluations
3. Wait/process b results

s1

Virtual Count Value ğ‘›ğ‘ . The a â€œvirtualâ€ value to
temporarily add to ğ‘ ( ğ‘ , ğ‘) during the simulation to discourage all simulations in a batch
from choosing the same path.

a1
s2
a2

MAV(s, a)

s3
a3
{(s1, a1), . . . , (sb, ab)}
Evaluate asynchronously!

Figure 4 | An overview of Asynchronous MCTS.
than an optimized deep convolutional network
(such as the ones used in MuZero (Schrittwieser
et al., 2020)), keeping the elapsed time for an
MCTS search to a reasonable level can be a challenge. The inference time of a single model call
dominates the time take for a search, so we aim
to keep the total calls low. Since the prior and
value for a new node are both obtained for the
MAV, there is at most one model call per simulation of MCTS. In the low simulation count regime
that we operate in, reusing the search trees is a
simple optimization that reduces the number of
server calls by 5-10% in our experiments.
Despite this lower number of inference calls,
it can still be costly to make many model calls.
Hence, we run an asynchronous version of MCTS
that is conceptually very similar to Algorithm 1,
but with the main loop (between lines 7â€“9)
changed. An overview is shown in Figure 4.
Parallel MCTS implementations usually rely on
virtual losses (Chaslot et al., 2008; Mirsoleimani
et al., 2017) to avoid multiple threads choosing
the same simulation paths down due to deterministic action choices. Our asynchronous MCTS
introduces three new parameters:
Batch size ğ‘. The number of simulations, each
leading to an evaluation (model call), that
are done asynchronously at any given time.
Timeout ğ‘¡0 . The amount of time to wait for evaluations. After the timeout expires, any evaluations that have not returned are discarded.

In Asynchronous MCTS, simulations are instead
performed in batches. First, ğ‘ downward passes
are performed serially to queue ğ‘ evaluations. The
ğ‘ evaluations are performed in parallel and the
MAV outputs are returned asynchronously.
The evaluations are then processed one-by-one
as they return. For each queued evaluation that
was successful (i.e., did not time out), its values
are then backpropagated up the tree (serially).
The state-action pairs that are visited before the
queuing of evaluations are assigned temporary
virtual counts: their visit counts are temporary set
to ğ‘ ( ğ‘ , ğ‘) = ğ‘ ( ğ‘ , ğ‘) + ğ‘›ğ‘ . The visit counts and virtual counts are then subtracted upon the upward
pass, i.e., ğ‘ ( ğ‘ , ğ‘) = ğ‘ ( ğ‘ , ğ‘) âˆ’ ğ‘›ğ‘ .
Note that, since the simulations and processing of evaluations (backpropagation) are both
done serially, there is no need for complex concurrency handling primitives such as mutexes or
semaphores. In practice, the implementation is
based on Pythonâ€™s concurrent.futures module and re-uses most of the serial MCTS subroutines, changing only the main loop.
Dynamic Virtual Counts In our low simulation
count settings, using the virtual losses accompanied by the fixed virtual counts ğ‘›ğ‘ did not strike a
satisfactory balance between exploration and exploitation. To circumvent this obstacle, we introduce the dynamic virtual counts that dynamically
assign more weight to the virtual count values
closer to the leaf nodes. Suppose simulation ğ‘š
encounters leaf node Nğ‘™ . We define a virtual count
for states-action pairs ( ğ‘ ğ‘¡ , ğ‘ğ‘¡ ) visited in simulation
ğ‘š and leaf Nğ‘™



ğ‘›ğ‘ ( ğ‘š, Nğ‘™ ) = min ğ‘›min , ğ‘›max Â· 2ğ‘‘Nğ‘¡ âˆ’ ğ‘‘Nğ‘™ ,
where ğ‘‘ Nğ‘¡ represents the depth of a child node Nğ‘¡
relative to the leaf node Nğ‘™ reached during simulation ğ‘š and âŒŠÂ·âŒ‹ is a floor function. As depicted
in Figure 5, it proved beneficial to exponentially
decrease the virtual counts starting with the maximum virtual count ğ‘›max at the leaf node which

8

Mastering Board Games by External and Internal Planning with Language Models

task, akin to CLRS-Text (Markeeva et al., 2024).

+4

+2

+4

+4

+4

+8

+8

+8

Figure 5 | Dynamic virtual counts for ğ‘›max = 8
and ğ‘›min = 2. Virtual counts from separate simulations are added, as is the case in the +4 node
with two children (+4 = (+2) + (+2)).
is then halved at each parent up to the root node
while maintining a minimum virtual count ğ‘›min .

The training data is based on target search
trees, which were constructed using depth 3 (N.B.,
depth-zero is MAV), by annotating states (e.g.
chess states being annotated with Stockfish), and
expanding the top 5 moves into trees. This results in high quality target search trees, similar
to those internally generated by engines such as
Leela or Stockfish. To diversify training data and
enable search budget control for trained models,
prompts were composed with diverse search parameters, ranging depth 1â€“3 and breadth 2â€“5,
and continuations yield corresponding trees that
were subsampled to match the parameters while
fitting into context size. This necessitated excluding the biggest parameter combination (i.e.,
omitting depth 3, breadth 5 examples).
An example internal search trace predicted by
the trained model, along with the corresponding
search tree, are shown in Figure 6.
Training details. We leveraged the pre-trained
MAV model and fine-tuned it using a mixture of
60% MAV data and 40% search data. Fine-tuning
was run for 20,000 steps, using a batch size of
512.

Internal Search
In contrast to external search, in internal search
the model does not require an external controller.
Instead, the search procedure is distilled into the
model so that it is capable of (ğ‘–) evaluating search
nodes (states), (ğ‘–ğ‘–) expanding nodes while updating the current state, and (ğ‘–ğ‘–ğ‘–) backpropagating
the results from leaf nodes back to the root nodeâ€”
all within a single model call. The distillation is
done by linearizing search trees into a text format
and training the model on those linearized trees.
Data. The prompt for internal search resembles
that of the MAV models, but includes a preamble
with search parameters (tree depth and breadth,
see Figure 6). The format of the target data is
inspired by depth-first order traversal of minimax
trees, as an iterative and linearized sequence of
minimax tree traversal. Hence, following this
format corresponds to an algorithmic execution

Experiments
Evaluation
Evaluating large language models in general and
reasoning specifically is a broad field (Chang et al.,
2024), within which games have been established
as an evaluation benchmark (Costarelli et al.,
2024; Duan et al., 2024). We evaluate language
models in a games league which runs our agents
in head-to-head match-ups, sampling combinations uniformly at random from a pool of agents.
We report internal Elo ratings (relative Elo only
between members of the population) as well as
external Elo ratings in cases where some of our
agents have externally reported Elos.
For chess evaluation, we rely on the state-of-theart engine Stockfish at different playing strengths
to estimate the widely used external Elo rating.
This is done by calibrating the internal Elo with

9

Mastering Board Games by External and Internal Planning with Language Models

Minimax breadth=3 depth=1
Evaluation for node: <root>
<mav game=chess> %state %top all %best action </mav>
[%state 2r3k1/p3p3/4N1Pp/3Q4/8/5Pq1/PPr3P1/1K5R b]
[%top all . . . g3g6:<ctrl33> . . . c2e2:<ctrl32> . . . g3d6:<ctrl35> . . . ]
[%best action g3d6]
8

0ZrZ0ZkZ
o0Z0o0Z0
0Z0ZNZPo
Z0ZQZ0Z0
0Z0Z0Z0Z
Z0Z0ZPl0
POrZ0ZPZ
ZKZ0Z0ZR

Expand from node <root>:
<root g3d6>
<root g3g6>
<root c2e2>

7

6

5

Evaluation for node: <root g3d6>
<mav game=chess> %prev state %prev action %state %top all %best action </mav>
[%prev state 2r3k1/p3p3/4N1Pp/3Q4/8/5Pq1/PPr3P1/1K5R b]
[%prev action g3d6]
[%state 2r3k1/p3p3/3qN1Pp/3Q4/8/5P2/PPr3P1/1K5R w]
[%top all d5d4:<ctrl18> . . . d5b3:<ctrl23> d5d6:<ctrl32> a2a3:<ctrl11> . . . ]
[%best action d5d6]
Decision for node: <root g3d6>
Selecting: d5d6 : "<ctrl32>"
Evaluation for node: <root g3g6>
<mav game=chess> %prev state %prev action %state %top all %best action </mav>
[%prev state 2r3k1/p3p3/4N1Pp/3Q4/8/5Pq1/PPr3P1/1K5R b]
[%prev action g3g6]
[%state 2r3k1/p3p3/4N1qp/3Q4/8/5P2/PPr3P1/1K5R w]
[%top all . . . d5c5:<ctrl1> e6f4:<ctrl22> b2b3:<ctrl1> . . . ]
[%best action e6f4]
Decision for node: <root g3g6>
Selecting: e6f4 : "<ctrl22>"
Evaluation for node: <root c2e2>
<mav game=chess> %prev state %prev action %state %top all %best action </mav>
[%prev state 2r3k1/p3p3/4N1Pp/3Q4/8/5Pq1/PPr3P1/1K5R b]
[%prev action c2e2]
[%state 2r3k1/p3p3/4N1Pp/3Q4/8/5Pq1/PP2r1P1/1K5R w]
[%top all . . . h1h6:<ctrl1> e6f4:<ctrl32> h1c1:<ctrl1> . . . ]
[%best action e6f4]
Decision for node: <root c2e2>
Selecting: e6f4 : "<ctrl32>"

4

3

2

1

a

b

c

d

e

qd6

g

h

re2

qXg6

v(â€¢) = 0.55
8

f

v(â€¢) = 0.5

v(â€¢) = 0.52
8

8

0ZrZ0ZkZ
o0Z0o0Z0
0Z0lNZPo
Z0ZQZ0Z0
0Z0Z0Z0Z
Z0Z0ZPZ0
POrZ0ZPZ
ZKZ0Z0ZR

0ZrZ0ZkZ
o0Z0o0Z0
0Z0ZNZqo
Z0ZQZ0Z0
0Z0Z0Z0Z
Z0Z0ZPZ0
POrZ0ZPZ
ZKZ0Z0ZR

0ZrZ0ZkZ
o0Z0o0Z0
0Z0ZNZPo
Z0ZQZ0Z0
0Z0Z0Z0Z
Z0Z0ZPl0
PO0ZrZPZ
ZKZ0Z0ZR

best action: QXd6

best action: Nf4

best action: Nf4

v(â—¦) = 0.5

v(â—¦) = 0.34

v(â—¦) = 0.5

7

6

5

4

3

2

1

a

b

Decision for node: <root> g3d6 : "<ctrl33>" g3g5 : "<ctrl43>" c2e2: "<ctrl33>"
Selecting g3g6 : "<ctrl43>"
Playing g3g6!

c

d

e

f

g

h

7

6

5

4

3

2

1

a

v(â€¢, a1 ) = 0.5,

b

c

d

e

f

g

v(â€¢, a2 ) = 0.66,

h

Selecting qXg6

7

6

5

4

3

2

1

a

b

c

d

e

f

g

h

v(â€¢, a3 ) = 0.5

Figure 6 | Internal search input prompt and response (breadth=3, depth=1). The response is an
actual model response, but for brevity, we only show some of the top_all action-value pairs. The
corresponding minimax search tree is visualized on the right. MAV assigns qd6 the highest value,
while internal search identifies the only winning move, qxg6.
externally-reported ratings using a linear fit. As
an additional, we include the Ext-BoN model (Ruoss et al., 2024), which showed Grandmasterlevel performance on chess with Transformers
(see Appendix for details). We use a set of TCEC
(Top Chess Engine Championship) opening positions (tce) (Table 4). In each match-up between
two agents, a specific opening is used, and agents
swap seats to ensure each agent plays each opening both as black and as white. Every instance of
Stockfish is run with 2 seconds of search time. We
delineate further our evaluation setting together
with the closest related works in the Appendix.

forms several strong baselines, including Stockfishâ€“L10 and performs comparably with the ExtBoN model by Ruoss et al. (2024). For Chess960
MAV outperforms Ruoss et al. (2024), perhaps
due to being trained explicitly on Chess960 data.

An overall comparison of the playing strength
of different methods is shown in Table 2. Next,
we perform a deeper dive into the performance
of the different approaches.

Generalization. During the opening and
endgame, human players often rely on memorized opening lines and endgame theory, while
middlegame requires more calculation and
intuition. We can see the same pattern in the
games of MAV (see Figure 8). Overall, 10% of
the positions played by MAV in evaluation appear
in its training data, while between moves 20 and
50, virtually no position has been seen by MAV
during training. These results show that in order

Multi-Action-Value Results
In terms of chess playing strength, MAV reaches
an external Elo of 2923 when using mean scoring
and 2875 when using max scoring. It thus outper-

In Table 3, we analyze the legal move rate,
the precision and recall of the predicted â€œtop-allâ€
moves, and the accuracy of predicting the next
FEN state after applying a chess move. The results
demonstrate that MAV is able to reliably perform
all of these actions.

10

Mastering Board Games by External and Internal Planning with Language Models

2920

3150

b=2
d=2

2910

3100

Elo

Elo

b=3 b=4
d=2 d=2

2930

3200

2900

3050

2890

3000

2880 MAV

10 2

2870

10 3

Number of simulations (MCTS)
(a) External search results. We vary the number
of simulations / MAV model calls.

b=3
d=1

10 3

Test-time tokens

10 4

(b) Internal search results. We vary the breadth (ğ‘)
and depth (ğ‘‘ ) of the minimax search performed in
a single model call. The ğ‘¥ -axis shows the number
of tokens in the prompt+response.

Figure 7 | Chess Elo improves with more test-time compute.

Agent
Stockfishâ€“L20
MAVâ€“MCTS( ğ‘€ = 2000)
Stockfishâ€“L19
Stockfishâ€“L18
MAVâ€“MCTS( ğ‘€ = 1000)
Stockfishâ€“L17
MAVâ€“MCTS( ğ‘€ = 500)
MAVâ€“MCTS( ğ‘€ = 250)
Stockfishâ€“L15
MAVâ€“MCTS( ğ‘€ = 100)
Ext-BoN (Ruoss et al., 2024)
MAV (mean scoring)
MAV (max scoring)
MAVâ€“small (max scoring)
Stockfishâ€“L10
Stockfishâ€“L5
Stockfishâ€“L0
MCTS

Chess
Int. Elo Ext. Elo
1990
3474
1707
3209
1689
3191
1655
3170
1633
3157
1604
3141
1592
3131
1542
3088
1520
3069
1435
2988
1370
2926
1367
2923
1317
2875
1259
2820
1225
2788
808
2203
515
1320
0
805

Chess960
Int. Elo
2053
1602
1645
1604
1561
1569
1506
1432
1436
1377
1208
1278
1213
1141
769
533
0

Connect Four
Int. Elo

Hex
Int. Elo

499
445
428

1048
1002

342

884

98

713

0

0

Table 2 | Performance comparison of different agents in Chess, Chess960, Connect Four, and Hex.
In MAVâ€“MCTS agents, ğ‘€ refers to the number of simulations. Important: The external Elos of the
Stockfish agents are anchored to the CCLR Blitz Elos. Therefore, the Elo estimates for the MAVâ€“MCTS
agents are not accurate as those agents would not be able to play at blitz time controls.

11

Mastering Board Games by External and Internal Planning with Language Models

%best_action legal
%top_all precision
%top_all recall
%top_all F1 score
Updated FEN correct

Lichess
puzzles

OOD
positions

0.999
0.999
1.000
0.999
1.000

0.996
0.997
0.997
0.995
0.996

0JRZ0ANS
ZPO0O0ZP
3
PZNZpO0Z
4
Z0Z0Z0O0
5
0o0O0ZQZ
6
Z0ZpZnZ0
7
pZpmqZpo
8
s0akZ0Zr
1
2

Table 3 | Error rate analysis for MAV model in
chess positions. We consider positions drawn
from Lichess puzzles, and from a dataset of randomly generated boards that never occur in the
course of normal gameplay, and are highly outof-distribution compared to the training data.

to avoid losing games during middlegame, MAV
is required to generalize.

h

g

f

e

d

c

b

a

Figure 9 | Example position where MAV plays a
creative pawn sacrifice, g5 (best move according
to Stockfish), to gain a long-term advantage.
External search results

Test positions seen
during training (%)

100
80
60
40
20
0

0

10

20

30

40

50

Fullmove number

60

70

Figure 8 | Percentage of chess positions encountered during evaluation that also appear in the
MAV training data. Between moves 20 and 50, almost all of the encountered positions are unseen,
requiring the model to generalize.

Finally, we show an example of MAVâ€™s generalization capabilities into a position which does
not appear in the training data. In the position
shown in Figure 9, MAV has found a creative
move, g5, which is the best move according to
Stockfish. The move allows the White knight on
f3 to capture the pawn but results in a long-term
advantage for Black.

For our external-MCTS agents, we tune hyperparameters using a combination of manual and
head-to-head comparisons. We found that setting ğœ = 1.0, ğ‘˜ = 5, and ğœ€ = 0.1 worked best
for the prior. Please see the appendix for details.
For Async MCTS we used a batch size ğ‘ = 16.
We found that lower batch sizes were always
preferred in terms of performance. After hyperparameter tuning, we used dynamic virtual count
values ğ‘›min = 2 in all cases, and ğ‘›max varying with
the number of simulations: ( ğ‘€, ğ‘›max ) âˆˆ {(100, 8),
(250, 8), (500, 8), (1000, 16), (2000, 32)}. We
also include a basic MCTS baseline, which refers
to MCTS with a uniform prior and random rollouts run with 100 simulations.
We first analyze the performance of the scoring
method for the value function when used within
MAVâ€“MCTS . We do this by running a large tournament amount all MAVâ€“MCTS variants, various
levels of Stockfish, MAV on its own, and basic
MCTS. MAVâ€“MCTS with mean scoring performs
better in all cases, with a 25-69 difference in Elo.
Hence, for the remainder of the external search
experiments, we report results only for the mean
scoring method. The full results are shown in
Figure 10 in the appendix.
We then run a similar tournament including

12

Mastering Board Games by External and Internal Planning with Language Models

Ext-BoN: the results are shown in Table 2. The
total number of games played in each respective
tournament were 14689 for standard chess, 4480
for chess960, 2189 for Connect Four, and 6334
for Hex. In chess, MAVâ€“MCTS with just 100 simulations achieves an internal Elo 68 higher than the
base MAV model in chess, and generally performance rises consistently with more simulations,
up to 340 internal Elo improvement at 2000 simulations. This is also illustrated in Figure 7a, which
demonstrates that Elo improves logarithmically
as a function of the number of simulations.
In the case of Chess960, every game begins
with a random position (among a preset 960 initial positions). We obtain comparable results to
chess.
In the case of Connect Four, we notice that MAVâ€“
MCTS is particularly helpful in improving upon
the base model. All external search agents improve by at least 244 Elo upon the base model. In
Connect Four, we notice that improvements consistently rise with added simulations, albeit with
smaller performance differences between simulation counts compared to chess. In Connect Four,
we notice a relatively smaller performance gain
between basic MCTS and the MAV model, and
larger improvements between the MAV model
and external search.
Since our final model was not adequately
trained with state-tracking capabilities for Hex,
in the Hex results only a game engine is used
to determine terminal states, legal actions, and
state transitions. In contrast to Connect Four, we
notice a large improvement between basic MCTS
and the MAV model in Hex, and improvements
similar to chess from search. We suspect that this
is due to the relative complexity of the games,
but more research is needed to clarify the reason for these differences. It should be possible to
support the engine-free logic in Hex similarly to
chess going forward. Across all games, external
MCTS performs consistently better as the number
of simulations is increased.
Internal search results
For our internal search experiments, we vary the
depth and breadth parameters of the minimax

search, up to breadth 4 and depth 2. We map
these different configurations into token counts
by computing the average length of the prompt +
response per configuration in our training data.
Figure 7b shows the performance of the model
as the function of token counts. We can see that
playing strength, measured by external Elo2 , increases with the search budget.
For an example of how internal search can improve playing strength, see Figure 6. In this example, the initial MAV section of the response
predicts qd6 as the best move. However, as the
internal search continues, the model is able to
find a better move qXg6 after exploring the top3 lines one step further. This points to the modelâ€™s
ability to self-correct, which is an important capability of LLMs that can reason (Kumar et al.,
2024).

Discussions and limitations
Despite promising results in the domain of perfect
information board games indicating the potential
of external and internal planning with LLMs, our
initial study makes a number of assumptions that
future work may need to address â€“ namely, the
ability to acquire or generate large quantities of
game play data, as well as the availability of reliable solvers or game engines that can be used to
annotate this data in order to create an appropriate training curriculum for the model. We have
also yet to fully explore the distillation of more
complex search procedures, which may introduce
additional challenges.
Another important limitation of our MAV models is that they have been trained exclusively on
game data, and therefore do not possess the ability to communicate verbally using natural language. However, there should be no fundamental
obstacles in achieving the same ability in potentially larger models that may also incorporate
natural language data, as we train on the exact
2 For the internal search experiments, we didnâ€™t play

games until checkmate but stopped them once either side
had reached a decisive, 1200+ centipawn advantage. This
was done since the internal search training data did not
train the model to predict the quickest win, which would
sometimes result in the model aimlessly moving around
pieces in winning positions.

13

Mastering Board Games by External and Internal Planning with Language Models

same architecture and tokenizer used in classical
text-based LLMs.
Meanwhile, we argue that there is potential
utility in the separation of responsibilities within
a larger system, and we demonstrate that it is
possible to utilise the proposed models as tools
within a larger generalist model, calling the specialist model through a natural language tool-use
interface with an appropriately formatted input
(objective, game dynamics, game state) and output (choice, justification). Specialist models may
also be used as teachers for distilling their knowledge into generalists (Bounsi et al., 2024).
It remains an open question how to design good
value functions for general conversational task,
and how to incorporate these value functions or
other highly specialized knowledge in training
such that the model can draw upon them flexibly
at inference time, in a wide variety of conversational contexts.

Conclusions
This paper demonstrates the capacity of LLMs to
learn strong value functions and act as a world
model across multiple perfect information games.
This enables their use in MCTS, where we observe
significant performance gains of approximately
+300 Elo points even with a fairly limited search
budget. Going further, we find that training on
search traces enables the model to learn an effective search procedure that can be executed via a
single model call. This adds to the rapidly growing body of literature highlighting the promise of
planning and reasoning with LLMs.

Acknowledgements
We would like to thank Alexis Jacq, Yoram
Bachrach, and Roma Patel for their contributions
early on in the project, and GM Bogdan-Daniel
Deac, GM Dharshan Kumaran, and Luka RimaniÄ‡
for playing test games and providing feedback on
the MAV model. We are grateful to Aliaksei Severyn, David Silver, Jessica Hamrick, Gabriel DulacArnold, Been Kim, Simon Osindero, Matthew Lai,
and Demis Hassabis for their support and advising on the project.

References
Top chess engine championship. URL https:
//tcec-chess.com/.
Torres and his remarkable automatic devices
â€” he would substitute machinery for the human mind. Scientific American Supplement, 80
(2079):296, November 1915.
M. Acher. Debunking the chessboard: Confronting gpts against chess engines to estimate elo ratings and assess legal move abilities,
2023. URL https://blog.mathieuacher.
com/GPTsChessEloRatingLegalMoves/.
R. Agarwal, A. Singh, L. M. Zhang, B. Bohnet,
S. Chan, A. Anand, Z. Abbas, A. Nova, J. D. CoReyes, E. Chu, et al. Many-shot in-context learning. arXiv preprint arXiv:2404.11018, 2024.
R. Aksitov, S. Miryoosefi, Z. Li, D. Li, S. Babayan,
K. Kopparapu, Z. Fisher, R. Guo, S. Prakash,
P. Srinivasan, M. Zaheer, F. Yu, and S. Kumar.
Rest meets react: Self-improvement for multistep reasoning llm agent, 2023. URL https:
//arxiv.org/abs/2312.10003.
Anonymous. Implicit search via discrete diffusion:
A study on chess. In Submitted to The Thirteenth
International Conference on Learning Representations, 2024. URL https://openreview.
net/forum?id=A9y3LFX4ds. under review.
Y. Bang, S. Cahyawijaya, N. Lee, W. Dai, D. Su,
B. Wilie, H. Lovenia, Z. Ji, T. Yu, W. Chung,
Q. V. Do, Y. Xu, and P. Fung. A multitask,
multilingual, multimodal evaluation of chatgpt
on reasoning, hallucination, and interactivity,
2023. URL https://arxiv.org/abs/2302.
04023.
M. Besta, N. Blach, A. Kubicek, R. Gerstenberger, M. Podstawski, L. Gianinazzi, J. Gajda,
T. Lehmann, H. Niewiadomski, P. Nyczyk, and
T. Hoefler. Graph of thoughts: Solving elaborate problems with large language models. In
AAAI, pages 17682â€“17690. AAAI Press, 2024.
N. Borazjanizadeh and S. T. Piantadosi. Reliable
reasoning beyond natural language, 2024. URL
https://arxiv.org/abs/2407.11373.

14

Mastering Board Games by External and Internal Planning with Language Models

W. Bounsi, B. Ibarz, A. Dudzik, J. B. Hamrick, L. Markeeva, A. Vitvitskyi, R. Pascanu,
and P. VeliÄkoviÄ‡. Transformers meet neural algorithmic reasoners.
arXiv preprint
arXiv:2406.09308, 2024.
M. M. Bronstein, J. Bruna, T. Cohen, and
P. VeliÄkoviÄ‡. Geometric deep learning: Grids,
groups, graphs, geodesics, and gauges. arXiv
preprint arXiv:2104.13478, 2021.
T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D.
Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,
G. Sastry, A. Askell, et al. Language models
are few-shot learners. Advances in neural information processing systems, 33:1877â€“1901,
2020.
C. Burns, P. Izmailov, J. H. Kirchner, B. Baker,
L. Gao, L. Aschenbrenner, Y. Chen, A. Ecoffet, M. Joglekar, J. Leike, et al. Weak-tostrong generalization: Eliciting strong capabilities with weak supervision. arXiv preprint
arXiv:2312.09390, 2023.
Y. Chang, X. Wang, J. Wang, Y. Wu, L. Yang,
K. Zhu, H. Chen, X. Yi, C. Wang, Y. Wang, et al.
A survey on evaluation of large language models. ACM Transactions on Intelligent Systems
and Technology, 15(3):1â€“45, 2024.
G. M. B. Chaslot, M. H. Winands, and H. J. van
Den Herik. Parallel Monte-Carlo tree search. In
Computers and Games: 6th International Conference, CG 2008, Beijing, China, September 29October 1, 2008. Proceedings 6, pages 60â€“71.
Springer, 2008.
C. Chen, X. Wang, T.-E. Lin, A. Lv, Y. Wu,
X. Gao, J.-R. Wen, R. Yan, and Y. Li. Masked
thought: Simply masking partial reasoning
steps can improve mathematical reasoning
learning of language models. arXiv preprint
arXiv:2403.02178, 2024a.
L. Chen, P. Tong, Z. Jin, Y. Sun, J. Ye, and H. Xiong.
Plan-on-graph: Self-correcting adaptive planning of large language model on knowledge
graphs, 2024b. URL https://arxiv.org/
abs/2410.23875.

Z. Chen, Y. Deng, H. Yuan, K. Ji, and Q. Gu. Selfplay fine-tuning converts weak language models to strong language models, 2024c. URL
https://arxiv.org/abs/2401.01335.
Z. Chen, M. White, R. Mooney, A. Payani, Y. Su,
and H. Sun. When is tree search useful for
llm planning? it depends on the discriminator, 2024d. URL https://arxiv.org/abs/
2402.10890.
Y. K. Chia, V. T. Y. Han, D. Ghosal, L. Bing, and
S. Poria. Puzzlevqa: Diagnosing multimodal
reasoning challenges of language models with
abstract visual patterns, 2024. URL https:
//arxiv.org/abs/2403.13315.
A. Costarelli, M. Allen, R. Hauksson, G. Sodunke,
S. Hariharan, C. Cheng, W. Li, and A. Yadav. Gamebench: Evaluating strategic reasoning abilities of LLM agents. arXiv preprint
arXiv:2406.06613, 2024.
W. Cui, K. Bi, J. Guo, and X. Cheng. More:
Multi-modal retrieval augmented generative
commonsense reasoning.
arXiv preprint
arXiv:2402.13625, 2024.
G. Dagan, F. Keller, and A. Lascarides. Dynamic
planning with a llm, 2023. URL https://
arxiv.org/abs/2308.06391.
R. Ding, C. Zhang, L. Wang, Y. Xu, M. Ma,
W. Zhang, S. Qin, S. Rajmohan, Q. Lin, and
D. Zhang. Everything of thoughts: Defying the
law of penrose triangle for thought generation.
arXiv preprint arXiv:2311.04254, 2023.
J. Duan, R. Zhang, J. Diffenderfer, B. Kailkhura,
L. Sun, E. Stengel-Eskin, M. Bansal, T. Chen,
and K. Xu. Gtbench: Uncovering the strategic reasoning limitations of llms via gametheoretic evaluations, 2024. URL https://
arxiv.org/abs/2402.12348.
A. E. Elo. The proposed uscf rating system, its
development, theory, and applications. Chess
life, 22(8):242â€“247, 1967.
N. Ensmenger. Is chess the drosophila of artificial
intelligence? a social history of an algorithm.
Social studies of science, 42(1):5â€“30, 2012.

15

Mastering Board Games by External and Internal Planning with Language Models

M. Fang, S. Deng, Y. Zhang, Z. Shi, L. Chen,
M. Pechenizkiy, and J. Wang. Large language
models are neurosymbolic reasoners. In AAAI,
pages 17985â€“17993. AAAI Press, 2024.
J. Farebrother, J. Orbay, Q. Vuong, A. A. TaÃ¯ga,
Y. Chebotar, T. Xiao, A. Irpan, S. Levine, P. S.
Castro, A. Faust, A. Kumar, and R. Agarwal.
Stop regressing: Training value functions via
classification for scalable deep rl, 2024. URL
https://arxiv.org/abs/2403.03950.
G. Feng, B. Zhang, Y. Gu, H. Ye, D. He, and
L. Wang. Towards revealing the mystery behind chain of thought: a theoretical perspective. Advances in Neural Information Processing
Systems, 36, 2024a.
X. Feng, Y. Luo, Z. Wang, H. Tang, M. Yang,
K. Shao, D. Mguni, Y. Du, and J. Wang. Chessgpt: Bridging policy learning and language
modeling, 2023. URL https://arxiv.org/
abs/2306.09200.
X. Feng, Z. Wan, M. Wen, S. M. McAleer, Y. Wen,
W. Zhang, and J. Wang. Alphazero-like treesearch can guide large language model decoding and training, 2024b. URL https:
//arxiv.org/abs/2309.17179.

C. Gao and J. Pawlewicz. neurobenzene: An improved benzene project for playing and solving hex with the help of deep neural networks. URL https://github.com/cgao3/
neurobenzene.
T. Gao, A. Fisch, and D. Chen. Making pretrained language models better few-shot learners. arXiv preprint arXiv:2012.15723, 2020.
Gemini Team, R. Anil, S. Borgeaud, Y. Wu, J.-B.
Alayrac, J. Yu, R. Soricut, J. Schalkwyk, A. M.
Dai, A. Hauth, et al. Gemini: A family of highly
capable multimodal models, 2024. URL https:
//arxiv.org/abs/2312.11805.
P. Giadikiaroglou, M. Lymperaiou, G. Filandrianos, and G. Stamou. Puzzle solving using
reasoning of large language models: A survey,
2024. URL https://arxiv.org/abs/2402.
11291.
O. Gramopadhye, S. S. Nachane, P. Chanda,
G. Ramakrishnan, K. S. Jadhav, Y. Nandwani,
D. Raghu, and S. Joshi. Few shot chain-ofthought driven reasoning to prompt llms for
open ended medical question answering. arXiv
preprint arXiv:2403.04890, 2024.

A. Grosnit, A. Maraval, J. Doran, G. Paolo,
A. Thomas, R. S. H. N. Beevi, J. Gonzalez,
K. Khandelwal, I. Iacobacci, A. Benechehab,
E. Gan, Y. Zhao, L. Cheng, Y. Mao, A. Goyal,
H. Cherkaoui, Y. A. El-Hili, K. Shao, J. Hao,
K. Kawaguchi, M.-Y. Kan, and M. Shieh. ReaJ. Yao, B. Kegl, H. Bou-Ammar, and J. Wang.
soning robustness of llms to adversarial typoLarge language models orchestrating strucgraphical errors, 2024. URL https://arxiv.
tured reasoning achieve kaggle grandmaster
org/abs/2411.05345.
level, 2024. URL https://arxiv.org/abs/
2411.03562.
K. Gandhi, D. Sadigh, and N. D. Goodman. Strategic reasoning with language models. arXiv J. Gu, C. Li, Y. Liang, Z. Shi, Z. Song, and T. Zhou.
preprint arXiv:2305.19165, 2023.
Fourier circuits in neural networks: Unlocking
K. Gandhi, J.-P. FrÃ¤nken, T. Gerstenberg, and
N. Goodman. Understanding social reasoning
in language models with language models. Advances in Neural Information Processing Systems,
36, 2024a.
K. Gandhi, D. Lee, G. Grand, M. Liu, W. Cheng,
A. Sharma, and N. D. Goodman. Stream of
search (SoS): Learning to search in language,
2024b.

the potential of large language models in mathematical reasoning and modular arithmetic.
arXiv preprint arXiv:2402.09469, 2024.
K. Guo, B. Nan, Y. Zhou, T. Guo, Z. Guo,
M. Surve, Z. Liang, N. V. Chawla, O. Wiest,
and X. Zhang. Can LLMs solve molecule puzzles? a multimodal benchmark for molecular structure elucidation. In The Thirtyeight Conference on Neural Information Processing Systems Datasets and Benchmarks Track,

16

Mastering Board Games by External and Internal Planning with Language Models

URL https://openreview.net/
forum?id=t1mAXb4Cop.

model-based game agents, 2024b. URL https:
//arxiv.org/abs/2404.02039.

M. U. Hadi, R. Qureshi, A. Shah, M. Irfan, A. Zafar, M. B. Shaikh, N. Akhtar, J. Wu, S. Mirjalili,
et al. A survey on large language models: Applications, challenges, limitations, and practical
usage. Authorea Preprints, 2023.

S. Hu, T. Huang, and L. Liu. Pokellmon: A
human-parity agent for pokemon battles with
large language models, 2024c. URL https:
//arxiv.org/abs/2402.01118.

2024.

J. Huang and K. C.-C. Chang. Towards reasonK. Hamade, R. McIlroy-Young, S. Sen, J. Kleinberg,
ing in large language models: A survey. arXiv
and A. Anderson. Designing skill-compatible
preprint arXiv:2212.10403, 2022.
ai: Methodologies and frameworks in chess,
2024. URL https://arxiv.org/abs/2405. J. Huang, X. Chen, S. Mishra, H. S. Zheng, A. W.
Yu, X. Song, and D. Zhou. Large language mod05066.
els cannot self-correct reasoning yet, 2024. URL
S. Hao, Y. Gu, H. Ma, J. J. Hong, Z. Wang, D. Z.
https://arxiv.org/abs/2310.01798.
Wang, and Z. Hu. Reasoning with language
model is planning with world model. arXiv E. Jenner, S. Kapur, V. Georgiev, C. Allen, S. Emmons, and S. Russell. Evidence of learned
preprint arXiv:2305.14992, 2023.
look-ahead in a chess-playing neural network,
S. Haresh, D. Dijkman, A. Bhattacharyya, and
2024. URL https://arxiv.org/abs/2406.
R. Memisevic. Clevrskills: Compositional lan00877.
guage and visual reasoning in robotics. In The
Thirty-eight Conference on Neural Information D. Ji, L. Zhu, S. Gao, P. Xu, H. Lu, J. Ye, and
F. Zhao. Tree-of-table: Unleashing the power
Processing Systems Datasets and Benchmarks
of llms for enhanced large-scale table underTrack, 2024. URL https://openreview.
standing, 2024. URL https://arxiv.org/
net/forum?id=64sZtFSOh6.
abs/2411.08516.
J. J. Horton. Large language models as simulated economic agents: What can we learn from J. Jiang, Z. Chen, Y. Min, J. Chen, X. Cheng,
J. Wang, Y. Tang, H. Sun, J. Deng, W. X. Zhao,
homo silicus? Technical report, National BuZ. Liu, D. Yan, J. Xie, Z. Wang, and J.-R. Wen.
reau of Economic Research, 2023.
Technical report: Enhancing llm reasoning
A. Hosseini, X. Yuan, N. Malkin, A. Courville,
with reward-guided tree search, 2024. URL
A. Sordoni, and R. Agarwal. V-star: Trainhttps://arxiv.org/abs/2411.11694.
ing verifiers for self-taught reasoners. arXiv
Z. Jin, Y. Chen, F. Leeb, L. Gresele, O. Kamal,
preprint arXiv:2402.06457, 2024.
Z. Lyu, K. Blin, F. Gonzalez Adauto, M. KleimanM. Hu, L. Zong, H. Wang, J. Zhou, J. Li, Y. Gao,
Weiner, M. Sachan, et al. Cladder: A benchmark
K.-F. Wong, Y. Li, and I. King.
SeRTS:
to assess causal reasoning capabilities of lanSelf-rewarding tree search for biomediguage models. Advances in Neural Information
cal retrieval-augmented generation.
In
Processing Systems, 36, 2024.
Y. Al-Onaizan, M. Bansal, and Y.-N. Chen,
editors, Findings of the Association for Com- D. Kahneman. Thinking, Fast and Slow. Farrar,
Straus and Giroux, 2011.
putational Linguistics: EMNLP 2024, pages
1321â€“1335, Miami, Florida, USA, Nov. 2024a.
Association for Computational Linguistics. J. Kil, Z. Mai, J. Lee, A. Chowdhury, Z. Wang,
K. Cheng, L. Wang, Y. Liu, and W.-L. Chao.
URL https://aclanthology.org/2024.
MLLM-compbench: A comparative reasoning
findings-emnlp.71.
benchmark for multimodal LLMs. In The
S. Hu, T. Huang, F. Ilhan, S. Tekin, G. Liu, R. KomThirty-eight Conference on Neural Information
pella, and L. Liu. A survey on large language
Processing Systems Datasets and Benchmarks

17

Mastering Board Games by External and Internal Planning with Language Models

Track, 2024.

URL https://openreview.
net/forum?id=xotfLEAF4u.

for large language models. In The Thirtyeight Conference on Neural Information Processing Systems Datasets and Benchmarks Track,
2024b. URL https://openreview.net/
forum?id=Jaye8aWpmZ.

J. Y. Koh, S. McAleer, D. Fried, and R. Salakhutdinov. Tree search for language model agents,
2024. URL https://arxiv.org/abs/2407.
01476.
J. Light, M. Cai, W. Chen, G. Wang, X. Chen,
W. Cheng, Y. Yue, and Z. Hu. Strategist: LearnT. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwaing strategic skills by llms via bi-level tree
sawa. Large language models are zero-shot
search, 2024. URL https://arxiv.org/
reasoners. Advances in neural information proabs/2408.10635.
cessing systems, 35:22199â€“22213, 2022.
A. Kumar, V. Zhuang, R. Agarwal, Y. Su, J. D. CoReyes, A. Singh, K. Baumli, S. Iqbal, C. Bishop,
R. Roelofs, et al. Training language models to
self-correct via reinforcement learning. arXiv
preprint arXiv:2409.12917, 2024.
M. Lanctot, E. Lockhart, J.-B. Lespiau, V. Zambaldi, S. Upadhyay, J. PÃ©rolat, S. Srinivasan, F. Timbers, K. Tuyls, S. Omidshafiei,
et al. Openspiel: A framework for reinforcement learning in games. arXiv preprint
arXiv:1908.09453, 2019.
M. Laskin, L. Wang, J. Oh, E. Parisotto, S. Spencer,
R. Steigerwald, D. Strouse, S. Hansen, A. Filos,
E. Brooks, M. Gazeau, H. Sahni, S. Singh, and
V. Mnih. In-context reinforcement learning
with algorithm distillation, 2022. URL https:
//arxiv.org/abs/2210.14215.
J. Lee, F. Yang, T. Tran, Q. Hu, E. Barut, K.-W.
Chang, and C. Su. Can small language models help large language models reason better?:
Lm-guided chain-of-thought. arXiv preprint
arXiv:2404.03414, 2024.
J. Li, H. Le, Y. Zhou, C. Xiong, S. Savarese, and
D. Sahoo. Codetree: Agent-guided tree search
for code generation with large language models, 2024a. URL https://arxiv.org/abs/
2411.04329.
N. Li, C. Gao, Y. Li, and Q. Liao. Large language model-empowered agents for simulating macroeconomic activities. arXiv preprint
arXiv:2310.10436, 2023.
Y. Li, Q. Zhou, Y. Luo, S. Ma, Y. Li, H.-T. Zheng,
X. Hu, and P. S. Yu. When LLMs meet cunning texts: A fallacy understanding benchmark

J. Long. Large language model guided treeof-thought. arXiv preprint arXiv:2305.08291,
2023.
P. Lu, S. Mishra, T. Xia, L. Qiu, K.-W. Chang, S.C. Zhu, O. Tafjord, P. Clark, and A. Kalyan.
Learn to explain: Multimodal reasoning via
thought chains for science question answering.
Advances in Neural Information Processing Systems, 35:2507â€“2521, 2022.
P. Lu, B. Peng, H. Cheng, M. Galley, K.-W. Chang,
Y. N. Wu, S.-C. Zhu, and J. Gao. Chameleon:
Plug-and-play compositional reasoning with
large language models. Advances in Neural
Information Processing Systems, 36, 2024.
L. Markeeva, S. McLeish, B. Ibarz, W. Bounsi,
O. Kozlova, A. Vitvitskyi, C. Blundell, T. Goldstein, A. Schwarzschild, and P. VeliÄkoviÄ‡. The
clrs-text algorithmic reasoning language benchmark. arXiv preprint arXiv:2406.04229, 2024.
E. Markowitz, A. Ramakrishna, J. Dhamala,
N. Mehrabi, C. Peris, R. Gupta, K.-W. Chang,
and A. Galstyan. Tree-of-traversals: A zeroshot reasoning algorithm for augmenting blackbox language models with knowledge graphs,
2024. URL https://arxiv.org/abs/2407.
21358.
J. McCarthy. Chess as the drosophila of ai. In Computers, chess, and cognition, pages 227â€“237.
Springer, 1990.
A. Menon. Bridging chess mastery and ai innovation: The making of llm-chesscoach, 2023.
S. Menon, R. Zemel, and C. Vondrick. Whiteboardof-thought: Thinking step-by-step across

18

Mastering Board Games by External and Internal Planning with Language Models

modalities, 2024. URL https://arxiv.org/
abs/2406.14562.
S. Minaee, T. Mikolov, N. Nikzad, M. Chenaghlu,
R. Socher, X. Amatriain, and J. Gao. Large
language models: A survey. arXiv preprint
arXiv:2402.06196, 2024.
S. A. Mirsoleimani, A. Plaat, J. van den Herik,
and J. Vermaseren. An analysis of virtual loss
in parallel MCTS. In International Conference
on Agents and Artificial Intelligence, 2017. URL

https://api.semanticscholar.org/
CorpusID:34042014.

A. Plaat, A. Wong, S. Verberne, J. Broekens,
N. van Stein, and T. Back. Reasoning with
large language models, a survey. arXiv preprint
arXiv:2407.11511, 2024.
O. Press, M. Zhang, S. Min, L. Schmidt, N. A.
Smith, and M. Lewis. Measuring and narrowing the compositionality gap in language models. arXiv preprint arXiv:2210.03350, 2022.
B. Prystawski, M. Li, and N. Goodman. Why think
step by step? reasoning emerges from the locality of experience. Advances in Neural Information Processing Systems, 36, 2024.

C. Mitra, B. Huang, T. Darrell, and R. Herzig.
Compositional chain-of-thought prompting for
large multimodal models. In Proceedings of
the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pages 14420â€“14431,
2024.

P. Putta, E. Mills, N. Garg, S. Motwani, C. Finn,
D. Garg, and R. Rafailov. Agent q: Advanced
reasoning and learning for autonomous ai
agents, 2024. URL https://arxiv.org/
abs/2408.07199.

D. Monroe and T. Leela Chess Zero Team. Mastering chess with a transformer model, 2024. URL
https://arxiv.org/abs/2409.12272.

R. Rafailov, J. Hejna, R. Park, and C. Finn. From
ğ‘Ÿ to ğ‘âˆ— : Your language model is secretly a qfunction, 2024. URL https://arxiv.org/
abs/2404.12358.

M. Nguyen and E. Shareghi. One step at a
time: Language agents are stepwise planners, S. Rasal and E. J. Hauer. Optimal decision making
2024. URL https://arxiv.org/abs/2411.
through scenario simulations using large lan08432.
guage models, 2024. URL https://arxiv.
org/abs/2407.06486.
H. Nori, N. Usuyama, N. King, S. M. McKinney,
X. Fernandes, S. Zhang, and E. Horvitz. From D. Rebstock, C. Solinas, N. R. Sturtevant, and
medprompt to o1: Exploration of run-time
M. Buro. Transformer based planning in the
strategies for medical challenge problems and
observation space with applications to trick takbeyond, 2024. URL https://arxiv.org/
ing card games, 2024. URL https://arxiv.
abs/2411.03590.
org/abs/2404.13150.
B. Paranjape, S. Lundberg, S. Singh, H. Hajishirzi, L. Zettlemoyer, and M. T. Ribeiro. Art:
Automatic multi-step reasoning and tool-use
for large language models. arXiv preprint
arXiv:2303.09014, 2023.

A. Z. Ren, B. Ichter, and A. Majumdar. Thinking forward and backward: Effective backward planning with large language models,
2024. URL https://arxiv.org/abs/2411.
01790.

T. Parekh, P. Prakash, A. Radovic, A. Shekher,
and D. Savenkov. Dynamic strategy planning A. Ruoss, G. DelÃ©tang, S. Medapati, J. GrauMoya, L. K. Wenliang, E. Catt, J. Reid, C. A.
for efficient question answering with large lanLewis, J. Veness, and T. Genewein. Amortized
guage models, 2024. URL https://arxiv.
planning with large-scale transformers: A case
org/abs/2410.23511.
study on chess. In NeurIPS, 2024.
J. Pfau, W. Merrill, and S. R. Bowman. Letâ€™s
think dot by dot: Hidden computation in trans- K. Saab, T. Tu, W.-H. Weng, R. Tanno, D. Stutz,
former language models, 2024. URL https:
E. Wulczyn, F. Zhang, T. Strother, C. Park,
//arxiv.org/abs/2404.15758.
E. Vedadi, et al. Capabilities of gemini models

19

Mastering Board Games by External and Internal Planning with Language Models

in medicine. arXiv preprint arXiv:2404.18416,
2024.
A. Saparov and H. He.
Language models
are greedy reasoners: A systematic formal
analysis of chain-of-thought. arXiv preprint
arXiv:2210.01240, 2022.
T. Schaul, J. Togelius, and J. Schmidhuber. Measuring intelligence through games. arXiv
preprint arXiv:1109.1314, 2011.

strapping mathematical reasoning for multimodal large language models, 2024. URL
https://arxiv.org/abs/2406.17294.
D.

Silver, T. Hubert, J. Schrittwieser,
I. Antonoglou, M. Lai, A. Guez, M. Lanctot,
L. Sifre, D. Kumaran, T. Graepel, T. Lillicrap,
K. Simonyan, and D. Hassabis. Mastering
chess and shogi by self-play with a general
reinforcement learning algorithm, 2017. URL
https://arxiv.org/abs/1712.01815.

J. Schrittwieser, I. Antonoglou, T. Hubert, K. Si- A. Singh, J. D. Co-Reyes, R. Agarwal, A. Anand,
P. Patil, X. Garcia, P. J. Liu, J. Harrison,
monyan, L. Sifre, S. Schmitt, A. Guez, E. LockJ. Lee, K. Xu, A. Parisi, A. Kumar, A. Alemi,
hart, D. Hassabis, T. Graepel, T. Lillicrap, and
A. Rizkowsky, A. Nova, B. Adlam, B. Bohnet,
D. Silver. Mastering atari, go, chess and shogi
G. Elsayed, H. Sedghi, I. Mordatch, I. Simpby planning with a learned model. Nature,
son, I. Gur, J. Snoek, J. Pennington, J. Hron,
588(7839):604â€“609, 2020. doi: 10.1038/
K. Kenealy, K. Swersky, K. Mahajan, L. Culp,
s41586-020-03051-4. URL https://doi.
L. Xiao, M. L. Bileschi, N. Constant, R. Noorg/10.1038/s41586-020-03051-4.
vak, R. Liu, T. Warkentin, Y. Qian, Y. Bansal,
H. Shao, S. Qian, H. Xiao, G. Song, Z. Zong,
E. Dyer, B. Neyshabur, J. Sohl-Dickstein, and
L. Wang, Y. Liu, and H. Li. Visual cot: AdN. Fiedel. Beyond human data: Scaling selfvancing multi-modal language models with
training for problem-solving with language
a comprehensive dataset and benchmark for
models, 2024. URL https://arxiv.org/
chain-of-thought reasoning. In The Thirtyabs/2312.06585.
eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track, K. Stechly, K. Valmeekam, and S. Kambhampati.
Chain of thoughtlessness? an analysis of cot in
2024a. URL https://openreview.net/
planning, 2024. URL https://arxiv.org/
forum?id=aXeiCbMFFJ.
abs/2405.04776.
Z. Shao, Y. Gong, Y. Shen, M. Huang, N. Duan,
X. Tang, X. Wang, W. X. Zhao, and J.-R. Wen.
and W. Chen. Synthetic prompting: Generating
Dawn-icl: Strategic planning of problemchain-of-thought demonstrations for large lansolving trajectories for zero-shot in-context
guage models. In International Conference on
learning, 2024a. URL https://arxiv.org/
Machine Learning, pages 30706â€“30775. PMLR,
abs/2410.20215.
2023.
Z. Tang, X. Zhang, B. Wan, and F. Wei. MathZ. Shao, P. Wang, Q. Zhu, R. Xu, J. Song,
scale: Scaling instruction tuning for mathematiM. Zhang, Y. Li, Y. Wu, and D. Guo. Deepseekcal reasoning. arXiv preprint arXiv:2403.02884,
math: Pushing the limits of mathematical rea2024b.
soning in open language models. arXiv preprint
Y. Tian, B. Peng, L. Song, L. Jin, D. Yu, H. Mi,
arXiv:2402.03300, 2024b.
and D. Yu. Toward self-improvement of llms
F. Shi, M. Suzgun, M. Freitag, X. Wang, S. Srivia imagination, searching, and criticizing,
vats, S. Vosoughi, H. W. Chung, Y. Tay, S. Ruder,
2024. URL https://arxiv.org/abs/2404.
D. Zhou, et al. Language models are multilin12253.
gual chain-of-thought reasoners. arXiv preprint
O. Topsakal and J. B. Harper. Benchmarking large
arXiv:2210.03057, 2022.
language model (llm) performance for game
W. Shi, Z. Hu, Y. Bin, J. Liu, Y. Yang, S.-K. Ng,
playing via tic-tac-toe. Electronics, 13(8):1532,
L. Bing, and R. K.-W. Lee. Math-llava: Boot2024.

20

Mastering Board Games by External and Internal Planning with Language Models

J. Tromp. The fhourstones benchmark. URL

https://tromp.github.io/c4/fhour.
html.
C. F. Tsai, X. Zhou, S. S. Liu, J. Li, M. Yu, and
H. Mei. Can large language models play text
games well? current state-of-the-art and open
questions. arXiv preprint arXiv:2304.02868,
2023a.

L. Wang, C. Ma, X. Feng, Z. Zhang, H. Yang,
J. Zhang, Z. Chen, J. Tang, X. Chen, Y. Lin,
et al. A survey on large language model based
autonomous agents. Frontiers of Computer Science, 18(6):186345, 2024e.
X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi,
S. Narang, A. Chowdhery, and D. Zhou. Selfconsistency improves chain of thought reasoning in language models. arXiv preprint
arXiv:2203.11171, 2022.

C. F. Tsai, X. Zhou, S. S. Liu, J. Li, M. Yu, and
H. Mei. Can large language models play
text games well? current state-of-the-art and Y. Wang, S. Zhao, Z. Wang, H. Huang, M. Fan,
Y. Zhang, Z. Wang, H. Wang, and T. Liu.
open questions, 2023b. URL https://arxiv.
Strategic chain-of-thought: Guiding accurate
org/abs/2304.02868.
reasoning in llms through strategy elicitaM. Turpin, J. Michael, E. Perez, and S. Bowtion, 2024f. URL https://arxiv.org/abs/
man. Language models donâ€™t always say what
2409.03271.
they think: unfaithful explanations in chain-ofthought prompting. Advances in Neural Infor- J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia,
E. Chi, Q. V. Le, D. Zhou, et al. Chain-of-thought
mation Processing Systems, 36, 2024.
prompting elicits reasoning in large language
P. VeliÄkoviÄ‡, C. Perivolaropoulos, F. Barbero,
models. Advances in neural information processand R. Pascanu. softmax is not enough
ing systems, 35:24824â€“24837, 2022.
(for sharp out-of-distribution). arXiv preprint
S. Wu, L. Zhu, T. Yang, S. Xu, Q. Fu, Y. Wei, and
arXiv:2410.01104, 2024.
H. Fu. Enhance reasoning for large language
models in the game werewolf, 2024a. URL
D. Wang, Z. Ye, F. Fang, and L. Li. Cooperative
https://arxiv.org/abs/2402.02330.
strategic planning enhances reasoning capabilities in large language models, 2024a. URL
X. Wu, Y. Shen, C. Shan, K. Song, S. Wang,
https://arxiv.org/abs/2410.20007.
B. Zhang, J. Feng, H. Cheng, W. Chen, Y. Xiong,
and D. Li.
Can graph learning improve
H. Wang, S. Feng, T. He, Z. Tan, X. Han, and
planning
in
LLM-based
agents?
In The
Y. Tsvetkov. Can language models solve graph
Thirty-eighth Annual Conference on Neural
problems in natural language? Advances in NeuInformation Processing Systems, 2024b. URL
ral Information Processing Systems, 36, 2024b.
H. Wang, J. Xu, S. Xie, R. Wang, J. Li, Z. Xie,
B. Zhang, C. Xiong, and X. Chen. M4u: Evaluating multilingual understanding and reasoning for large multimodal models, 2024c. URL
https://arxiv.org/abs/2405.15638.
K. Wang, J. Pan, W. Shi, Z. Lu, M. Zhan, and H. Li.
Measuring multimodal mathematical reasoning with math-vision dataset. arXiv preprint
arXiv:2402.14804, 2024d.
L. Wang, W. Xu, Y. Lan, Z. Hu, Y. Lan, R. K.-W.
Lee, and E.-P. Lim. Plan-and-solve prompting:
Improving zero-shot chain-of-thought reasoning by large language models. arXiv preprint
arXiv:2305.04091, 2023.

https://openreview.net/forum?id=
bmoS6Ggw4j.
Y. Wu, J. Liu, X. Bu, J. Liu, Z. Zhou, Y. Zhang,
C. Zhang, Z. Bai, H. Chen, T. Ge, et al. Conceptmath: A bilingual concept-wise benchmark for measuring mathematical reasoning
of large language models. arXiv preprint
arXiv:2402.14660, 2024c.
J. Xie, R. Zhang, Z. Chen, X. Wan, and G. Li.
Whodunitbench: Evaluating large multimodal
agents via murder mystery games. In The
Thirty-eight Conference on Neural Information
Processing Systems Datasets and Benchmarks
Track, 2024a. URL https://openreview.
net/forum?id=qmvtDIfbmS.

21

Mastering Board Games by External and Internal Planning with Language Models

Y. Xie, A. Goyal, W. Zheng, M.-Y. Kan, T. P. Lillicrap, K. Kawaguchi, and M. Shieh. Monte
carlo tree search boosts reasoning via iterative preference learning, 2024b. URL https:
//arxiv.org/abs/2405.00451.
S. Xiong, A. Payani, R. Kompella, and F. Fekri.
Large language models can learn temporal reasoning. arXiv preprint arXiv:2401.06853, 2024.
C. Yang, X. Wang, J. Jiang, Q. Zhang, and
X. Huang. Evaluating world models with llm
for decision making, 2024a. URL https://
arxiv.org/abs/2411.08794.

in LLMs. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024. URL https://openreview.
net/forum?id=GN2qbxZlni.
D. Zhang, J. Li, X. Huang, D. Zhou, Y. Li, and
W. Ouyang. Accessing gpt-4 level mathematical olympiad solutions via monte carlo tree
self-refine with llama-3 8b. arXiv preprint
arXiv:2406.07394, 2024a.
E. Zhang, V. Zhu, N. Saphra, A. Kleiman, B. L.
Edelman, M. Tambe, S. M. Kakade, and
E. Malach. Transcendence: Generative models can outperform the experts that train
them, 2024b. URL https://arxiv.org/
abs/2406.11741.

L. Yang, Z. Yu, T. Zhang, S. Cao, M. Xu, W. Zhang,
J. E. Gonzalez, and B. Cui. Buffer of thoughts:
Thought-augmented reasoning with large language models, 2024b. URL https://arxiv. H. Zhang, J. Da, D. Lee, V. Robinson, C. Wu,
W. Song, T. Zhao, P. Raja, D. Slack, Q. Lyu,
org/abs/2406.04271.
et al. A careful examination of large language
S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran,
model performance on grade school arithmetic.
K. Narasimhan, and Y. Cao. React: SynergizarXiv preprint arXiv:2405.00332, 2024c.
ing reasoning and acting in language models.
Y. Zhang, S. Mao, T. Ge, X. Wang, A. de Wynter,
arXiv preprint arXiv:2210.03629, 2022.
Y. Xia, W. Wu, T. Song, M. Lan, and F. Wei.
Llm as a mastermind: A survey of strategic
S. Yao, D. Yu, J. Zhao, I. Shafran, T. Griffiths,
reasoning with large language models. arXiv
Y. Cao, and K. Narasimhan. Tree of thoughts:
preprint arXiv:2404.01230, 2024d.
Deliberate problem solving with large language
models. Advances in Neural Information ProY. Zhang, Y. Yuan, and A. C.-C. Yao. On the
cessing Systems, 36, 2024.
diagram of thought, 2024e. URL https://
arxiv.org/abs/2409.10038.
X. Ye and G. Durrett. The unreliability of explanations in few-shot prompting for textual reason- Z. Zhang, A. Zhang, M. Li, and A. Smola. Autoing. Advances in neural information processing
matic chain of thought prompting in large lansystems, 35:30378â€“30392, 2022.
guage models, 2022. URL https://arxiv.

org/abs/2210.03493.
E. Zelikman, Y. Wu, J. Mu, and N. D. Goodman.
Star: Bootstrapping reasoning with reasoning, Z. Zhang, A. Zhang, M. Li, H. Zhao, G. Karypis,
2022. URL https://arxiv.org/abs/2203.
and A. Smola. Multimodal chain-of-thought
14465.
reasoning in language models. arXiv preprint
arXiv:2302.00923, 2023.
E. Zelikman, G. Harik, Y. Shao, V. Jayasiri,
N. Haber, and N. D. Goodman. Quiet-star: Lan- Z. Zhao, W. S. Lee, and D. Hsu. Large language
guage models can teach themselves to think
models as commonsense knowledge for largebefore speaking, 2024. URL https://arxiv.
scale task planning. Advances in Neural Infororg/abs/2403.09629.
mation Processing Systems, 36, 2024.
Z. Zeng, Y. Liu, Y. Wan, J. Li, P. Chen, J. Dai,
Y. Yao, R. Xu, Z. Qi, W. Zhao, L. Shen, J. Lu,
H. Tan, Y. Chen, H. Zhang, Z. Shi, B. Wang,
Z. Guo, and J. Jia. MR-ben: A meta-reasoning
benchmark for evaluating system-2 thinking

A. Zhou, K. Yan, M. Shlapentokh-Rothman,
H. Wang, and Y.-X. Wang. Language agent
tree search unifies reasoning acting and planning in language models, 2024. URL https:
//arxiv.org/abs/2310.04406.

22

Mastering Board Games by External and Internal Planning with Language Models

D. Zhou, N. SchÃ¤rli, L. Hou, J. Wei, N. Scales,
X. Wang, D. Schuurmans, C. Cui, O. Bousquet,
Q. Le, et al. Least-to-most prompting enables
complex reasoning in large language models.
arXiv preprint arXiv:2205.10625, 2022.
C. Ziems, W. Held, O. Shaikh, J. Chen, Z. Zhang,
and D. Yang. Can large language models transform computational social science? Computational Linguistics, 50(1):237â€“291, 2024.

23

Mastering Board Games by External and Internal Planning with Language Models

External MCTS: Additional Results

1700

Internal Elo

1650
1600
1550
1500
1450
MAV-MCTS (mean scoring)
MAV-MCTS (max scoring)

1400
1350

100

250

500

1000

Number of simulations

2000

Figure 10 | Performance of scoring methods in MCTS among a tournaments between all MCTS agents,
various levels of Stockfish, and basic MCTS. The y-axis shows the internal Elo of each agent with basic
MCTS set to 0 internal Elo.

External MCTS: Algorithm Details
In this section, we describe the terminology and pseudo-code for external MCTS.
Notation:
â€¢ ğ‘– âˆˆ {0, 1}: denotes the active player; e.g., in chess, 0 for white, 1 for black
â€¢ ğ‘€ : number of MCTS simulations
â€¢ ğ‘ ğ‘¡ : a string description of a state at step ğ‘¡ ; e.g., a FEN in chess
â€¢ ğ‘ğ‘¡ : an action at step ğ‘¡
â€¢ ğ‘‡ ( ğ‘ ğ‘¡ âˆ’1 , ğ‘ğ‘¡ âˆ’1 ) = ğ‘ ğ‘¡ : a (deterministic) transition function
â€¢ ğ’‚ğ‘¡ğ¿ = ( ğ‘1ğ‘¡ , . . . , ğ‘ğ‘¡ğ¿ ( ğ‘ ğ‘¡ ) ): a list of legal actions at step ğ‘¡ ; note that ğ’‚ğ‘¡ğ¿ is state dependent, but we omit
dependency for the simplicity of notation
â€¢ N0 : a root node; stores internal objects
â€“ an active player N0 ( ğ‘–) âˆˆ {0, 1}
â€“ a string description of the initial state N0 ( ğ‘ ) = ğ‘ 0
â€“ a list of legal actions N0 ( ğ’‚ğ¿ ) = ğ’‚0ğ¿
â€¢ ğ‘„ ( ğ‘– ) ( ğ‘ ğ‘¡ , ğ‘ğ‘¡ ): a state-action value from the perspective of player ğ‘– in state ğ‘ ğ‘¡ given action ğ‘ğ‘¡
â€¢ ğ‘¸ ( ğ‘– ) ( ğ‘ ğ‘¡ , ğ’‚ğ‘¡ğ¿ ) = ( ğ‘„ ( ğ‘– ) ( ğ‘ ğ‘¡ , ğ‘1ğ‘¡ ) , . . . , ğ‘„ ( ğ‘– ) ( ğ‘ ğ‘¡ , ğ‘ğ‘¡ğ¿ ( ğ‘ ğ‘¡ ) )): a state-action value from the perspective of player
ğ‘– in state ğ‘ ğ‘¡ for all legal moves ğ’‚ğ‘¡ğ¿
â€¢ ğ‘ƒ ( ğ‘ ğ‘¡ , ğ‘ğ‘¡ ) = â„™( ğ‘ğ‘¡ | ğ‘ ğ‘¡ ): a prior probability of action ğ‘ğ‘¡ in state ğ‘ ğ‘¡
â€¢ ğ‘· ( ğ‘ ğ‘¡ , ğ’‚ğ‘¡ğ¿ ) = ( ğ‘ƒ ( ğ‘ ğ‘¡ , ğ‘1ğ‘¡ ) , . . . , ğ‘ƒ ( ğ‘ ğ‘¡ , ğ‘ğ‘¡ğ¿ ( ğ‘ ğ‘¡ ) )): a prior distribution, i.e., a distribution over all legal moves
ğ’‚ğ‘¡ğ¿ in state ğ‘ ğ‘¡
â€¢ Nğ‘¡ : a node at step ğ‘¡ > 0; stores internal objects
â€“ an active player Nğ‘¡ ( ğ‘–) = 1 âˆ’ Nğ‘¡ âˆ’1 ( ğ‘–)

24

Mastering Board Games by External and Internal Planning with Language Models

â€“ a string description of a state Nğ‘¡ ( ğ‘ ) âˆˆ { ğ‘ ğ‘¡ = ğ‘‡ ( ğ‘ ğ‘¡ âˆ’1 , ğ‘ğ‘¡ âˆ’1 ) , Non e}
â€“ a list of legal actions Nğ‘¡ ( ğ’‚ğ¿ ) âˆˆ { ğ’‚ğ‘¡ğ¿ , Non e} in state ğ‘ ğ‘¡
â€“ a cumulative value Nğ‘¡ (ğ‘‰ ( ğ‘– ) ( ğ‘ )) â‰¥ 0 from childâ€™s perspective ğ‘– = Nğ‘¡ ( ğ‘–)
â€“ a visit count Nğ‘¡ ( ğ‘ ( ğ‘ , ğ‘)) = ğ‘ ( ğ‘ ğ‘¡ âˆ’1 , ğ‘ğ‘¡ âˆ’1 ) â‰¥ 0 given the parent state ğ‘ ğ‘¡ âˆ’1 and action ğ‘ğ‘¡ âˆ’1
â€“ a prior probability Nğ‘¡ ( ğ‘ƒ ( ğ‘ , ğ‘)) = ğ‘ƒ ( ğ‘ ğ‘¡ âˆ’1 , ğ‘ğ‘¡ âˆ’1 ) â‰¥ 0 given the parent state ğ‘ ğ‘¡ âˆ’1 and action ğ‘ğ‘¡ âˆ’1
â€¢ MAV: a model that supports a multi-action value interface
â€“ ( ğ’‚0ğ¿ , ğ‘¸ ( ğ‘– ) ( ğ‘ 0 , ğ’‚0ğ¿ )) = M AV ( ğ‘ 0 ): a state evaluator; returns a list of legal moves ğ’‚0ğ¿ and associated
state-action values ğ‘¸ ( ğ‘– ) ( ğ‘ 0 , ğ’‚0ğ¿ ) for the state ğ‘ 0 in the root node N0 ; notice that the state
evaluator is only necessary for the root node
â€“ ( ğ‘ ğ‘¡ , ğ’‚ğ‘¡ğ¿ , ğ‘¸ ( ğ‘– ) ( ğ‘ ğ‘¡ , ğ’‚ğ‘¡ğ¿ )) = M AV ( ğ‘ ğ‘¡ âˆ’1 , ğ‘ğ‘¡ âˆ’1 ): a state-action evaluator; for a given state-action
parent tuple ( ğ‘ ğ‘¡ âˆ’1 , ğ‘ğ‘¡ âˆ’1 ) returns the child state ğ‘ ğ‘¡ = ğ‘‡ ( ğ‘ ğ‘¡ âˆ’1 , ğ‘ğ‘¡ âˆ’1 ), a list of childâ€™s legal actions
ğ’‚ğ‘¡ğ¿ and the associated state-action values ğ‘¸ ( ğ‘– ) ( ğ‘ ğ‘¡ , ğ’‚ğ‘¡ğ¿ ) from childâ€™s perspective ğ‘– = Nğ‘¡ ( ğ‘–)
Algorithm 2 E x pan d (Nğ‘¡ âˆ’1 , ğ‘· )
1: Input: Parent node Nğ‘¡ âˆ’1 , prior ğ‘·
2: Output: Non e
3: for ğ‘ğ‘¡ âˆ’1 âˆˆ Nğ‘¡ âˆ’1 ( ğ’‚ ğ¿ ) do

Create an empty child node Nğ‘¡
5:
Connect parent node Nğ‘¡ âˆ’1 and a child node Nğ‘¡ with edge (Nğ‘¡ âˆ’1 , ğ‘ğ‘¡ âˆ’1 )
6:
Initialize child node:
7:
Nğ‘¡ ( ğ‘–) â† 1 âˆ’ Nğ‘¡ âˆ’1 ( ğ‘–)
8:
Nğ‘¡ ( ğ‘ ) â† Non e
9:
Nğ‘¡ ( ğ’‚ğ¿ ) â† Non e
10:
Nğ‘¡ (ğ‘‰ ( ğ‘– ) ( ğ‘ )) â† 0
11:
ğ‘  â† Nğ‘¡ âˆ’1 ( ğ‘ ) , ğ‘ â† ğ‘ğ‘¡ âˆ’1
12:
Nğ‘¡ ( ğ‘ ( ğ‘ , ğ‘)) â† 0
13:
Nğ‘¡ ( ğ‘ƒ ( ğ‘ , ğ‘)) â† ğ‘ƒ ( ğ‘ , ğ‘)
14: end for
15: return
4:

External Engines and Game Data
Stockfish For chess and Chess960 we used the open source engine Stockfish 16 (Source Code Avalible
on Github) for both annotations and as opponents in our internal Elo calculations. We compiled all
Stockfish builds from source, using clang++, with the following compile flags -O3 -DIS_64BIT
-DUSE_PTHREADS -mprefer-vector-width=128 for all builds. We ran Stockfish over a wide
array of hardware using two different configurations, for older hardware we added -DUSE_POPCNT
-DUSE_SSSE3 -DUSE_SSE41 -march=westmere -msse4.2 and for newer hardware we added
-DUSE_AVX2 -DUSE_PEXT -march=haswell. These builds usually give us between 350k-700k
nodes per second for single threaded runs of stockfish â€“ bench 4096 1 130000 default
nodes.
Ext-BoN (Ruoss et al., 2024) showed that a small (270M-parameter) transformer can play Blitz
chess on Lichess at an Elo of 2895 against humans (i.e., Grandmaster level). They created a large-scale
dataset of 10 million chess games with legal move and value annotations (15 billion data points)
provided by Stockfish 16, the state-of-the-art chess engine. They then trained Transformers via

25

Mastering Board Games by External and Internal Planning with Language Models

Algorithm 3 S i m u l at ion (Nğ‘¡ âˆ’1 , M AV , ğ‘˜)
1: Input: Parent node Nğ‘¡ âˆ’1 , multi-action value model M AV, top ğ‘˜ values
2: Output: Non e
3: ğ‘ ğ‘¡ âˆ’1 â† Nğ‘¡ âˆ’1 ( ğ‘ )
4: ğ‘ğ‘¡ âˆ’1 â† Se l ec t(Nğ‘¡ âˆ’1 )
5: Nğ‘¡ â† Mov e - to - C h i l d(Nğ‘¡ âˆ’1 , ğ‘ğ‘¡ âˆ’1 )
6: if Nğ‘¡ ( ğ‘ ) is Non e then

( ğ‘ ğ‘¡ , ğ’‚ğ‘¡ğ¿ , ğ‘¸ ( ğ‘– ) ( ğ‘ ğ‘¡ , ğ’‚ğ‘¡ğ¿ )) = M AV ( ğ‘ ğ‘¡ âˆ’1 , ğ‘ğ‘¡ âˆ’1 ) from childâ€™s perspective ğ‘– = Nğ‘¡ ( ğ‘–)
8:
ğ‘· ( ğ‘ ğ‘¡ , ğ’‚ğ‘¡ğ¿ ; ğ‘¸ ( ğ‘– ) , ğ‘˜) â† Equation (1)
9:
Expan d (Nğ‘¡ , ğ‘· )
10:
Nğ‘¡ ( ğ‘ ) â† ğ‘ ğ‘¡
11:
Nğ‘¡ ( ğ’‚ğ¿ ) â† ğ’‚ğ‘¡ğ¿
12:
ğ‘„ âˆ— = maxğ‘ğ‘¡ âˆˆ ğ’‚ğ‘¡ğ¿ ğ‘„ ( ğ‘– ) ( ğ‘ ğ‘¡ , ğ‘ğ‘¡ )
13:
Backp ropagat e (Nğ‘¡ , ğ‘„ âˆ— )
14: else
15:
Simul at ion (Nğ‘¡ , M AV)
16: end if
17: return
7:

Algorithm 4 Se l ec t (Nğ‘¡ âˆ’1 )
1: Input: Parent node Nğ‘¡ âˆ’1
2: Output: Action ğ‘âˆ— determined by PUCT
3: Access child nodes values from parentâ€™s perspective and compute PUCT; if tied select randomly
4: ğ‘– = Nğ‘¡ âˆ’1 ( ğ‘–)
5: ğ‘  = Nğ‘¡ âˆ’1 ( ğ‘ )
6: ğ‘ â€² = Nğ‘¡ ( ğ‘ )
7: ğ’‚ ğ¿ = Nğ‘¡ âˆ’1 ( ğ’‚ ğ¿ )
8: ğ‘ ( ğ‘ ) =
9:

Ã

ğ‘ âˆˆ ğ’‚ ğ¿ Nğ‘¡ ( ğ‘ ( ğ‘ , ğ‘))

âˆš
Nğ‘¡ (ğ‘‰ ( ğ‘– ) ( ğ‘ â€² ) )
ğ‘ (ğ‘ )
âˆ—
ğ´ â† arg maxğ‘ âˆˆ ğ’‚ğ¿ Nğ‘¡ ( ğ‘ ( ğ‘ ,ğ‘ ) ) + ğ‘puct Â· Nğ‘¡ ( ğ‘ƒ ( ğ‘ , ğ‘)) Â· 1+Nğ‘¡ ( ğ‘ ( ğ‘ ,ğ‘ ) )

10: if | ğ´âˆ— | > 1 then
11:

ğ‘âˆ— â† RAND( ğ´âˆ— )

12: else
13:

ğ‘âˆ— â† ğ´âˆ—

14: end if
15: return ğ‘âˆ—

Algorithm 5 Bac k p ropagat e (Nğ‘¡ , ğ‘„ )
1: Input: Child node Nğ‘¡ , state-action value ğ‘„
2: Output: Non e
3: while Nğ‘¡ â‰  N0 do

Nğ‘¡ (ğ‘‰ ( ğ‘– ) ( ğ‘ )) â† Nğ‘¡ (ğ‘‰ ( ğ‘– ) ( ğ‘ )) + ğ‘„
5:
ğ‘  = Nğ‘¡ âˆ’1 ( ğ‘ ) , ğ‘ = Nğ‘¡ âˆ’1 ( ğ‘)
6:
Nğ‘¡ ( ğ‘ ( ğ‘ , ğ‘)) â† Nğ‘¡ ( ğ‘ ( ğ‘ , ğ‘)) + 1
7:
Nğ‘¡ â† Mov e - to - Par e n t(Nğ‘¡ )
8: end while
9: return
4:

26

Mastering Board Games by External and Internal Planning with Language Models

Algorithm 6 Mov e - to - C h i l d(Nğ‘¡ âˆ’1 , ğ‘ğ‘¡ âˆ’1 )
1: Input: Parent node Nğ‘¡ âˆ’1 , parent action ğ‘ğ‘¡ âˆ’1
2: Output: Child node Nğ‘¡
3: Move from a parent node Nğ‘¡ âˆ’1 to a child node Nğ‘¡ via the edge (Nğ‘¡ âˆ’1 , ğ‘ğ‘¡ âˆ’1 )
4: return Nğ‘¡

Algorithm 7 Mov e - to - Par e n t (Nğ‘¡ )
1: Input: Child node Nğ‘¡
2: Output: Parent node Nğ‘¡ âˆ’1
3: Move from a child node Nğ‘¡ to a parent node Nğ‘¡ âˆ’1
4: return Nğ‘¡ âˆ’1

Algorithm 8 F i nal Mov e Se l ec t ion (N0 )
1: Input: Root node N0

2: Output: Best final action ğ‘âˆ— given search statistics
3: Determine most visited child; if tied find maximum estimated value
4: ğ‘  â† N0 ( ğ‘ )
5: ğ’‚ ğ¿ â† N0 ( ğ’‚ ğ¿ )

6: ğ´âˆ— â† arg maxğ‘ âˆˆ ğ’‚ğ¿ N1 ( ğ‘ ( ğ‘ , ğ‘))
7: if | ğ´âˆ— | > 1 then

Access child nodes values from rootâ€™s perspective and find maximum estimated value
9:
ğ‘– â† N0 ( ğ‘–)
10:
ğ‘ â€² â† N1 ( ğ‘ )
N1 (ğ‘‰ ( ğ‘– ) ( ğ‘ â€² ) )
11:
ğ‘âˆ— â† arg maxğ‘ âˆˆ ğ´âˆ— N ( ğ‘ ( ğ‘ ,ğ‘ ) )
1
12: else
13:
ğ‘âˆ— â† ğ´âˆ—
14: end if
15: return ğ‘âˆ—
8:

supervised learning to predict action-values, i.e., no explicit search, and showed that their models
achieve highly non-trivial generalization (e.g., solving challenging chess puzzles). They thus showed
that a remarkably good approximation of Stockfishâ€™s search-based algorithm can be distilled into
large-scale transformers via supervised learning, but that perfect distillation is still beyond reach.

Chess/Chess960 Game Training Data Chess positions were drawn from two sources: Lichess
and TCEC. TCEC data consisted of all 34,291 standard chess games played in seasons 1-25, from
which 4,204,025 unique positions were extracted. Lichess standard rated chess games were drawn
from the months October 2014, March 2017, and January 2020 for a total of 58,705,532 games. All
19,758,457 Chess960 games played on Lichess from August 2013 to June 2024 were included. All
positions were annotated with Stockfish 16 for a duration of 1 second, with the exception of those
drawn from TCEC and Lichess October 2014 games, where 15 seconds of analysis time was used.

Hex Training Data 12,279,645 Hex games were generated by self-play with neurobenzene (Gao
and Pawlewicz), run with search time set to 10 seconds. In 10% of positions, a random move was
chosen instead to encourage exploration of an otherwise narrow state space distribution.

27

Mastering Board Games by External and Internal Planning with Language Models

Connect Four Training Data 2,458,293 Connect Four games were generated using an ğœ€-greedy
strategy with ğœ€ = 40%. Greedy actions were chosen uniformly among all moves that yielded the best
attainable minimax value, computed using the Fhourstones solver (Tromp).

Games league
We conduct planning and reasoning experiments in games, similar to GameBench (Costarelli et al.,
2024) and GTBench (Duan et al., 2024). Games present an opportunity to develop and test approaches
in a controllable and safe environment, with ground truth that is readily verifiable through existing
game models. We use OpenSpiel (Lanctot et al., 2019) as the game engine to drive our evaluations.
Decision-making with language agents inseparably fuses a prompting strategy, the language model,
and the response interpretation. The language model essentially interfaces with a second modality
â€“ the game, for which prompting encodes the state observation as language input, and response
interpretation maps from language output back to action. The language model performs the response
computation in language space. Any given triplet can be evaluated on specific states, or by playing
against another triplet or against benchmark bots (e.g. Random, search or reinforcement learning
based agents) that operate directly on the game representation.
We evaluate agents offline, through fixed datasets of states, and online, in pairwise matches against
reference opponents. Metrics such as action-choice quantiles and action-value regret that we compute
for each dataset across agents are directly comparable, and exhibit different skill dimensions (tasks),
such as doing well in opening, mid-game or endgame positions. In contrast, online matches directly
measure relative playing strength as wins/draws/losses, and may traverse different distributions of
states for each match-up of opponents. While the eventual objective is to increase playing strength
across a wide range of opponents, the offline evaluation on datasets helps characterise each policy.
A tournament of multiple opponents results in square agent-vs-agent matrices indicating the number
of wins and draws (losses inferable from transposed of wins) for each pair. Elo (Elo, 1967) finds the
best single-dimensional rating for each contender, such that their mutual win probabilities are best
explained by a ratio of their exponentiated rating. This implies a ranking, i.e., an ordinal preference
over each of the contenders. We report average winrates (treating draws as half wins) for matches,
and Elo for tournaments.

Out-of-Distribution test set positions
We programmatically generate out-of-distribution (OOD) positions by randomly sampling the number
and type of pieces on the board while ensuring compliance with several rules such as: kings cannot be
in check simultaneously, or the position is not a checkmate. Examples of OOD positions are shown in
Figure 11. Notice that some positions are not reachable via a legal sequence of moves from the initial
chess position, which showcases that MAV generalizes outside of the human games it was trained on
by achieving near 100% accuracy as reported in Table 3.

Related work
Planning and reasoning with language models is both an open challenge and an active area of research.
Given how widely relevant planning is as a capability to support decision making in complex, dynamic,
and open-ended domains (Rasal and Hauer, 2024), there is, perhaps unsurprisingly, a correspondingly
wide variety of planning approaches that have been explored to date, mapping onto these unmet
needs. The remainder of this section first outlines general reasoning benchmarks, and then goes

28

Mastering Board Games by External and Internal Planning with Language Models

NZ0M0Z0Z
7
Z0ZnZpZ0
6
0O0JpZ0m
5
s0OpZ0Zp
4
0Z0O0s0o
3
apZQOpOB
2
0Z0ZPZRZ
1
Z0Z0Z0Zk
8

a

b

c

d

e

f

g

h

0Z0Z0Z0Z
7
J0Z0Z0m0
6
nOpZpZ0Z
5
O0O0S0Z0
4
0ZPZ0ZNZ
3
jbZBLplP
2
pO0OpZ0a
1
Z0s0Z0Z0
8

a

b

c

d

e

f

g

h

0Z0Z0M0Z
lPo0Z0an
6
PS0M0M0l
5
ZBl0O0oP
4
koRZQL0Z
3
o0ZKOBm0
2
pOPm0Z0Z
1
a0Zra0sR
8
7

a

b

c

d

e

f

g

h

0Z0Z0Z0Z
J0ZQZ0Z0
6
0Z0Z0Z0Z
5
mpZkO0oP
4
NZ0m0o0A
3
s0opM0S0
2
0O0Z0Z0Z
1
Z0ZRZ0Z0
8
7

a

b

c

d

e

f

g

h

Figure 11 | A sample from out-of-distribution set to test the legal move rate and state tracking accuracy
of the MAV model. The squares next to the diagrams indicate active players.

into game benchmarks in particular. Next, we outline adjacent works of in-context reasoning, which
shares with internal search that plans are expanded by the language model itself, and reasoning as
search, which sketches a broader scope around approaches similar to external search. Finally, we
give pointers to specific works as chess, which takes a prominent role in our evaluation.

Benchmarking reasoning Reasoning tasks can be divided into tasks of common sense reasoning (Cui et al., 2024; Zhao et al., 2024), structured reasoning (Wang et al., 2024b), mathematical
reasoning (Chen et al., 2024a; Gu et al., 2024; Shao et al., 2024b; Tang et al., 2024b; Wang et al.,
2024d; Wu et al., 2024c; Zhang et al., 2024c), algorithmic reasoning (Markeeva et al., 2024), symbolic
reasoning (Fang et al., 2024), causal reasoning (Jin et al., 2024), temporal reasoning (Xiong et al.,
2024), meta-reasoning (Zeng et al., 2024) and strategic reasoning (Zhang et al., 2024d). Multimodal
reasoning may span any subset of these categories, with the added complexity of incorporating
cross-modal tasks (Chia et al., 2024; Haresh et al., 2024; Kil et al., 2024; Shao et al., 2024a; Shi
et al., 2024; Xie et al., 2024a). There are also multilingual benchmarks (Bang et al., 2023; Wang
et al., 2024c), aimed at evaluating model reasoning across languages. Large language models can

29

Mastering Board Games by External and Internal Planning with Language Models

approach these reasoning tasks directly, or with help of external tools (Lu et al., 2024; Paranjape
et al., 2023) or planners and solvers (Borazjanizadeh and Piantadosi, 2024; Dagan et al., 2023), and
their performance can be evaluated in typical scenarios or puzzles (Giadikiaroglou et al., 2024; Li
et al., 2024b), which tend to be more complex and more out-of-distribution. These evaluations can
either be general or more domain-specific (Guo et al., 2024; Nori et al., 2024). There have also been
efforts aimed at evaluating the utility of language models as world models, from the perspective of
decision making and planning (Yang et al., 2024a).
Reasoning in games Strategic reasoning (Gandhi et al., 2023), which naturally arises in game
play, is particularly challenging due to a dynamic environment and the uncertainty in predicting the
actions of the adversary. It is goal-oriented, interactive, adaptive, and requires a level of predictive
ability. Outside of games, this type of reasoning may be valuable in economic (Horton, 2023; Li et al.,
2023) and social (Gandhi et al., 2024a; Ziems et al., 2024) applications. The focus in this paper
is primarily on strategic planning in games, which have been suggested as a an important set of
benchmarks for developing and evaluating strategic reasoning (Costarelli et al., 2024; Duan et al.,
2024; Tsai et al., 2023a) in language models, not unlike their historical role in the development
of AI previously (Ensmenger, 2012; McCarthy, 1990; Schaul et al., 2011), and sequential decision
making in particular. Two particular game benchmarks that have been concurrently developed with
this paper are GameBench (Costarelli et al., 2024) and GTBench (Duan et al., 2024). Both adopt the
same agentification of language models for games: an agent comprises a prompting strategy that
generates a prompt from a game state, an LLM that generates the response, and an interpretation of
the textual response as a game action. The resulting agent can be evaluated by playing matches in
specific games, like tic-tac-toe, either against benchmark RL agents or other language model agents.
This makes it possible to draw conclusions on strategic reasoning abilities from the pairwise winrates
or rankings derived from Elo-rating the tournament results. Our specific evaluation is delineated in
the experimental section of this paper.
Reasoning in-context It has been demonstrated that large language models encode a certain level
of intrinsic reasoning ability in the natural language space, especially when prompted to do so (Plaat
et al., 2024), which can be solicited by chain-of-thought (CoT) techniques (Kojima et al., 2022; Shi
et al., 2022; Wang et al., 2024f; Wei et al., 2022; Zhang et al., 2023), least-to-most prompting (Zhou
et al., 2022), plan-and-solve prompting (Wang et al., 2023), self-ask structured prompting (Press
et al., 2022), multi-step problem decomposition and plan execution (Nguyen and Shareghi, 2024),
few-shot prompting (Brown et al., 2020; Gao et al., 2020; Gramopadhye et al., 2024), and many-shot
prompting (Agarwal et al., 2024), among others. Yet, CoT methods are not always reliable, may
express inconsistent reasoning steps or traces that do not actually correspond to how the decisions are
reached (Turpin et al., 2024; Ye and Durrett, 2022), may not be robust to typographical errors (Gan
et al., 2024), and may not be the best approach for planning in more complex domains, though it
has recently been shown that they can in principle handle e.g. dynamic programming tasks (Feng
et al., 2024a). Without a world model capable of tracking state transitions, it is hard to evaluate
the long-term consequences of earlier decisions (Hao et al., 2023). These emerging capabilities are
heavily influenced by the data itself, as intermediate reasoning steps are only helpful in case of locally
structured data, consisting of local clusters of variables with strong mutual influence (Prystawski
et al., 2024). CoT rationales can be optimised through task-oriented feedback (Lee et al., 2024).
Informative thought templates can be distilled from and reused across a number of different tasks,
and compiled in a buffer of thoughts (Yang et al., 2024b). Diversity in CoT generations matters,
and generating a larger number of diverse reasoning chains can lead to better performance (Zhang
et al., 2022). Reasoning traces can be interleaved with actions, as in ReAct (Yao et al., 2022). Self-

30

Mastering Board Games by External and Internal Planning with Language Models

consistency techniques present another avenue for further improving model performance (Wang
et al., 2022). To be useful, CoT prompts may need to be specific to their problem class (Stechly
et al., 2024). Synthetic data generation can be used to improve the quality and the coverage of
demonstrations (Shao et al., 2023). CoT has also been considered in the multimodal context (Lu
et al., 2022; Mitra et al., 2024) and whiteboard-of-thought was recently shown to be helpful, in
encouraging reasoning across modalities (Menon et al., 2024). Language models are capable of
improving their performance on some types of problems merely by the extra computation granted
by the additional tokens, even when those are filter tokens rather than structured or interpretable
CoT (Pfau et al., 2024). It is possible to consider instead generating internal thoughts, as rationales
at the token level for predicting future tokens, demonstrated by the Quiet-STAR method (Zelikman
et al., 2024). This method belongs to a class of approaches that utilise self-improvement or self-play
for boosting the planning and reasoning ability in language models, which has become a widely
used approach (Aksitov et al., 2023; Chen et al., 2024c; Hosseini et al., 2024; Saab et al., 2024;
Singh et al., 2024; Tian et al., 2024; Zelikman et al., 2022). Self-improvement approaches often
rely on the intrinsic ability for self-correction in LLMs, yet self-correcting reasoning without explicit
external feedback remains difficult (Huang et al., 2024). Given that CoT reasoning is ultimately
greedy and may have problems when there are many options worth exploring (Saparov and He,
2022), this was a motivation for exploring alternative, more structured search methods. Dynamic
prompt-conditional strategy selection may help identify the best strategic approach to each particular
problem (Parekh et al., 2024). Multi-agent approaches can be used to further develop this particular
point, decoupling strategic reasoning and more specific step-wise planning (Wang et al., 2024a).
Planning can also be done over associated knowledge graphs (Chen et al., 2024b), and graph learning
may help with the overall planning capabilities in the more general case (Wu et al., 2024b). Finally,
some problems may lend themselves more naturally to backward planning, potentially necessitating
a custom approach (Ren et al., 2024).
Reasoning as search Testing LLMs on especially sequential decision-making problems requires
agentification, with a variety of proposed approaches to use LLMs as or within game agents (Hu
et al., 2024b,c; Tsai et al., 2023b; Wu et al., 2024a). MCTS-based planning, and self-play, have
been also been explored in this context (Light et al., 2024; Putta et al., 2024; Rebstock et al., 2024).
Rather than relying on individual reasoning chains, it is possible to instead construct a tree of
thoughts (Long, 2023; Yao et al., 2024) a graph of thoughts (Besta et al., 2024), or a diagram of
thoughts (Zhang et al., 2024e). There has also been recent interest in utilizing MCTS with LLMs for
complex reasoning tasks (Zhang et al., 2024a). The everything-of-thoughts (XoT) (Ding et al., 2023)
approach utilizes MCTS for incorporating external domain knowledge into thoughts, as does Tree-ofTraversals (Markowitz et al., 2024), enabling language models to effectively reason over facts encoded
in knowledge graphs. Tree search has also proved valuable in completing realistic web tasks (Koh
et al., 2024), as well as code generation (Li et al., 2024a), mathematical reasoning (Jiang et al., 2024),
and tabular data handling (Ji et al., 2024). While most approaches rely on the prompted LLM itself
acting as a value function, therefore bounding the utility of search by the quality of that value function
approximation (Chen et al., 2024d), and searching at low depths, it is also possible to use tree search
with a learned value function in guiding LLM decoding, as was demonstrated in TS-LLM (Feng et al.,
2024b). Language Agent Tree Seatch (LATS) (Zhou et al., 2024) incorporates MCTS along with
self-reflection and memory, achieving strong performance on programming tasks. MCTS has also been
used to improve LLM reasoning ability through iterative preference optimization (Xie et al., 2024b).
When applied in the language generation space, MCTS can be seen as a likelihood-based search on
the direct preference optimization (DPO) policy (Rafailov et al., 2024). MCTS can also be used to
strategically plan over the the problem-solving trajectories for zero-shot in-context learning (Tang et al.,
2024a). Self-Rewarding Tree Search based on MCTS has been used for improving domain-specific

31

Mastering Board Games by External and Internal Planning with Language Models

retrieval-augmented generation (Hu et al., 2024a). In terms of other search strategies, Searchformer
has recently been proposed, a Transformer model that was trained to mimic the dynamics of the
ğ´âˆ— algorithm, showing good performance on Sokoban puzzles and in maze navigation. Algorithm
distillation has recently been proposed as a method for distilling reinforcement learning algorithms
into neural networks, facilitating in-context reinforcement learning with language models (Laskin
et al., 2022).
Reasoning in chess As our paper explores the application of planning with language models to chess,
which has been a separate topic of interest, here we also briefly review the current state of art and the
approaches and evaluations relevant to chess in particular. Chess-GPT (Feng et al., 2023) was a custom
model, integrating chess playing and language ability, that was shown to offer notable improvements
in board state tracking and playing strength over a number of LLM baselines. More recently, it was
shown to be possible to train Transformer models to Grandmaster-level strength in chess (Ruoss et al.,
2024), without search, looking just a single move ahead. There have been recent advances involving
diffusion models as well (Anonymous, 2024). By training specialized Transformer models for chess,
it has been shown that the models may demonstrate transcendence (Zhang et al., 2024b), at least
at lower playing strengths â€“ where the resulting model may outperform any of the human players
from the training set, as the model learns a policy that effectively averages out some of the mistakes
human players make. This is in line with the findings showing that weak-to-strong supervision is
possible (Burns et al., 2023). It is also possible to develop skill-compatible models (Hamade et al.,
2024), as skill compatibility is ultimately distinct from playing strength. There is also an interest in
developing models that can act as chess coaches (Menon, 2023). There is evidence that chess-playing
Transformers can learn and internalize look-ahead in relation to future optimal moves (Jenner et al.,
2024). An in-depth analysis of chess playing strength of the most prominent language models (Acher,
2023) had identified gpt-3.5-turbo-instruct as the strongest model at the time, capable of completing
longer games and winning against non-trivial Stockfish difficulty levels, yet still failing to finish a
non-negligible percentage of games due to illegal moves.

32

Mastering Board Games by External and Internal Planning with Language Models

Featured games
Chess
We start games from the opening book described
in Table 4. A
symbol indicates the last move
loaded from the opening book after which the
agents continue the game. Once the game is finished, the agents reverse the colors and play the
game with the same opening position. A square
next to the diagrams represents the side to play.
All games, except for Game 0 and Game 1, use
Stockfish with 2 seconds of thinking time per
move. Further details can be found in Section
â€œExternal Engines and Game Dataâ€. We use MAVâ€“
MCTS to represent the external search MAV with
mean scoring, MAVâ€“MCTS - max scoring is selfexplanatory, and MAVâ€“IS represents the internal
search MAV .

Game 0
A win against human player
Long-term piece activity
Date: 2024-07-24
White: Luka RimaniÄ‡, 1990 FIDE Elo
Black: MAV - max scoring
Result: 0 â€“ 1
Online PGN: https://lichess.org/eU15TjI0
1. e4 e6 2. d4 d5 3. Nc3 dxe4 4. Nxe4 Nf6 5.
Bg5 Be7 6. Bxf6 gxf6 7. g4

rmblkZ0s
7
opo0apZp
6
0Z0Zpo0Z
5
Z0Z0Z0Z0
4
0Z0ONZPZ
3
Z0Z0Z0Z0
2
POPZ0O0O
1
S0ZQJBMR

Bc6 16. Rg1 Rc8 17. Kb1 f4 18. Ne2 Be4+ 19.
Ka1 Bf3 20. Rb1 Rd8 21. Nxf4 Rxd4 22. Bb5+
Kf8 23. Ne2 Rd2 24. Rbc1 Rxh5 MAV regains
the sacrificed pawn with interest after 17
moves; despite the even material, White is
losing 25. Rc8+ Rd8 26. Rxd8+ Bxd8 27. Nc3
Rxh2 28. Rf1 Bb6 29. Nd1 Ke7 30. a3 f5 31. Kb1
Kf6 32. Kc2 a6 33. Bc4 Bd4 34. b4 b5 35. Bd3
e5 36. Kd2

0Z0Z0Z0Z
Z0Z0Z0Z0
6
pZ0Z0j0Z
5
ZpZ0opZ0
4
0O0a0Z0Z
3
O0ZBZbZ0
2
0Z0J0O0s
1
Z0ZNZRZ0
8
7

a

b

c

d

e

f

g

h

36...Bxd1 MAV is not afraid to enter the
endgame with opposite-colored bishops. 37.
Kxd1 e4 38. Be2 Bxf2 39. a4 bxa4 40. Bxa6 a3
41. Bc4 Be3 42. b5 Rd2+ 43. Ke1 Rb2 44. b6
Bxb6 45. Kd1 Ke5 46. Ke1 Be3 47. Kd1 f4 48.
Ke1 f3 49. Kd1 Kd4 50. Bf7 Kc3 51. Ba2 Rxa2
52. Rxf3 exf3 53. Ke1 Ra1# 0 â€“ 1

8

a

b

c

d

e

f

g

Game 1
The first win against Stockfish
Unclear long-term attack
Date: 2024-05-31
White: MAVâ€“MCTS , development version
Black: Unoptimized Stockfish ( 50K-90K nps)
Result: 1 â€“ 0
Online PGN: https://lichess.org/gVNnuSWn
1. d4 f5 2. Bg5 g6
3. e3 Bg7 4. Qd2 h6 5.
Bh4 c5 6. f4 Qb6

h

7...h5 MAV sacrifices a pawn for the long-term
piece activity 8. gxh5 f5 9. Ng3 c5 10. Nf3 Nc6
11. c3 cxd4 12. Nxd4 Nxd4 13. Qxd4 Qxd4 MAV
exchanges queens, but the bishop pair on the
open board and rooksâ€™ activity secure the
advantage for Black 14. cxd4 Bd7 15. O-O-O

33

Mastering Board Games by External and Internal Planning with Language Models

rmbZkZns
7
opZpo0a0
6
0l0Z0Zpo
5
Z0o0ZpZ0
4
0Z0O0O0A
3
Z0Z0O0Z0
2
POPL0ZPO
1
SNZ0JBMR
8

a

b

c

d

e

f

g

h

7. Nc3 A prelude to a pawn sacrifice. cxd4
8. exd4 Bxd4 MAVâ€“MCTS sacrifices a central
pawn and likely loses castling rights for a
compensation that is unclear to a human eye.
9. Nf3 Be3 10. Qd3 Nc6 11. Nd5 Qxb2 12. Qxe3

rZbZ0jns
opZpo0Z0
6
0ZnZ0Zpo
5
Z0ZNZpZ0
4
0Z0Z0O0A
3
Z0Z0LNZ0
2
PZPZ0JPO
1
l0Z0ZBZR
8
7

a

b

c

d

e

f

g

h

14. Bb5 MAVâ€“MCTS sacrifices a rook! Qxh1 15.
Bxc6 g5 16. fxg5 dxc6

rZbZ0jns
opZ0o0Z0
6
0ZpZ0Z0o
5
Z0ZNZpO0
4
0Z0Z0Z0A
3
Z0Z0LNZ0
2
PZPZ0JPO
1
Z0Z0Z0Zq
8
7

rZbZkZns
opZpo0Z0
6
0ZnZ0Zpo
5
Z0ZNZpZ0
4
0Z0Z0O0A
3
Z0Z0LNZ0
2
PlPZ0ZPO
1
S0Z0JBZR
8
7

a

b

c

d

e

f

g

h

12...Qxa1+ MAVâ€“MCTS proceeds with sacrificing an exchange with a check 13. Kf2 Kf8

a

b

c

d

e

f

g

h

17. g6 A nail in the coffin â€“ Black is lost despite
being two rooks up Qa1 18. Bxe7+ Kg7 19. Bd6
cxd5 20. Qe8 Be6 21. Qxe6 (game terminated
by early termination). MAVâ€“MCTS â€™s playing
style resembles games of players such as GM
Mikhail Tal and IM Rashid Nezhmetdinov
who sacrificed material for unclear long-term
attacks. Note that the game was played with
limited resources during the development
phase, which affected the evaluation of some
moves. 1 â€“ 0

Game 2
Restricting opponentâ€™s activity
Date: 2024-11-12
White: MAVâ€“MCTS( ğ‘€ = 2000) - max scoring
Black: Stockfishâ€“L20
Result: 1 â€“ 0

34

Mastering Board Games by External and Internal Planning with Language Models

Online PGN: https://lichess.org/xLsaUTr8
1. e4 e5 2. f4 exf4 3. Nf3 g5 4. Nc3 Nc6 5. g3 g4
6. Nh4 f3 7. d4 Bb4 8. d5 Qe7
9. Be3 Ne5
10. Nf5 Bxc3+ 11. bxc3 Qa3

rZbZkZns
7
opopZpZp
6
0Z0Z0Z0Z
5
Z0ZPmNZ0
4
0Z0ZPZpZ
3
l0O0ApO0
2
PZPZ0Z0O
1
S0ZQJBZR
8

a

b

c

d

e

f

g

h

12. d6 MAVâ€“MCTS sacrificed the second pawn
to paralyze Blackâ€™s queenside. White will
further rapidly develop its pieces by attacking
the exposed black queen. Qxc3+ 13. Kf2 Nf6
14. Bd3 cxd6 15. Bd4 Qc6

rZbZkZ0s
opZpZpZp
6
0Zqo0m0Z
5
Z0Z0mNZ0
4
0Z0APZpZ
3
Z0ZBZpO0
2
PZPZ0J0O
1
S0ZQZ0ZR
8
7

a

b

c

d

e

f

g

h

16. a4 At the first glance, this move aims to
stop b5 and queenside development, but the
move also has a much deeper idea Rg8 17.
Ra3 Now the real idea behind 16.a4 becomes
apparent; MAVâ€“MCTS wants to activate its
rook via c3! Rg5 18. Qd2 Rxf5 A knight
paralyzes the entire black position, so Black
desperately sacrifices a rook for some activity.
19. exf5 Ne4+ 20. Bxe4 Qxe4 21. Re1 Qxf5 22.
Rd3 f6 23. Bb2 Kd8 24. Rxd6 b6 25. Bxe5 fxe5
26. Rd5 Qf6 27. Rexe5 Kc7 28. Re3 h6 29. Rc3+

Kb8 30. a5 Qe7 31. Qf4+ d6 32. Re3 Qc7 33.
Rxd6 Kb7 34. Qe4+ Kb8 35. Rc6 Bd7 36. Rxc7
Kxc7 37. Qxa8 bxa5 38. Qxa7+ Kc6 39. Rc3+
Kd6 40. Rd3+ Kc6 41. Qxd7+ Kb6 42. Rd6+
Kc5 43. Rc6+ Kb4 44. Qb7+ Ka3 45. Qb3#
1â€“0

Game 3
Precise pawn endgame
Date: 2024-11-12
White: MAVâ€“MCTS( ğ‘€ = 2000) - max scoring
Black: Stockfishâ€“L18
Result: 1 â€“ 0
Online PGN: https://lichess.org/Q486S86Y
1. e4 Nc6 2. d4 d5 3. Nc3 Nf6 4. e5 Nd7
5.
Nce2 e6 6. c3 f6 7. Nf4 Qe7 8. exf6 Nxf6 9. Be2
Qd7 10. Nf3 Bd6 11. O-O O-O 12. Nd3 Ne4 13.
Nfe5 Bxe5 14. Nxe5 Nxe5 15. dxe5 a5 16. Be3
b6 17. Qc2 Bb7 18. Bd3 h6 19. Rad1 Qe8 20. f3
Nc5 21. Bh7+ Kh8 22. Bg6 Qe7 23. Qd2 Kg8
24. Bb1 Ba6 25. Qc2 g5 26. Bxc5 bxc5 27. Qg6+
Qg7 28. Qxe6+ Qf7

rZ0Z0skZ
Z0o0ZqZ0
6
bZ0ZQZ0o
5
o0opO0o0
4
0Z0Z0Z0Z
3
Z0O0ZPZ0
2
PO0Z0ZPO
1
ZBZRZRJ0
8
7

a

b

c

d

e

f

g

h

29. Qxh6 MAVâ€“MCTS correctly sacrifices an
exchange to ruin Blackâ€™s kingside. Bxf1 30.
Kxf1 c6 31. Re1 Rae8 32. Bg6 Qg7 33. Qxg7+
Kxg7 34. Bxe8 Rxe8 35. e6 Kf6 36. e7 c4 37. b3
cxb3 38. axb3 Rxe7 39. Rxe7 Kxe7 40. Ke1 Kd6
41. g3 c5 42. h4 gxh4 43. gxh4 Kd7 44. h5 Ke8
45. Kd1 Kf8

35

Mastering Board Games by External and Internal Planning with Language Models

0Z0Z0j0Z
Z0Z0Z0Z0
6
0Z0Z0Z0Z
5
o0opZ0ZP
4
0Z0Z0Z0Z
3
ZPO0ZPZ0
2
0Z0Z0Z0Z
1
Z0ZKZ0Z0
8
7

a

b

c

d

e

f

g

h

46. f4 MAVâ€“MCTS plays the only winning
move in a seemingly simple pawn endgame.
The idea is to timely set up the f5-h5 pawn
formation. Kg7 47. f5 Kg8 48. Kc2 Kh7 49. f6
Kh6 50. Kb1 Kh7 51. Kc2 Kh6 52. Kd3 Kh7 53.
Ke3 Kh8 54. Kf4 Kg8 55. Kf5 d4 56. cxd4 Kh7
57. f7 Kg7 58. Ke6 c4 59. Ke7 Kh6 60. f8=Q+
Kh7 61. Kf6 cxb3 62. Qg7# 1 â€“ 0

Game 4
Building a fortress
Date: 2024-11-12
White: Stockfishâ€“L18
Black: MAVâ€“MCTS( ğ‘€ = 2000) - max scoring
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/a5Rqsg8s
1. d4 Nf6 2. Bg5 Ne4 3. Bf4 c5 4. f3 Qa5+ 5. c3
Nf6 6. d5 Qb6 7. e4
Qxb2 8. Nd2 Qxc3 9.
Bc7 g6 10. Rc1 Qe3+ 11. Ne2 d6 12. Rb1 Nfd7
13. f4

rmbZka0s
opAnopZp
6
0Z0o0ZpZ
5
Z0oPZ0Z0
4
0Z0ZPO0Z
3
Z0Z0l0Z0
2
PZ0MNZPO
1
ZRZQJBZR
8
7

a

b

c

d

e

f

g

h

13...Na6 Prelude to a queen sacrifice. 14. Rb3
Qxb3 MAVâ€“MCTS sacrifices a queen hoping its
position is solid enough to hold back Whiteâ€™s
pieces activity. 15. axb3 Nxc7 16. Qa1 Rg8 17.
h4 Bg7 18. Nc3 b6 19. h5 Bb7 20. hxg6 hxg6
21. Rh7 Bd4 22. Qc1 a6 23. Nc4 Nf6 24. Rh3
Bxc3+ 25. Rxc3 Nxe4 26. Re3 f5 27. Nxb6 Nxd5
28. Nxa8 Nxe3 29. Qxe3 Bxa8 30. g4 Rh8 31.
gxf5 gxf5 32. b4 cxb4 33. Qb6 Kd7 34. Qd4 Rc8
35. Bxa6 Rc1+ 36. Ke2 Nc5 37. Bb5+ Bc6 38.
Qxb4 Ra1 39. Bc4 Ra4 40. Qc3 Kc7 41. Kd1 Kb6
42. Qc1 e6 43. Qb2+ Kc7 44. Qc3 Bd7 45. Ke1
Ne4 46. Qc1 Ra5 47. Bf1+ Bc6 48. Be2 Nc5 49.
Qc3 Ra4 50. Qg3 Ra1+ 51. Bd1 Kb6 52. Qc3
Rb1 53. Qd4 Kc7 54. Qg7+ Kb6 55. Qe7 Ba4
56. Qxd6+ Bc6 57. Qd8+ Kb7 58. Qf8 Nd7 59.
Qa3 Kb6 60. Qd3 Rc1 61. Kd2 Rc5 62. Qb3+
Kc7 63. Be2 Bd5 MAVâ€“MCTS builds a fortress.
64. Qb4 Bh1 65. Ba6 Bc6 66. Ke2 Kd8 67. Bc4
Bd5 68. Ba6 Bc6 69. Kd2 Bh1 70. Ke3 Bd5 71.
Bb5 Rc7 72. Ba4 Ra7 73. Qd4 Rc7 74. Qh8+
Ke7 75. Kf2 Kd6 76. Qg7 Bh1 77. Bb5 Bc6 78.
Qd4+ Ke7 79. Qb4+ Kd8 80. Bc4 Bd5 81. Bd3
Ke8 82. Ke3 Rb7 83. Qd4 Be4 84. Qh8+ Ke7 85.
Bc4 Rc7 86. Qg7+ Kd6 87. Bb5 Bc6 88. Bc4 Bd5
89. Ba6 Be4 90. Qa1 Rc5 91. Kf2 Bd5 92. Be2
Bc6 93. Kg3 Rd5 94. Qa3+ Rc5 95. Bf1 Kc7 96.
Be2 Bd5 97. Kh4 Kc8 98. Qb2 Kc7 99. Kg3 Bc4
100. Bf3 Bd5 101. Bd1 Rc4 102. Bh5 Bc6 103.
Qg7 Rc1 104. Qe7 Rc3+ 105. Kf2 Rc2+ 106.
Kg1 (threefold repetition). MAVâ€“MCTS proves
its decision to sacrifice a queen on move 14
was correct. 1/2 â€“ 1/2

Game 5
Masterful middlegame maneuvering
Date: 2024-11-12
White: MAVâ€“MCTS( ğ‘€ = 2000) - max scoring
Black: Stockfishâ€“L18
Result: 1 â€“ 0
Online PGN: https://lichess.org/iJa6Nxlq
1. e4 e6 2. d4 d5 3. e5 c5 4. c3 Ne7 5. Nf3 Nec6
6. Bd3 Be7 7. O-O Nd7 8. Re1 f6 9. exf6
Nxf6 10. dxc5 a5 11. c4 O-O 12. Nc3 dxc4 13.
Bxc4 Qxd1 14. Rxd1 Bxc5 15. Na4 Ba7 16. Be3
Nd5 17. Bxa7 Nxa7 18. Nc5 Nc6 19. Ng5 Re8
20. Rac1 Nb6 21. Bb5 a4 22. a3 Ra5 23. Bxc6
bxc6 24. Nge4 h6 25. Rd6 Rb5 26. Rd2 Kh7 27.
Nd6 Rd8 28. Nce4 Rd5 29. Rxc6 Rxd2 30. Nxd2

36

Mastering Board Games by External and Internal Planning with Language Models

Na8 31. N6c4 Bb7 32. Rxe6 Rd4 33. f3 Bd5

nZ0Z0Z0Z
7
Z0Z0Z0ok
6
0Z0ZRZ0o
5
Z0ZbZ0Z0
4
pZNs0Z0Z
3
O0Z0ZPZ0
2
0O0M0ZPO
1
Z0Z0Z0J0
8

a

b

c

d

e

f

g

h

34. Rd6 After dominating the key squares by
masterful maneuvers, MAVâ€“MCTS correctly
evaluates that entering a rook versus minor
pieces endgame is decisive. Rxc4 35. Nxc4
Bxc4 36. Rc6 Bd5 37. Ra6 Nc7 38. Rxa4 Kg8 39.
Ra7 Ne6 40. b4 Kf8 41. b5 Ke8 42. b6 Nd8 43.
Rxg7 Nf7 44. a4 Kd7 45. a5 Kc6 46. Rg6+ Kb7
47. h4 h5 48. Rf6 Bc4 49. Rf5 Nd8 50. Rxh5 Bf7
51. Rh8 Nc6 52. Rh7 Ne5 53. f4 Nd7 54. Rxf7
Kc6 55. Rxd7 Kxd7 56. a6 Kd6 57. b7 Kc7 58.
h5 Kd6 59. b8=Q+ Kc6 60. a7 Kd5 61. a8=Q+
Kc5 62. Qa4 Kd5 63. Qe5# 1 â€“ 0

Game 6
Stunning piece sacrifice
Date: 2024-11-14
White: MAVâ€“MCTS( ğ‘€ = 100)
Black: Stockfishâ€“L18
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/pTgHnsqV
1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5.
Nc3 a6 6. Be3 e6 7. f3 Be7 8. Qd2 b5 9. g4 Nfd7
10. O-O-O Ne5 11. g5 b4 12. Na4 O-O 13. f4
Ned7 14. Qxb4 Nc5 15. h4 Bd7

rm0l0skZ
Z0Zbapop
6
pZ0opZ0Z
5
Z0m0Z0O0
4
NL0MPO0O
3
Z0Z0A0Z0
2
POPZ0Z0Z
1
Z0JRZBZR
8
7

a

b

c

d

e

f

g

h

16. Nxe6 MAVâ€“MCTS sacrifices a knight on a
square defended by three pieces. Nxe6 17. f5
d5 It is still unclear what MAVâ€“MCTS gained
for a sacrificed piece. 18. Qb3 Bxa4 19. Qxa4
Bc5 20. Kb1 Bxe3 21. fxe6 d4 22. exf7+ Kh8 23.
e5 Rxf7 24. Bg2 Raa7 25. Rhe1 Bf2 26. e6 Rf5
27. Re2 Re7 28. Rf1 Qf8 29. Qb4 Nd7 30. Bh3
d3 31. cxd3 Bc5 32. Rxf5 Bxb4

0Z0Z0l0j
Z0Zns0op
6
pZ0ZPZ0Z
5
Z0Z0ZRO0
4
0a0Z0Z0O
3
Z0ZPZ0ZB
2
PO0ZRZ0Z
1
ZKZ0Z0Z0
8
7

a

b

c

d

e

f

g

h

33. exd7 It was likely better to grab the queen,
but the position remain unclear. Qd8 34. Rfe5
Rxe5 35. Rxe5 Be7 36. d4 h6 37. g6 a5 38. Re1
Kg8 39. d5 Qb6 40. h5 Kf8 41. a3 a4 42. Rc1
Qa5 43. d6 Bd8 44. Rc8 Qe1+ 45. Ka2 Qe6+
46. Ka1 Qf6 47. Bg4 Qg5 48. Bf5 Qf6 49. Be6
Qf1+ 50. Ka2 Qa1+ 51. Kxa1 (stalemate).

37

Mastering Board Games by External and Internal Planning with Language Models

0ZRa0j0Z
7
Z0ZPZ0o0
6
0Z0OBZPo
5
Z0Z0Z0ZP
4
pZ0Z0Z0Z
3
O0Z0Z0Z0
2
0O0Z0Z0Z
1
J0Z0Z0Z0
8

a

b

c

d

e

f

g

h

Stunning end to an exciting game. 1/2 â€“ 1/2

Game 7
Exquisit active defense
Date: 2024-11-14
White: Stockfishâ€“L19
Black: MAVâ€“MCTS( ğ‘€ = 250)
Result: 0 â€“ 1
Online PGN: https://lichess.org/nyMarqhl
1. e4 c5 2. Nc3 Nc6 3. Nf3 g6 4. d4 cxd4 5. Nxd4
Bg7 6. Be3 d6 7. h3 Nf6 8. g4 O-O 9. g5 Ne8 10.
h4 Nc7 11. f4 e5 12. Nde2 f5
13. h5 fxe4 14.
Qd2 d5 15. O-O-O d4 16. hxg6 This is a start
of an attack where a cost of a mistake is an
immediate loss. dxc3 17. Qxc3 Qe8 18. Qb3+
Be6 19. Qxb7 Nd5 20. Bc5 Rb8 21. gxh7+ Kh8

0s0Zqs0j
oQZ0Z0aP
6
0ZnZbZ0Z
5
Z0Ano0O0
4
0Z0ZpO0Z
3
Z0Z0Z0Z0
2
POPZNZ0Z
1
Z0JRZBZR

0s0Z0l0Z
o0Z0Z0jP
6
0ZnZbZ0Z
5
Z0Zno0O0
4
0Z0ZpO0Z
3
Z0Z0Z0Z0
2
POPZNZ0Z
1
Z0JRZBZR
8
7

a

b

c

d

e

f

g

h

24. h8=R White finds an opportunity to
underpromote to a rook! Qxh8 25. Rxh8 Rxh8
26. f5 Ne3 27. fxe6 Nxd1 28. Kxd1 Rh1 After
the dust has settled, MAVâ€“MCTS has a decisive
advantage. 29. Ng3 Rg1 30. Nf5+ Kg6 31. e7
Kf7 32. g6+ Ke8 33. Ke1 Nd4 34. Ne3 Kxe7 35.
c3 Nf3+ 36. Ke2 Rxg6 37. Nc4 Kf6 38. Ne3 Kg5
39. Kf2 Rd6 40. Be2 Nh4 41. b4 Rd2 42. a4 Nf5
43. Nxf5 Kxf5 44. Ke3 Rc2 45. c4 Ra2 46. c5
Rxa4 47. b5 Ra3+ 48. Kd2 e3+ 49. Kc2 Ra2+
50. Kd3 Kf4 51. c6 Rd2+ 52. Kc3 Rd8 53. Kb4
Kg3 54. Ka5 Kf2 55. Bc4 Rd4 56. b6 Rxc4 57.
bxa7 e2 58. a8=Q e1=Q+ 59. Kb6 Qb4+ 60.
Ka7 Qa5+ 61. Kb7 Rb4+ 62. Kc8 Qxa8+ 63.
Kd7 Qg8 64. Ke7 Qb8 65. Kf6 e4 66. c7 Qg8 67.
Kf5 Qf7+ 68. Kg5 Qd7 69. c8=Q Qxc8 70. Kh5
Rb1 71. Kh4 Rg1 72. Kh5 Qh8# 0 â€“ 1

8

Game 8

7

The strength of bishop pair
Date: 2024-11-14
White: MAVâ€“MCTS( ğ‘€ = 500)
Black: Stockfishâ€“L18
Result: 1 â€“ 0
Online PGN: https://lichess.org/pHzcWtOd
1. d4 f5 2. g3 Nf6 3. Bg2 e6 4. Nf3 Be7 5. c4
O-O 6. O-O d6 7. Nc3 Qe8
8. b4 Kh8 9. Qc2
Nbd7 10. a4 c6 11. a5 e5 12. b5 a6 13. bxc6
bxc6 14. dxe5 dxe5

a

b

c

d

e

f

g

h

22. Qxg7+ White sacrifices a queen as the last
resource. Kxg7 23. Bxf8+ Qxf8

38

Mastering Board Games by External and Internal Planning with Language Models

rZbZqs0j
Z0Zna0op
6
pZpZ0m0Z
5
O0Z0opZ0
4
0ZPZ0Z0Z
3
Z0M0ZNO0
2
0ZQZPOBO
1
S0A0ZRJ0
8
7

a

b

c

d

e

f

g

h

15. Qxf5 MAVâ€“MCTS grabs a pawn without
fearing numerous discovered attacks. Nd5
16. Qc2 Nxc3 17. Qxc3 e4 18. Ng5 Already on
move 15, MAVâ€“MCTS needed to assess the
exchange sacrifice correctly. Bf6 19. Qa3 Bxa1
20. Qxa1 Nf6 21. Ba3 Rg8 22. Bb2 h6 23. Bxf6
hxg5 24. Bxg5 Bg4 25. Re1 Qh5 26. h4 Bxe2 27.
Bxe4 Bxc4 28. Qd4 Bb3 29. Bxc6 Rab8 30. Kh2
Qg6 31. Bd7 Rgf8 32. Re5 Qc2 33. Be3 Qd1 34.
Rg5 Qxd4 35. Bxd4

0s0Z0s0j
Z0ZBZ0o0
6
pZ0Z0Z0Z
5
O0Z0Z0S0
4
0Z0A0Z0O
3
ZbZ0Z0O0
2
0Z0Z0O0J
1
Z0Z0Z0Z0
8
7

a

b

c

d

e

f

g

h

A bishop pair dominates the board even in
the endgame. 35...Rf7 36. Bf5 Kg8 37. Bb6
Rf6 38. g4 Rfxb6 39. axb6 Rxb6 40. Bd3 Bd1
41. Bc4+ Kf8 42. Kg3 Rf6 43. Bd5 a5 44. Rh5
Ra6 45. Rh8+ Ke7 46. h5 Rd6 47. Be4 Rd8 48.
Rh7 Kf6 49. f4 Rg8 50. g5+ Ke6 51. h6 gxh6
52. Rxh6+ Ke7 53. Ra6 a4 54. g6 Be2 55. Rxa4
Kf6 56. Rb4 Rxg6+ 57. Bxg6 Kxg6 58. Rb1 Bc4
59. Rb4 Be6 60. Rb1 Kf6 61. Rb4 Bc8 62. Rb1
Kf5 63. Rb8 Bd7 64. Rb7 Ba4 65. Re7 Kg6 66.

Re2 Kf5 67. Ra2 Bb3 68. Ra7 Be6 69. Rb7 Bc4
70. Rg7 Be6 71. Rb7 Bc4 72. Rd7 Kg6 73. Kf3
Kf5 74. Rg7 Bd3 75. Rh7 Be4+ 76. Ke3 Bc6 77.
Rh3 Be8 78. Rh7 Bg6 79. Re7 Kf6 80. Rc7 Be8
81. Rc4 Bb5 82. Rc8 Bd7 83. Ra8 Bh3 84. Ra2
Kf5 85. Kf3 Kf6 86. Ra8 Ke6 87. Rc8 Kf6 88.
Rc4 Kf5 89. Kf2 Ke6 90. Rc2 Bf5 91. Rc7 Kd6
92. Rb7 Kd5 93. Kg2 Kc5 94. Rf7 Bd3 95. Kf3
Kc6 96. Kg4 Be2+ 97. Kh4 Bf1 98. f5 Bb5 99.
Re7 Bc4 100. Kg5 Bg8 101. Kg6 Kc5 102. Kg7
Bb3 103. Rd7 Kc6 104. Ra7 Kd5 105. Ra6 Ke4
106. Rb6 Bd5 107. Rd6 Ke5 108. Rxd5+ Kxd5
109. Kh6 Ke4 110. Kg5 Kd5 111. f6 Ke6 112.
Kg6 Kd6 113. f7 Ke7 114. Kg7 Kd7 115. f8=Q
Kc7 116. Qe7+ Kb6 117. Kg6 Kb5 118. Qa3 Kc4
119. Kf7 Kd4 120. Qc1 Ke4 121. Qg5 Kd4 122.
Qb5 Kc3 123. Kf6 Kd2 124. Qf1 Ke3 125. Kf5
Kd4 126. Qc1 Kd5 127. Qh6 Kc4 128. Qb6 Kd5
129. Qh6 Kc5 130. Qa6 Kb4 131. Qa2 Kc3 132.
Ke4 Kb4 133. Kf3 Kb5 134. Qa7 Kc6 135. Ke4
Kb5 136. Qa3 Kb6 137. Kd5 Kb7 138. Qa5 Kb8
139. Kc6 Kc8 140. Qc7# Note that MAVâ€“MCTS
was inefficient in delivering forced mates
because of a very low simulation budget. 1 â€“ 0

Game 9
Material quality over quantity
Date: 2024-11-14
White: Stockfishâ€“L19
Black: MAVâ€“MCTS( ğ‘€ = 500)
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/Mka8BrUO
1. d4 Nf6 2. c4 c5 3. d5 e5 4. Nc3 d6 5. e4 Be7
6. Nf3 Nbd7 7. g3 O-O 8. Bg2

rZbl0skZ
opZnapop
6
0Z0o0m0Z
5
Z0oPo0Z0
4
0ZPZPZ0Z
3
Z0M0ZNO0
2
PO0Z0OBO
1
S0AQJ0ZR
8
7

a

b

c

d

e

f

g

h

39

Mastering Board Games by External and Internal Planning with Language Models

8...b5 MAVâ€“MCTS plays a pawn sacrifice
similar to Benko gambit. 9. cxb5 a6 10. Bf1
Ne8 11. Nd2 f5 MAVâ€“MCTS proceeds with
shattering Whiteâ€™s pawn structure. 12. exf5

rZblnskZ
7
Z0Zna0op
6
pZ0o0Z0Z
5
ZPoPoPZ0
4
0Z0Z0Z0Z
3
Z0M0Z0O0
2
PO0M0O0O
1
S0AQJBZR
8

a

b

c

d

e

f

g

h

12...Nc7 13. a4 axb5 14. Nxb5 Nf6 15. Bc4
Bxf5 16. O-O Na6 17. f4 e4 Despite being a
pawn down, MAVâ€“MCTS has a compact pawn
structure without any weaknesses that offer
an active piece play. 18. Re1 Nb4 19. Ra3 Nd3
20. Re3 Nb4 21. Re2 Kh8 22. Nf1 Bg4 23. Rae3
Qe8 24. Qb3

rZ0Zqs0j
Z0Z0a0op
6
0Z0o0m0Z
5
ZNoPZ0Z0
4
PmBZpObZ
3
ZQZ0S0O0
2
0O0ZRZ0O
1
Z0A0ZNJ0
8
7

a

b

c

d

e

f

g

h

24...Qh5 For two moves in a row MAVâ€“MCTS
estimates that a bishop is a stronger piece
than a rook and declines to win an exchange.
25. Re1 Rfb8 26. Bd2 Nbxd5 27. Rxe4 Bf8 28.
R4e2 Nb6 29. Bf7 Qh3 30. Be6 Nxa4 31. Bxg4
Qxg4 32. Qf7 Qg6 33. Qxg6 hxg6 34. Nc7 Ra7
35. Ne6 Nxb2 36. Bc3 Nc4 37. Bxf6 gxf6 38. Rc1
d5 39. Rd1 Rd7 40. Rc2 Nb6 41. Rb1 Bd6 42.
Rcb2 Re8 43. Rxb6 Rxe6 44. Kf2 c4 45. Rc6 Rc7

46. Rbb6 Rxc6 47. Rxc6 Kg7 48. Kf3 Kf7 49.
Ne3 Bb8 50. Rc8 Rb6 51. Nxd5 Rb3+ 52. Ke4
f5+ 53. Kd4 c3 54. Kc4 Rb7 55. Nxc3 Ba7 56.
Nd5 Bg1 57. h3 Bh2 58. g4 fxg4 59. Rh8 Kg7 60.
Rh4 g3 61. Rg4 Rb2 62. Kc3 Rf2 63. Ne3 Rf3
64. Kd2 g2 65. Nxg2 Rxh3 66. Ke1 Bxf4 67. Kf2
g5 68. Nh4 Rxh4 69. Rxh4 gxh4 70. Ke1 h3 71.
Kf2 Bh2 72. Kf3 Bd6 73. Kf2 Bh2 74. Kf3 Bd6
75. Kf2 Bh2 (threefold repetition). This is a well
known draw because the queening square is
the opposite color of the bishop. 1/2 â€“ 1/2

Game 10
Exemplary advantage conversion
Date: 2024-11-14
White: MAVâ€“MCTS( ğ‘€ = 2000)
Black: Stockfishâ€“L19
Result: 1 â€“ 0
Online PGN: https://lichess.org/HLOwBsg9
1. d4 d5 2. c4 c6 3. Nf3 Nf6 4. e3 e6 5. Nc3 a6
6. c5 Nbd7 7. b4 a5
8. b5 g6 9. Be2 Bg7 10.
O-O h5 11. Rb1 O-O 12. Na4 Qe7 13. Ne5 Nxe5
14. dxe5 Ng4 15. Nb6 Rb8 16. f4 Bd7 17. Bxg4
hxg4 18. Qxg4 cxb5 19. Nxd7 Qxd7 20. Bb2
b6 21. cxb6 Rxb6 The material is equal, but
MAVâ€“MCTS has much more active bishop and
upper-hands for a kingside attack with the
minimal resources. 22. h4 Rc6 23. h5 b4 24.
Rf3 Rfc8 25. hxg6 fxg6 26. Qxg6 Qf7 27. Qg5
Qf5 28. Qxf5 exf5 29. Rg3 Kh7 The conversion
is not easy because MAVâ€“MCTS â€™s rooks are
seemingly deprived of any activity.

0ZrZ0Z0Z
Z0Z0Z0ak
6
0ZrZ0Z0Z
5
o0ZpOpZ0
4
0o0Z0O0Z
3
Z0Z0O0S0
2
PA0Z0ZPZ
1
ZRZ0Z0J0
8
7

a

b

c

d

e

f

g

h

30. Kf2 MAVâ€“MCTS finds a beautiful maneuver
which activates all its pieces at the cost of a

40

Mastering Board Games by External and Internal Planning with Language Models

pawn. Rc2+ 31. Kf3 R8c4 32. Rh1+ Kg8 33.
Bd4 Rxa2

0Z0Z0ZkZ
Z0Z0Z0a0
6
0Z0Z0Z0Z
5
o0ZpOpZ0
4
0orA0O0Z
3
Z0Z0OKS0
2
rZ0Z0ZPZ
1
Z0Z0Z0ZR
8
7

a

b

c

d

e

f

g

h

The endgame looks scary for White because of
the advanced Blackâ€™s pawns, but MAVâ€“MCTS
correctly evaluates that black king is too weak.
34. Rg5 Rd2 35. e6 Rdxd4 36. exd4 b3 37. g4
Rc3+ 38. Ke2 Kf8 39. e7+ Kxe7 40. Rxg7+ Kf6
41. Rb7 fxg4 42. Rh5 Rc4 43. Rxb3 Rxd4 44.
Rb6+ Kf7 45. Rh7+ Kg8 46. Rd7 Re4+ 47. Kd3
Rxf4 48. Ra7 Rf8 49. Rg6+ Kh8 50. Kd4 a4 51.
Rh6+ Kg8 52. Rg6+ Kh8 53. Ke5 d4 54. Rh6+
Kg8 55. Rg6+ Kh8 56. Ke6 Rf4 57. Rf6 Rf1 58.
Rxf1 Kg8 59. Ke5 g3 60. Rg1 d3 61. Rxg3+ Kh8
62. Kf5 d2 63. Ra8+ Kh7 64. Ra7+ Kh8 65. Rd7
d1=B 66. Rxd1 Kh7 67. Rh1# 1 â€“ 0

0s0s0Z0j
Z0l0Zpa0
6
0ZpZbZpo
5
o0Ano0Z0
4
PZ0ZNZPZ
3
ZBZ0ZPZ0
2
0OPZ0Z0O
1
ZKZRL0ZR
8
7

a

b

c

d

e

f

g

h

20. Ba3 MAVâ€“MCTS vacates c5 square for a
knight and estimates that the control over
a3-f8 diagonal is much more important than
the control over g1-a7 diagonal. Additionally,
it protects b2 square from any possible attack
along the b line. Nf4 21. Bxe6 Nxe6 22. h4
Rxd1+ 23. Qxd1 c5 24. Qd6 Qb7 25. Qd3 Qc6
26. g5 h5 27. Qc4 Qd7 28. Ka2 Rd8 29. Rf1 Qc8
30. Rf2 Rd4 31. Qb5 Qd8 32. Qc6 Rd1 33. Bxc5
Nxc5 34. Qxc5 Kh7 35. Re2 Rd5 36. Qc6 Rd7
37. Re3 Rc7 38. Qb6 Qd7 39. Qb5 Qh3 40. c4
Qxh4 41. c5 Qf4 42. Rd3 h4 43. Qxa5 Rc8 44.
Qa6 Rc7 45. Qb6 Rc8 46. Qb7 Rf8 47. c6 h3 48.
c7 h2 49. Rd8 h1=Q 50. c8=Q Rxd8 51. Qxd8

0Z0L0Z0Z
ZQZ0Zpak
6
0Z0Z0ZpZ
5
Z0Z0o0O0
4
PZ0ZNl0Z
3
Z0Z0ZPZ0
2
KO0Z0Z0Z
1
Z0Z0Z0Zq
8

Game 11
Controlling key squares
Date: 2024-11-12
White: MAVâ€“MCTS( ğ‘€ = 2000) - max scoring
Black: Stockfishâ€“L18
Result: 1 â€“ 0
Online PGN: https://lichess.org/l2F7vJ7q
1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3
g6 6. Be3 Bg7 7. f3 O-O 8. Qd2 Nc6 9. O-O-O
d5 10. Qe1 e5 11. Nxc6 bxc6 12. exd5 Nxd5 13.
Bc4 Be6 14. Kb1 Rb8
15. Ne4 Qc7 16. Bc5
Rfd8 17. g4 a5 18. a4 h6 19. Bb3 Kh8

7

a

b

c

d

e

f

g

h

51...Qh3 A long maneuvering phase of the
game results in a four queens endgame!
MAVâ€“MCTS is completely winning because of
a very weak black king. 52. Qbb8 Qe6+ 53.
b3 f5 54. gxf6 Bxf6 55. Qb7+ Be7 56. Qbxe7+
Qxe7 57. Qxe7+ Kh8 58. Qf6+ Kg8 59. Qxf4

41

Mastering Board Games by External and Internal Planning with Language Models

exf4 60. a5 g5 61. a6 Kg7 62. a7 Kf7 63. a8=Q
g4 64. Qd5+ Ke7 65. Qd6+ Kf7 66. Qf6+ Ke8
67. Nc5 gxf3 68. Qg7 f2 69. Qd7+ Kf8 70. Ne6+
Kg8 71. Qg7# 1 â€“ 0

Game 12
Exploiting opponentâ€™s aggressive play
Date: 2024-11-14
White: MAVâ€“MCTS( ğ‘€ = 2000)
Black: Stockfishâ€“L17
Result: 1 â€“ 0
Online PGN: https://lichess.org/0vDAbIW8
1. e4 e5 2. Nf3 Nc6 3. Bb5 a6 4. Ba4 Nf6 5.
O-O Be7 6. Re1 b5 7. Bb3 O-O 8. a4 b4 9. a5
d5
10. exd5 e4 11. dxc6 Black sacrifices
a knight and relies on aggressive piece play
with a possible kingside attack. Bd6 12. d4
MAVâ€“MCTS decides to immediately activate
its pieces by returning the sacrificed knight.
exf3 13. Qxf3 h6 14. h3 Rb8 15. Nd2 Rb5 16.
Nc4 Re8 17. Rxe8+ Qxe8

0ZbZqZkZ
Z0o0Zpo0
6
pZPa0m0o
5
OrZ0Z0Z0
4
0oNO0Z0Z
3
ZBZ0ZQZP
2
0OPZ0OPZ
1
S0A0Z0J0
8

Game 13
Well executed caveman attack
Date: 2024-11-14
White: MAVâ€“MCTS( ğ‘€ = 100)
Black: Stockfishâ€“L19
Result: 1 â€“ 01 â€“ 0
Online PGN: https://lichess.org/gvDiGfcP
1. e4 g6 2. d4 Bg7 3. Nc3 d6 4. Be3 a6 5. Qd2
b5 6. h4
h6 7. h5 b4 8. Nd5 c6 9. Nxb4 g5
10. Ne2 a5 11. Nd3 Nf6 12. f3 Qc7 13. Ng3 c5
14. c3 a4 15. Be2 O-O

rmbZ0skZ
Z0l0opa0
6
0Z0o0m0o
5
Z0o0Z0oP
4
pZ0OPZ0Z
3
Z0ONAPM0
2
PO0LBZPZ
1
S0Z0J0ZR
8
7

a

7

a

b

c

d

e

f

g

h

18. Bxh6 MAVâ€“MCTS enters a scary tactical
sequence. Rf5 19. Nxd6 cxd6 20. Qg3 Nh5 21.
Qe3 Qxc6 22. g4 Rf3 23. d5 Rxe3 24. dxc6 Rxh3
25. Bg5 Nf6 26. Bxf6 gxf6 27. Ra4 MAVâ€“MCTS
finishes the resulting winning endgame with
a nice rook lift. Kf8 28. Rxb4 Rh8 29. Rb8 Ke7
30. Bd5 Rg8 31. f3 Rg5 32. c4 Kd8 33. b4 Re5
34. Kf2 Kc7 35. Ra8 f5 36. f4 Rxd5 37. cxd5 Kd8
38. g5 Ke7 39. Rxc8 f6 40. Ke3 fxg5 41. fxg5 Kf7
42. Kf4 Ke7 43. Rg8 Kf7 44. Rc8 Kg7 45. Kxf5
Kh7 46. c7 Kg7 47. Rb8 Kf7 48. c8=Q Ke7 49.
Qb7# 1 â€“ 0

b

c

d

e

f

g

h

16. Bxg5 MAVâ€“MCTS sacrifices a bishop for a
devastating attack. hxg5 17. h6 Bh8 18. Qxg5+
Kh7 19. Nf5 Nh5 20. Rxh5 f6

rmbZ0s0a
Z0l0o0Zk
6
0Z0o0o0O
5
Z0o0ZNLR
4
pZ0OPZ0Z
3
Z0ONZPZ0
2
PO0ZBZPZ
1
S0Z0J0Z0
8
7

a

b

c

d

e

f

g

h

21. Qg7+ A stunning queen sacrifice â€“ the
cherry on top. Bxg7 22. hxg7+ Kg8 23. Rh8+
Kf7 24. Rxf8+ Ke6 25. Nxc5+ Qxc5 26. g8=Q+
Kd7 27. Rd8+ Kc7 28. Rxc8+ Kb6 29. dxc5+
Kb7 30. Bb5 Ra6 31. O-O-O Ka7 32. g3 a3 33.
Nxe7 d5 34. b3 d4 35. f4 Re6 36. Re8 d3 37.

42

Mastering Board Games by External and Internal Planning with Language Models

Qh8 f5 38. Bxd3 Rf6 39. Bc4 Re6 40. g4 Rxe4
41. Rh1 Rxc4 42. Nc8+ Kb7 43. Qg7+ Nd7 44.
bxc4 Kc6 45. Kb1 Kxc5 46. Kc1 Nb8 47. Qd4+
Kc6 48. Rf8 Nd7 49. c5 Nxf8 50. Re1 Nd7 51.
Re2 Kc7 52. g5 Kxc8 53. Qh8+ Kc7 54. g6 Nb8
55. Re1 Na6 56. Re7+ Kc6 57. Qa8+ Kb5 58.
g7 Nb8 59. c4+ Kxc4 60. Re1 Kb5 61. g8=Q
Kxc5 62. Rg1 Na6 63. Kd1 Kb5 64. Rh1 Nc7 65.
Rh5 Nxa8 66. Qd5+ Kb6 67. Qc4 Kb7 68. Qd5+
Kc8 69. Rxf5 Nb6 70. Qc5+ Kb7 71. Qc2 Nd5
72. Rxd5 Kb8 73. Re5 Kb7 74. Qf2 Kc7 75. Kc2
Kb8 76. f5 Kb7 77. Qe3 Kc7 78. Qg1 Kd8 79.
Qe3 Kc7 80. f6 Kc6 81. Kd2 Kb7 82. Kc2 Ka6
83. Qg1 Kb7 84. f7 Kc7 85. Kd3 Kd8 86. Qf1
Kc7 87. f8=Q Kb7 88. Kd2 Kc7 89. Qe2 Kc6 90.
Qe7 Kb6 91. Qb5# Note that MAVâ€“MCTS was
inefficient in delivering forced mates because
of the extremely low simulation budget. 1 â€“ 0

King in the center
Date: 2024-11-21
White: MAVâ€“IS(ğ‘ = 4, ğ‘‘ = 2)
Black: Stockfishâ€“L15
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/XVqKocbp
1. e4 e6 2. d4 d5 3. Nd2 Nf6 4. e5 Nfd7 5. Bd3
c5 6. c3 b5
7. Ne2 Ba6 8. a3 Nc6 9. Nf3
cxd4 10. cxd4 Qc8 11. b4 Bb7 12. O-O a5 13.
bxa5 Rxa5 14. Ng5 Be7 15. Bd2 Rxa3 16. Rxa3
Bxa3 17. Nf4 MAVâ€“IS starts a sequence that
sacrifices two central pawns. Nxd4 18. Qh5
Nxe5

0ZqZkZ0s
ZbZ0Zpop
6
0Z0ZpZ0Z
5
ZpZpm0MQ
4
0Z0m0M0Z
3
a0ZBZ0Z0
2
0Z0A0OPO
1
Z0Z0ZRJ0
8
7

b

c

d

e

f

0Z0Z0Z0s
Z0ZkZpMp
6
0Z0Z0Z0Z
5
ZblpL0Z0
4
0Z0Z0Z0Z
3
Z0Z0Z0Z0
2
0Z0A0OPO
1
Z0Z0Z0J0
8
7

a

Game 14

a

19. Ngxe6 MAVâ€“IS sacrifices a knight to keep
black king in the center. Nxe6 20. Bxb5+ Bc6
21. Nxe6 Bxb5 22. Re1 Bd6 23. Nxg7+ Kd7
24. Rxe5 Bxe5 25. Qxe5 MAVâ€“IS correctly
estimated that the vulnerable black king
and dark squares are worth the sacrificed
exchange. Qc5

g

b

c

d

e

f

g

h

26. h3 MAVâ€“IS plays a quite prophylactic
move which resolves a potential back rank
issues before proceeding with the attack. Ra8
27. Bf4 Bd3 28. Nh5 Rc8 29. Be3 d4 30. Nf6+
Kc6 31. Bxd4 Qd6 32. Qe3 Kb7 33. Be5 Qe6
34. Qd4 Rc4 35. Qb2+ Ka6 36. Qa3+ Kb6 37.
Qb3+ Kc5 38. Qb8 Rc1+ 39. Kh2 Rc2 40. Ng4
Bf5 41. Ne3 Rxf2 42. Qa7+ Kb5 43. Qb7+ Kc5
44. Qa7+ Kb4 45. Qb7+ Ka4 46. Qa7+ Kb4
47. Qb7+ Kc5 48. Qa7+ (threefold repetition).
1/2 â€“ 1/2

Game 15
Dominating the center
Date: 2024-11-21
White: Stockfishâ€“L10
Black: MAVâ€“IS(ğ‘ = 4, ğ‘‘ = 2)
Result: 0 â€“ 1
Online PGN: https://lichess.org/8a0RINHx
1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 e5 5.
Nb5 a6 6. Nd6+ Bxd6 7. Qxd6 Qf6 8. Qd1 Qg6
9. Nc3 Nge7
10. f4 d5 11. f5

h

43

Mastering Board Games by External and Internal Planning with Language Models

rZbZkZ0s
ZpZ0mpop
6
pZnZ0ZqZ
5
Z0ZpoPZ0
4
0Z0ZPZ0Z
3
Z0M0Z0Z0
2
POPZ0ZPO
1
S0AQJBZR
8
7

a

b

c

d

e

f

g

h

11...Nxf5 To avoid a passive defense, MAVâ€“IS
sacrifices a piece for two central pawns. 12.
exf5 Bxf5 13. Bd3 e4 14. Bf1 d4 15. Nd5

rZ0ZkZ0s
ZpZ0Zpop
6
pZnZ0ZqZ
5
Z0ZNZbZ0
4
0Z0opZ0Z
3
Z0Z0Z0Z0
2
POPZ0ZPO
1
S0AQJBZR
8

White: MAVâ€“IS(ğ‘ = 4, ğ‘‘ = 2)
Black: Stockfishâ€“L10
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/cHJzIu8F
1. e4 e5 2. f4 exf4 3. Nf3 d6 4. d4 g5 5. g3 g4 6.
Nh4 f3 7. Nc3
Nf6 8. Bg5 Be7 9. Qd2 Nc6 10.
O-O-O h6 11. Bxh6 Nxd4

rZblkZ0s
opo0apZ0
6
0Z0o0m0A
5
Z0Z0Z0Z0
4
0Z0mPZpM
3
Z0M0ZpO0
2
POPL0Z0O
1
Z0JRZBZR
8
7

a

7

a

b

c

d

e

f

g

h

15...O-O-O MAVâ€“IS pushes backwards the only
Whiteâ€™s active piece, while all other pieces are
still stuck at their original squares. 16. Nf4
Qd6 17. Be2 Qc5 18. O-O d3+ 19. Kh1 dxe2
20. Qxe2 h5 21. c4 Bg4 22. Qe1 Rd1 23. Be3
Rxe1 24. Bxc5 Rxa1 25. Rxa1 h4 26. Re1 Bf5
27. Kg1 h3 28. b3 hxg2 29. Rd1 Bh3 30. Rd5 f6
31. Nxh3 Rxh3 32. Bd6 Rd3 33. Kxg2 Rxd5 34.
cxd5 Nd4 35. Kf2 Nf5 36. Bb4 Kd7 37. Ba3 Kc7
38. Bc5 Kd7 39. a4 Kc7 40. Bb4 Kd7 41. Bf8 g6
42. b4 Ne7 43. Bxe7 Kxe7 44. a5 Kd6 45. Ke1
Kxd5 46. Ke2 Kd4 47. b5 axb5 48. Kf2 (game
terminated by early termination). 0 â€“ 1

Game 16
The power of zwischenzug
Date: 2024-11-21

b

c

d

e

f

g

h

12. Bg7 Instead of an immediate recapture,
MAVâ€“IS complicates the game by playing an
in-between move. Rg8 13. Qxd4 Rxg7 14. e5
Nh5 15. Bc4 Kf8 16. Kb1 d5 17. Nxd5 c6 18.
Nxe7 Qxd4 19. Rxd4 Kxe7 20. Re1 b5

rZbZ0Z0Z
o0Z0jps0
6
0ZpZ0Z0Z
5
ZpZ0O0Zn
4
0ZBS0ZpM
3
Z0Z0ZpO0
2
POPZ0Z0O
1
ZKZ0S0Z0
8
7

a

b

c

d

e

f

g

h

21. e6 Instead of retreating the attacked piece,
MAVâ€“IS plays a strong in-between move that
sacrifices a piece and leads to a dynamic
equality. bxc4 22. Nf5+ Kf6 23. Nxg7 Nxg7 24.
Rxg4 Bxe6 25. Rf4+ Kg5 26. Rxf3 f5 27. b3 Rh8
28. Rf2 Rh3 29. bxc4 a5 30. Re5 a4 31. Rc5 Bd7
32. Ra5 Be6 33. Rxa4 Ne8 34. Re2 Rh6 35. c5
Ng7 36. Ra7 Kf6 37. Ra8 Bc4 38. Rf8+ Kg6 39.

44

Mastering Board Games by External and Internal Planning with Language Models

Rf2 Rh7 40. a4 Ne6 41. R8xf5 Ra7 42. Rf6+
Kg7 43. h4 Bd5 44. h5 Nxc5 45. Rg6+ Kh7 46.
Rff6 Be4 47. Rg5 Bd5 48. Rgg6 Be4 49. Rg5 Bd5
50. Re5 Rb7+ 51. Kc1 Nxa4 52. g4 Nb6 53. g5
Ra7 54. Kd1 Nc4 55. Re8 Kg7 56. h6+ Kh7 57.
Ke1 Rb7 58. Kf2 Rd7 59. Ke2 Na3 60. Kf2 Nxc2
61. Re5 Bg8 62. Kg3 Nb4 63. Re8 Bf7 64. Rb8
c5 65. Rc8 Re7 66. Rxc5 Nd3 67. Rcc6 Re3+ 68.
Kh4 Ne5 69. Rc7 Kg8 70. Rc8+ Kh7 71. Rc7
Kg8 72. Rc8+ Kh7 73. Rc7 1/2 â€“ 1/2

Game 17
Execution is stronger than a threat
Date: 2024-12-01
White: MAVâ€“MCTS( ğ‘€ = 2000)
Black: Stockfishâ€“L20
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/Qoyj7u8h
1. e4 g6 2. d4 Bg7 3. Nc3 d6 4. f4 Nc6
5. Be3
e6 6. Nf3 a6 7. Bd3 b5 8. a4 b4 9. Ne2 Nf6 10.
O-O a5 11. f5 MAVâ€“MCTS does not hesitate to
start an immediate pawn break. exf5 12. exf5
O-O 13. Bg5 Ne7 14. Ng3 Ba6 15. Bxa6 Rxa6
16. Qd3 Ra8 17. Nd2 Ned5 18. c3 bxc3 19. bxc3
Qd7 20. Nde4 Nxe4 21. Nxe4 Rfe8 22. h4 Rab8
23. Rf2 Qc6 24. Qf3 Qd7 25. Qd3 h6 26. Bd2 c5
27. Raf1 cxd4 28. fxg6 fxg6

0s0ZrZkZ
Z0ZqZ0a0
6
0Z0o0Zpo
5
o0ZnZ0Z0
4
PZ0oNZ0O
3
Z0OQZ0Z0
2
0Z0A0SPZ
1
Z0Z0ZRJ0
8
7

a

b

c

d

e

f

g

40. Rh3 Qe1+ 41. Kh2 Qe5+ 42. Kg1 Qe1+ 43.
Kh2 Qe5+ 44. Kg1 Qe1+ 45. Kh2 (threefold
repetition). Perpetual check saves Black from
getting mated. 1/2 â€“ 1/2

Game 18
The dragon bishop
Date: 2024-12-01
White: Stockfishâ€“L19
Black: MAVâ€“MCTS( ğ‘€ = 2000)
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/2HlG6ZaD
1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5.
Nc3 g6 6. Be3 Bg7 7. f3 O-O 8. Qd2 Nc6 9. Bc4
Qa5 10. O-O-O Bd7
11. Kb1 Rfc8 12. Nb3
Qd8 13. Be2 Ne5 14. h4 a5 15. Nd4 a4 16. g4
a3 17. b3 Qa5 18. Ncb5 Qxd2 19. Bxd2 Nc6 20.
Bc1 Nxd4 21. Nxd4 Rc3 22. Rhe1 h5 23. g5 Ne8
This seemingly unimportant knight will play
a pivotal role in what is to come.

rZ0ZnZkZ
7
ZpZbopa0
6
0Z0o0ZpZ
5
Z0Z0Z0Op
4
0Z0MPZ0O
3
oPs0ZPZ0
2
PZPZBZ0Z
1
ZKARS0Z0
8

a

b

c

d

e

f

g

h

24. Bxa3 Prelude to a very unusual tactic.
Rxa3

h

29. Nf6+ MAVâ€“MCTS does take time for the
preparatory moves, but jumps with a knight
to a square that is defended twice to open the
diagonals and lines around Blackâ€™s king. Nxf6
30. Rxf6 Re6 31. Qxg6 Rxf6 32. Rxf6 Qe7 33.
Rf3 Qe8 34. Qg4 Kh8 35. Rg3 Be5 36. Bf4 dxc3
37. Bxe5+ Qxe5 38. Qg6 Qd4+ 39. Kh1 Qxh4+

45

Mastering Board Games by External and Internal Planning with Language Models

0Z0ZnZkZ
ZpZbopa0
6
0Z0o0ZpZ
5
Z0Z0Z0Op
4
0Z0MPZ0O
3
sPs0ZPZ0
2
PZPZBZ0Z
1
ZKZRS0Z0
8
7

a

b

c

d

e

f

g

h

25. Kb2 A lone king is "forking" two rooks.
Rxa2+ 26. Kxc3

0Z0Z0ZkZ
7
Zpmbopa0
6
0Z0o0ZpZ
5
Z0Z0Z0Op
4
0Z0MPZ0O
3
ZPJ0ZPZ0
2
rZPZBZ0Z
1
Z0ZRS0Z0
8

a

b

c

d

e

f

g

h

26...Nc7 27. b4 White makes a â€œluftâ€ to escape
a pin from the dark-squared bishop. Ne6 The
knight enters the game with a great effect! 28.
Kb3 Ra8 29. Nxe6

rZ0Z0ZkZ
ZpZbopa0
6
0Z0oNZpZ
5
Z0Z0Z0Op
4
0O0ZPZ0O
3
ZKZ0ZPZ0
2
0ZPZBZ0Z
1
Z0ZRS0Z0
8
7

a

b

c

d

e

f

g

h

29...Ba4+ This zwischenschach is the only
move which secures sufficient compensation
for the exchange because it pushes the king
towards the center of the board. 30. Kc4 fxe6
31. Rc1 Rc8+ 32. Kd3 Bc3 33. Rf1 Bxb4 34. c3
Ba5 35. Bd1 Bb5+ The light-squared bishop
takes over the role of a pinner. 36. c4

0ZrZ0ZkZ
ZpZ0o0Z0
6
0Z0opZpZ
5
abZ0Z0Op
4
0ZPZPZ0O
3
Z0ZKZPZ0
2
0Z0Z0Z0Z
1
Z0SBZRZ0
8
7

a

b

c

d

e

f

g

h

36...d5 MAVâ€“MCTS is pinning White from
every angle! 37. Bb3 Ba6 38. f4 Kg7 39. exd5
exd5 40. Kd4 Rd8 41. c5 White returns the
exchange to release the tension and enter a
balanced endgame. Bxf1 42. Rxf1 e6 43. Ra1
b6 44. Kd3 Rc8 45. cxb6 Bxb6 46. Ra6 Rb8
47. Kd2 Bf2 48. Bc2 Kf7 49. Ke2 Rb2 50. Kxf2
Rxc2+ 51. Kg3 Ke7 52. Kf3 Rc1 53. Kg2 d4 54.
Ra4 Rd1 55. Kf3 Rh1 56. Rxd4 Rxh4 57. Ke3 e5
58. Re4 Rh3+ 59. Kd2 Rf3 60. Rxe5+ Kf8 61.
Re6 Kf7 62. Rf6+ Kg7 63. Ke1 h4 64. Ke2 Rg3
65. Re6 h3 66. Kf2 Rg4 67. Re7+ Kg8 68. Ra7
h2 69. Ra8+ Kg7 70. Ra7+ Kg8 71. Ra1 Kf7 72.
Re1 Rh4 73. Rh1 Rh3 74. Kf1 Ke6 75. Kg2 Re3
76. f5+ Kxf5 77. Ra1 Re8 78. Kh1 Re7 79. Ra5+
Re5 80. Ra1 Re8 81. Kxh2 Re7 82. Ra4 Re4 83.
Ra3 Kg4 84. Ra1 Re3 85. Rg1+ Kf4 86. Rb1
Re2+ 87. Kh1 Re3 88. Rc1 Kg3 89. Kg1 Rb3 90.
Kh1 Kh3 91. Kg1 Rb4 92. Kf2 Rf4+ 93. Ke1 Rf5
94. Rc2 Rxg5 95. Kf1 Rg4 96. Re2 g5 97. Re6
Kh2 98. Rh6+ Kg3 99. Rb6 Rc4 100. Rb3+ Kh2
101. Rb2+ Kh1 102. Kf2 Kh2 103. Kf1+ Kh1
104. Kf2 Kh2 105. Kf1+ (threefold repetition).
A peaceful outcome fo a wild game. 1/2 â€“ 1/2

Game 19
Taming the dragon bishop

46

Mastering Board Games by External and Internal Planning with Language Models

Date: 2024-12-01
White: MAVâ€“MCTS( ğ‘€ = 2000)
Black: Stockfishâ€“L19
Result: 1 â€“ 0
Online PGN: https://lichess.org/eKR8u32g
1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5.
Nc3 g6 6. Be3 Bg7 7. f3 O-O 8. Qd2 Nc6 9. Bc4
Qa5 10. O-O-O Bd7
11. Bb3 MAVâ€“MCTS
chooses the different approach to the Sicilian
Dragon than Stockfish in Game 18. Ne5 12.
Bh6 MAVâ€“MCTS immediately exchanges the
favorite piece of every Dragon player. Bxh6 13.
Qxh6 Rac8 14. Nd5 Nxd5 15. exd5 Qc5 16. a3
a5 17. h4 f6 18. Rhe1 a4 19. Ba2 b5 20. Qd2
Rfe8 21. h5 gxh5 22. Rh1 Rf8 23. Rxh5 Rf7 24.
Kb1 Nc4 25. Qe1 Rg7 26. g4 Ne5 27. Rh2 Rf8
28. Ka1 Nc4 29. Rh5 Ne5 30. c3 Nxf3 31. Nxf3
Bxg4

0Z0Z0skZ
Z0Z0o0sp
6
0Z0o0o0Z
5
ZplPZ0ZR
4
pZ0Z0ZbZ
3
O0O0ZNZ0
2
BO0Z0Z0Z
1
J0ZRL0Z0
8

33. Rh3 Another beautiful move by MAVâ€“MCTS
. Notice that a symmetric move Rf1 is the only
alternative which secures the advantage. Kh8
34. Re1 Qf4 35. Bb1 Bxh3 36. Qxh3 Qg4 37.
Qh1 f5 38. Rg1 Qxf3 39. Qxf3 Rxg1 40. Qh5 Re1
41. Qh4 Re2 42. Bd3 Re5 43. Bxb5 Rf6 44. Qf4
Re4 45. Qf3 Rg4 46. Ka2 h5 47. Qe2 Rf7 48.
Be8 Rfg7 49. Qe6 f4 50. Bf7 Kh7 51. Qf5+ R4g6
52. Qxh5+ Rh6 53. Qf5+ Kh8 54. Qc8+ Kh7
55. Qf5+ Kh8 56. Qxf4 Rf6 57. Qh4+ Rh7 58.
Bh5 Kg7 59. Qg4+ Kh8 60. Qxa4 Kg8 61. Qe8+
Rf8 62. Qg6+ Kh8 63. a4 Rg8 64. Qf5 Rh6 65.
a5 Rf6 66. Qh3 Kg7 67. Qe3 Kf8 68. a6 e5 69.
a7 Ke7 70. Qb6 Rff8 71. Qc7+ Kf6 72. Qxd6+
Kf5 73. Qe6+ Kf4 74. d6 Kg5 75. Bf7 Ra8 76.
Qxe5+ Kh4 77. Qh2+ Kg4 78. Qg2+ Kh4 79.
Qh2+ Kg5 80. Qg3+ Kf5 81. Bxg8 Rxa7+ 82.
Kb1 Ra8 83. d7 Ke4 84. Qg4+ Ke3 85. Qd4+
Kf3 86. Bd5+ Ke2 87. Bxa8 Kf1 88. b4 Ke2 89.
b5 Ke1 90. Bg2 Ke2 91. d8=Q Ke1 92. Qe8#
1â€“0

7

a

b

c

d

e

f

g

h

32. Qh1 MAVâ€“MCTS finds a beautiful geometry
to secure a huge advantage. Qe3

Game 20
Endgame masterclass
Date: 2024-12-01
White: MAVâ€“MCTS( ğ‘€ = 2000)
Black: Stockfishâ€“L19
Result: 1 â€“ 0
Online PGN: https://lichess.org/WjsKWo1E
1. d4 d5 2. c4 c6 3. Nc3 e6 4. e3 f5
5. Bd3
Nf6 6. Nge2 a5 7. O-O Bd6 8. c5 Bc7 9. f3 Nbd7
10. e4 dxe4 11. fxe4 fxe4 12. Nxe4 Nxe4 13.
Bxe4 Qh4 14. Nf4 O-O 15. g3 Qe7 16. Bc2 Nf6

rZbZ0skZ
7
Zpa0l0op
6
0ZpZpm0Z
5
o0O0Z0Z0
4
0Z0O0M0Z
3
Z0Z0Z0O0
2
POBZ0Z0O
1
S0AQZRJ0
8

rmblkans
opopopop
6
0Z0Z0Z0Z
5
Z0Z0Z0Z0
4
0Z0Z0Z0Z
3
Z0Z0Z0Z0
2
POPOPOPO
1
SNAQJBMR
8
7

a

b

c

d

e

f

g

h

a

17.

b

c

d

e

f

g

h

Nh5 A strong move that secures the

47

Mastering Board Games by External and Internal Planning with Language Models

initiative. e5 18. Bg5 a4 19. Qd3 e4 20. Qe3
Bh3 21. Nxf6+ gxf6 22. Bxf6 Rxf6 23. Qg5+
Qg7 24. Qxf6 Re8 25. Qxg7+ Kxg7

0Z0Z0Z0Z
ZpZ0Z0jp
6
0ZpZ0a0Z
5
Z0O0Z0Z0
4
pZ0OBZ0Z
3
Z0Z0Z0O0
2
PO0Z0Z0O
1
Z0Z0ZKZ0
8
7

0Z0ZrZ0Z
Zpa0Z0jp
6
0ZpZ0Z0Z
5
Z0O0Z0Z0
4
pZ0OpZ0Z
3
Z0Z0Z0Ob
2
POBZ0Z0O
1
S0Z0ZRJ0
8
7

a

b

c

d

e

f

g

h

26. Rae1 An unintuitive exchange sacrifice.
Bxf1 27. Kxf1 Bd8

0Z0arZ0Z
ZpZ0Z0jp
6
0ZpZ0Z0Z
5
Z0O0Z0Z0
4
pZ0OpZ0Z
3
Z0Z0Z0O0
2
POBZ0Z0O
1
Z0Z0SKZ0
8
7

a

b

c

d

e

f

g

h

28. Rxe4 MAVâ€“MCTS decides to enter the
opposite color bishops endgame which are
notorious for their high margin of a draw.
Rxe4 29. Bxe4 Bf6

a

b

c

d

e

f

g

h

30. d5 The pinnacle behind MAVâ€“MCTS â€™s
play, and the only winning move! When
sacrificing the exchange on move 26, MAVâ€“
MCTS correctly evaluated that the resulting
semi-forcing sequence will result in the
winning opposite color bishops endgame.
Bxb2 31. dxc6 bxc6 32. Bxc6 Ba3 33. Kg2 Bxc5
34. Bxa4 It is known that the opposite-colored
bishops endgames are winning if the distance
between the passed pawns is four or more
squares. MAVâ€“MCTS proceeds to display the
winning technique. Kf6 35. Bc2 h6 36. Kf3 Bg1
37. a4 Bb6 38. Kg4 Bg1 39. h3 Bb6 40. Kh5 Kg7
41. Be4 Bf2 42. g4 Be1 43. Bg2 Bg3 44. a5 Be1
45. a6 Bf2 46. Be4 Bd4 47. Bd3 Bc5 48. Bc4 Be3
49. h4 Bc5 50. Bd3 Bg1 51. Bc2 Ba7 52. Be4 Bf2
53. Bb1 Bg1 54. Bc2 Bc5 55. Bb1 Bb6 56. Bc2
Bf2 57. Bb1 Bd4 58. Bc2 Bb6 59. Ba4 Bg1 60.
Bd7 Be3 61. Ba4 Kf6 62. Bd1 Kf7 63. Ba4 Kf6
64. Bd1 Ke6 65. g5 Bxg5 66. hxg5 Kd6 67. Ba4
hxg5 68. Kxg5 Kc7 69. Kf5 Kb8 70. Ke4 Ka8 71.
Ke5 Kb8 72. Bc2 Kc8 73. Kd6 Kb8 74. Bg6 Ka7
75. Bd3 Kb8 76. Bg6 Ka7 77. Bd3 Kb6 78. Bf1
Ka5 79. a7 Kb4 80. a8=Q Kc3 81. Qd5 Kb2 82.
Qa5 Kb1 83. Qd2 Ka1 84. Bg2 Kb1 85. Bd5 Ka1
86. Qa2# 1 â€“ 0

Game 21
A menace knight
Date: 2024-12-01
White: Stockfishâ€“L19
Black: MAVâ€“MCTS( ğ‘€ = 2000)
Result: 0 â€“ 1
Online PGN: https://lichess.org/wuIGT2Q5

48

Mastering Board Games by External and Internal Planning with Language Models

1. d4 d5 2. c4 c6 3. Nc3 e6 4. e3 f5
5. Qc2
Nf6 6. Bd3 a5 7. b3 Ne4 8. Bb2 Nd7 9. Nh3 Bd6
10. O-O Nxc3 11. c5 Bxh2+ 12. Kxh2 Ne4 13.
Rfe1 Ndf6 14. Kg1 g5 15. f3 g4 16. Nf4 gxf3 17.
gxf3 Rg8+ 18. Kf1 Ng3+ 19. Kg1 Ngh5+ 20.
Kf1 Ng3+ 21. Kg1 Ngh5+ 22. Kf1 Nxf4 23. exf4
Kf7 24. Qh2 b6 25. Ke2 Ba6 26. Bxa6 Rxa6 27.
a4 Ra8 28. Rg1 Rb8 29. Rxg8 Qxg8 30. Rg1 Qf8
31. Bc3 b5 32. Kd3 h5 33. Qg2 Qh6 34. axb5
Rxb5 35. Kc2 Rb8 36. Qg5 Qh7 37. Qh4 Rg8
38. Rg5 Ra8 39. Kb2 a4 40. b4 Qh6 41. Ka2
Rh8 42. Ka3 Qf8 43. b5 Qa8 44. Rg1 Qb7 45.
Rb1 cxb5 46. Be1 Qc8 47. Rb2 Qa8 48. Bc3 Qa7
49. Rxb5 Rb8 50. Rxb8 Qxb8 51. Kxa4 Qb1 52.
Qh2 Qd3 53. Qd2 Even some extremely strong
engines do not immediately realize that this
is a losing move.

0Z0Z0Z0Z
Z0Z0ZkZ0
6
0Z0Zpm0Z
5
Z0OpZpZp
4
KZ0O0O0Z
3
Z0AqZPZ0
2
0Z0L0Z0Z
1
Z0Z0Z0Z0
8
7

a

b

c

d

e

f

g

h

53...Qxd2 MAVâ€“MCTS correctly recognizes
that the knight will dominate the bishop in
this static pawn structure. 54. Bxd2 h4 55. Be3
Ke8 56. Kb5 Kd7 57. Bf2 h3 58. Bg1 Kc7 59. Bh2
Nd7 60. Kb4 Nb8 61. Kc3 Kb7 62. Kd2 Kc6 63.
Bg1 Kb5 64. Kc3 Ka4 65. c6 Nxc6 66. Kd2 Kb4
67. Kd3 Kb3 68. Bh2 Kb4 69. Bg3 Kb3 70. Bh2
Nb4+ 71. Ke3 Kc3 72. Ke2 Nc2 73. Kf2 Nxd4
74. Ke3 Nc2+ 75. Kf2 d4 76. Kg3 d3 77. Kxh3
d2 78. Bg1 Nd4 79. Kh4 d1=Q 80. Be3 Qe1+
81. Kh5 Qxe3 82. Kh6 Qc1 83. Kg5 Kc2 84. Kf6
Qa3 85. Kg7 Qe7+ 86. Kh6 Kd2 87. Kh5 Qg7 88.
Kh4 Ke1 89. Kh5 Kf2 90. Kh4 Qh6# 0 â€“ 1

Game 22

White: MAVâ€“MCTS( ğ‘€ = 2000)
Black: Stockfishâ€“L18
Result: 1 â€“ 0
Online PGN: https://lichess.org/UMurXJiP
1. d4 Nf6 2. c4 e6 3. Nf3 c5 4. d5 d6 5. Nc3
exd5 6. cxd5 g6 7. h3 Bg7 8. e4 O-O 9. Bd3 Re8
10. O-O Nbd7
11. Bf4 c4 12. Bc2 Nc5 13.
Nd2 Qd7 14. Nxc4 Ncxe4 15. Nxe4 Nxe4 16. f3
Nf6 17. Nxd6 Rd8 18. Bg3 Nh5 19. Bh2 Qc7 20.
Ne4 Qb6+ 21. Kh1 f5 22. Ng3 Nf6 23. Bb3 Be6

rZ0s0ZkZ
opZ0Z0ap
6
0l0ZbmpZ
5
Z0ZPZpZ0
4
0Z0Z0Z0Z
3
ZBZ0ZPMP
2
PO0Z0ZPA
1
S0ZQZRZK
8
7

a

b

c

d

e

f

g

h

24. dxe6 MAVâ€“MCTS recognizes that the only
way to fight for the advantage is by sacrificing
the queen. Rxd1 25. Raxd1 Re8 26. e7+ Kh8
27. Rfe1 Qb4 28. Nf1 f4 29. Bg1 h6 30. Re5
Rxe7

0Z0Z0Z0j
opZ0s0a0
6
0Z0Z0mpo
5
Z0Z0S0Z0
4
0l0Z0o0Z
3
ZBZ0ZPZP
2
PO0Z0ZPZ
1
Z0ZRZNAK
8
7

a

b

c

d

e

f

g

h

31. Rd4 MAVâ€“MCTS plays a zwischenzug that
traps the opponentâ€™s queen in the middle of
the board! Qxb3

Dominating the queen
Date: 2024-12-01

49

Mastering Board Games by External and Internal Planning with Language Models

0Z0Z0Z0j
7
opZ0s0a0
6
0Z0Z0mpo
5
Z0Z0S0Z0
4
0Z0S0o0Z
3
ZqZ0ZPZP
2
PO0Z0ZPZ
1
Z0Z0ZNAK
8

a

b

c

d

e

f

g

h

32. Rxe7 MAVâ€“MCTS correctly evaluates
that taking the queen only leads to equality.
Instead, by taking the rook, MAVâ€“MCTS pieces
continue to dominate Blackâ€™s queen until the
rest of the game. Qg8 33. Nd2 g5 34. Ne4 Nd5
35. Rxb7 g4 36. hxg4 Qd8 37. Rd1 Qh4+ 38.
Bh2 a6 39. Rc1 Ne7 40. b4 Bb2 41. Rd1 Bg7 42.
b5 axb5 43. Rxb5 Ng8 44. Rh5 Qe7 45. Bxf4
Kh7 46. Rd6 Bb2 47. Bxh6 Nxh6 48. Rdxh6+
Kg8 49. Rg6+ Kf8 50. Rf5+ Ke8 51. Nd6+ Kd8
52. Rg8+ Kc7 53. Rf7 The queen is gone. Kxd6
54. Rxe7 Kxe7 55. g3 Ba3 56. Kg2 Kf7 57. Rb8
Kf6 58. Rb5 Ke7 59. Kh3 Kd7 60. Rb7+ Kc6 61.
Rb3 Be7 62. f4 Bd8 63. g5 Ba5 64. Kg4 Kd5 65.
Rb5+ Ke6 66. Rxa5 Kd6 67. Ra7 Ke6 68. Rb7
Kd6 69. g6 Ke6 70. a4 Kd6 71. g7 Kd5 72. a5
Kd6 73. g8=Q Kc5 74. f5 Kd4 75. Qg5 Kc5 76.
Qe3+ Kc6 77. Rh7 Kb5 78. Rc7 Ka4 79. Rb7
Kxa5 80. Qa3# 1 â€“ 0

Game 23
Underpromotion for the win
Date: 2024-11-14
White: Stockfishâ€“L17
Black: MAVâ€“MCTS( ğ‘€ = 2000)
Result: 0 â€“ 1
Online PGN: https://lichess.org/GzFmze7T
1. c4 c5 2. g3 g6 3. Bg2 Bg7 4. Nc3 Nc6 5. a3 e6
6. b4 Nxb4 7. axb4 cxb4 8. Nb5
Bxa1 9. Nf3
Qa5 10. O-O

rZbZkZns
opZpZpZp
6
0Z0ZpZpZ
5
lNZ0Z0Z0
4
0oPZ0Z0Z
3
Z0Z0ZNO0
2
0Z0OPOBO
1
a0AQZRJ0
8
7

a

b

c

d

e

f

g

h

10...a6 MAVâ€“MCTS finds the only move which
secures a sizable advantage in a very irrational
position. 11. Nd6+ Ke7 12. c5 Qxc5 13. d4
Qxd6 14. Bf4 Qb6 15. Qxa1 d5 16. e4 Nf6 17.
Rc1 Bd7 18. Ne5 Rhd8 19. Rc5 Nh5 20. Qc1
Rac8 21. exd5 exd5 22. Nxd7 Kxd7 23. Bd2 b3
24. Qb2 Rxc5 25. dxc5 Qxc5 26. Qxb3 Kc8 27.
Qb2 Qb5 28. Qa1 d4 29. Bf1 Qc5 30. Qa2 Rd7
31. Bh3 f5 32. g4 Nf6 33. gxf5 Kb8 34. fxg6 Rg7
35. Qb3 Rxg6+ 36. Kf1 Ne4 37. Bf4+ Ka8 38.
Be6 d3 39. Be3 Qxe3 40. fxe3 Nd2+ 41. Kf2
Nxb3 42. Bxb3 Rb6 43. Bc4 Rb2+ 44. Ke1 d2+
45. Ke2 a5 46. Bd3 a4 47. Bxh7 a3 48. Bg8 a2
49. Bxa2 d1=Q+ 50. Kxd1 Rxa2 51. Kc1 Rxh2
52. Kb1 Ka7 53. Kc1 b5 54. Kd1 Rg2 55. Ke1
Ra2 56. e4 Kb7 57. e5 Kc7 58. Kf1 Kd7 59. e6+
Kxe6 60. Kg1 b4 61. Kf1 Rc2 62. Ke1 Kd5 63.
Kd1 b3 64. Ke1 Kc6 65. Kd1 Kd5 66. Ke1 b2 67.
Kf1

0Z0Z0Z0Z
Z0Z0Z0Z0
6
0Z0Z0Z0Z
5
Z0ZkZ0Z0
4
0Z0Z0Z0Z
3
Z0Z0Z0Z0
2
0orZ0Z0Z
1
Z0Z0ZKZ0
8
7

a

b

c

d

e

f

g

h

67...b1=R#

50

Mastering Board Games by External and Internal Planning with Language Models

Chess960

0Z0Z0Z0Z
7
Z0Z0Z0Z0
6
0Z0Z0Z0Z
5
Z0ZkZ0Z0
4
0Z0Z0Z0Z
3
Z0Z0Z0Z0
2
0ZrZ0Z0Z
1
ZrZ0ZKZ0
8

a

b

c

d

e

f

g

h

MAVâ€“MCTS earns bonus points for finishing
the game in style! 0 â€“ 1

Each game starts with a randomly sampled initial
position from a set of chess960 legal permutations.
Once the game is finished, the agents reverse the
colors and play the game with the same initial
position. In the header of each game we show
the starting order of pieces. A square next to the
diagrams represents a side to play. All games
use Stockfish with 2 seconds of thinking time
per move. We use MAVâ€“MCTS to represent the
external search MAV with mean scoring.

Game 1
Setting the board on fire
Date: 2024-11-14
White: MAVâ€“MCTS( ğ‘€ = 100)
Black: Stockfishâ€“L19
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/0cs1dk1D

MNSBAQJR
1. d4 d5 2. c4 dxc4 3. Rxc4 Nc6 4. Nb3 e5 5.
dxe5 Nxe5 6. Rc1 c5 7. f4

nZrablks
opZ0Zpop
6
0Z0Z0Z0Z
5
Z0o0m0Z0
4
0Z0Z0O0Z
3
ZNZ0Z0Z0
2
PO0ZPZPO
1
ZNSBAQJR
8
7

a

b

c

d

e

f

g

h

7...c4 Instead of retreating, Black counterattacks MAVâ€“MCTS â€™s knight and the craziness
starts. 8. fxe5

51

Mastering Board Games by External and Internal Planning with Language Models

nZrablks
7
opZ0Zpop
6
0Z0Z0Z0Z
5
Z0Z0O0Z0
4
0ZpZ0Z0Z
3
ZNZ0Z0Z0
2
PO0ZPZPO
1
ZNSBAQJR
8

a

b

c

d

e

f

g

h

8...cxb3 Black sacrifices the rook! 9. Rxc8
Bb6+ 10. Bf2

nZRZblks
7
opZ0Zpop
6
0a0Z0Z0Z
5
Z0Z0O0Z0
4
0Z0Z0Z0Z
3
ZpZ0Z0Z0
2
PO0ZPAPO
1
ZNZBZQJR
8

a

b

c

d

e

f

g

h

10...bxa2

nZRZblks
opZ0Zpop
6
0a0Z0Z0Z
5
Z0Z0O0Z0
4
0Z0Z0Z0Z
3
Z0Z0Z0Z0
2
pO0ZPAPO
1
ZNZBZQJR
8
7

a

b

c

d

e

f

g

h

MAVâ€“MCTS cannot prevent black pawn from
promoting on move 10! But... 11. Ba4 a1=Q
12. Bxe8 Bxf2+ 13. Kxf2 Qa5

nZRZBlks
opZ0Zpop
6
0Z0Z0Z0Z
5
l0Z0O0Z0
4
0Z0Z0Z0Z
3
Z0Z0Z0Z0
2
0O0ZPJPO
1
ZNZ0ZQZR
8
7

a

b

c

d

e

f

g

h

Despite being a queen up, Black is not better!
14. Qc1 Nb6 15. Qc7 Nxc8 16. Qxa5 Qxe8 17.
Rd1 b6 18. Qb5 O-O 19. Qxe8 Rxe8 20. Rd7 a5
21. Na3 Kf8 22. Nc4 Re7 23. Rd8+ Re8 24. Rd7
Re6 25. Rc7 Ne7 26. Rb7 Ng6 27. Rb8+ Ke7
28. Rb7+ Kd8 29. Rxf7 Nxe5 30. Nxe5 Rxe5 31.
Rxg7 h5 32. h4 Rf5+ 33. Ke3 Re5+ 34. Kf3 Ke8
35. Rg5 Rxg5 36. hxg5 Kf7 37. Ke4 b5 38. Kd5
b4 39. Kc4 Kg6 40. Kb5 b3 41. Kxa5 Kxg5 42.
Ka4 h4 43. Kxb3

0Z0Z0Z0Z
Z0Z0Z0Z0
6
0Z0Z0Z0Z
5
Z0Z0Z0j0
4
0Z0Z0Z0o
3
ZKZ0Z0Z0
2
0O0ZPZPZ
1
Z0Z0Z0Z0
8
7

a

b

c

d

e

f

g

h

MAVâ€“MCTS must settle for a draw despite
being two pawns up in the pawn endgame!
43...Kf4 44. Kc2 Ke3 45. b4 Kxe2 46. b5 Kf1 47.
b6 Kxg2 48. b7 h3 49. b8=Q h2 50. Qb7+ Kg1
51. Qb1+ Kg2 52. Qb7+ Kg1 53. Qb1+ Kg2
54. Qb7+ (threefold repetition). After all the
craziness the game ends peacefully. 1/2 â€“ 1/2

Game 2
Accelerated Benko gambit

52

Mastering Board Games by External and Internal Planning with Language Models

Date: 2024-11-14
White: Stockfishâ€“L20
Black: MAVâ€“MCTS( ğ‘€ = 2000)
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/yJXI9zcc

LBANMRJR

Bb2 f6 25. Ba3 f5 26. Re1 Rb8 27. Kg1 Rb7 28.
Rge3 Rh6 29. Rxe6 Nxe6 30. Rxe6 Kg7 31. Bxf5
Rxe6 32. Bxe6 Kf6 33. Bc4 Rb1+ 34. Kf2 e5
35. Bd6 Ra1 36. Bb3 Rb1 37. Bg8 Ra1 38. Bb3
Rb1 39. Bg8 Ra1 40. Bb3 (threefold repetition).
After surviving some terrifying moments in
the middlegame, MAVâ€“MCTS lives to fight
another day. 1/2 â€“ 1/2

1. d4 h5 2. c4

Game 3

qabmnsks
7
opopopo0
6
0Z0Z0Z0Z
5
Z0Z0Z0Zp
4
0ZPO0Z0Z
3
Z0Z0Z0Z0
2
PO0ZPOPO
1
LBANMRJR
8

a

b

c

d

e

f

g

h

2...b5 Even Stockfish gives the same evaluation
as for the traditional Benko gambit. 3. b3 Nf6
4. h4 Qb7 5. Nf3 c6 6. e4 d6 7. Ne3 a6 8. Re1
Ng4 9. e5 dxe5 10. Nxe5 Nxe5 11. dxe5 g6 12.
O-O Ba7 13. f4 bxc4 14. Kh1 cxb3 15. axb3 Ne6
16. f5 The position seems dire for MAVâ€“MCTS.

0ZbZ0sks
7
aqZ0opZ0
6
pZpZnZpZ
5
Z0Z0OPZp
4
0Z0Z0Z0O
3
ZPZ0M0Z0
2
0Z0Z0ZPZ
1
LBA0SRZK
8

a

b

c

d

e

f

g

h

Delayed Benko gambit
Date: 2024-11-14
White: Stockfishâ€“L19
Black: MAVâ€“MCTS( ğ‘€ = 2000)
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/MBeKZuLV

ABMRLNJR
1. b3 c5 2. e4 h5 3. Ne3 b5 4. c4

bansqmks
7
o0Zpopo0
6
0Z0Z0Z0Z
5
Zpo0Z0Zp
4
0ZPZPZ0Z
3
ZPZ0M0Z0
2
PZ0O0OPO
1
ABMRL0JR
8

a

b

c

d

e

f

g

h

4...h4 Similar to Game 2, MAVâ€“MCTS pushes b
and h pawns. 5. O-O e5 6. Nd5 Nb6 7. Bd3 Ne6
8. Qe3 Qf8 9. Ne2 Re8 10. Rde1 Rh6 11. Qf3
Nd4 12. Qh3 Bb7 13. Ne3 bxc4 14. bxc4 Bc8 15.
Nxd4 exd4 16. Ng4 Rh8 17. f4 d6 18. f5 Ba6 19.
f6 Bc8 20. e5 Rxe5 21. Qf3 g6 22. Bb2 Rg5 23.
h3 Bxg4 24. hxg4 Nd7 25. Qb7 Ne5 26. Be2 h3
27. g3 d5 28. d3 Nxg4 29. Bxg4 Rxg4 30. Qd7
Rxg3+ 31. Kh1

16...Qb4 But, MAVâ€“MCTS finds astonishing
resources to keep the game alive! 17. Qa4
Qxa4 18. bxa4 Bxe3 19. Rxe3 gxf5 20. Bxf5
Rd8 21. Rg3+ Ng7 22. e6 Kf8 23. Bg6 Bxe6 24.

53

Mastering Board Games by External and Internal Planning with Language Models

0a0Z0lks
7
o0ZQZpZ0
6
0Z0Z0OpZ
5
Z0opZ0Z0
4
0ZPo0Z0Z
3
Z0ZPZ0sp
2
PA0Z0Z0Z
1
Z0Z0SRZK
8

a

b

c

d

e

f

g

h

31...Rg2 MAVâ€“MCTS again finds a saving
resource in a difficult position. 32. Re8 Rh2+
33. Kg1 Rg2+ 34. Kh1 Rh2+ 35. Kg1 Rg2+ 36.
Kh1 (threefold repetition). 1/2 â€“ 1/2

Game 4
Not fearing ghosts
Date: 2024-11-14
White: MAVâ€“MCTS( ğ‘€ = 1000)
Black: Stockfishâ€“L19
Result: 1 â€“ 0
Online PGN: https://lichess.org/4EMehaRm

MBSKAQMR
1. c4 f6 2. f4 c6 3. Nb3 O-O-O 4. d4 Bh5 5. Bb4
g5 6. f5 Qg7 7. Bd3 Bf4 8. Rc3 Nh6 9. g3 Ng4
10. Ke1 Bb8 11. Kd2 e5 12. d5 e4 13. Bxe4 Rhe8
14. Bf3 Be5 15. Rc2 Ne3

nZksrZ0Z
opZpZ0lp
6
0ZpZ0o0Z
5
Z0ZPaPob
4
0APZ0Z0Z
3
ZNZ0mBO0
2
PORJPZ0O
1
Z0Z0ZQMR
8
7

a

b

c

d

e

f

g

h

16. Kxe3 MAVâ€“MCTS correctly evaluates that
it is safe to capture the knight and to expose
its king to a various discovered attacks in the
center of the board. Bd6+ 17. Kf2 Bxf3 18.
Nxf3 Bxb4 19. c5 Nc7 20. a3 Qe7 21. Qc1 Nxd5
22. axb4 Nxb4 23. Rd1 Qe4 24. Nbd4 Nxc2 25.
Qxc2 Qxc2 26. Nxc2 Re4 27. Nd2 Ra4 28. b3
Ra5 29. Ne4 d5 30. Nd6+ Kc7 31. Nd4 Rxd6
32. cxd6+ Kd7 33. g4 Ra6 34. h4 gxh4 35. g5
fxg5 36. f6 Ke8 37. Ne6 b5 38. Nc7+ Kd7 39.
f7 Kxd6 40. Nxd5 c5 41. f8=Q+ Ke5 42. Qe8+
Re6 43. Qh8+ Kf5 44. Qxh7+ Ke5 45. Qg7+
Ke4 46. Qh7+ Ke5 47. Qg7+ Kf5 48. e4+ Kg4
49. Rg1+ Kh5 50. Rxg5# Once MAVâ€“MCTS
obtained the advantage in the middlegame, it
never let it slip. 1 â€“ 0

Game 5
Finishing games in style
Date: 2024-11-14
White: Stockfishâ€“L18
Black: MAVâ€“MCTS( ğ‘€ = 100)
Result: 0 â€“ 1
Online PGN: https://lichess.org/kaZI3lB6

ARJRMBMQ
1. e4 g5 2. g3

54

Mastering Board Games by External and Internal Planning with Language Models

bsks0anl
7
opopopZp
6
0Z0m0Z0Z
5
Z0Z0Z0o0
4
0Z0ZPZ0Z
3
Z0Z0Z0O0
2
POPO0O0O
1
ARJRMBMQ
8

a

b

c

d

e

f

g

h

2...Nd6 A move that breaks a traditional
wisdom not to block central pawns with
pieces. 3. Bg2 f5 4. exf5 Bg7 5. Nh3 g4 6. Nf4
h5 7. Ned3 Nxf5 MAVâ€“MCTS finds a stable
outputs for the knight. 8. h3 e6 9. hxg4 hxg4
10. Nh5 Bd4 11. a4 Nf6 12. Nhf4 e5 13. Ne2 d6
14. a5 Qxh1 15. Rxh1 b6 16. Bxa8 Rxa8 17. c3
e4 18. cxd4 exd3 19. Nf4 Kd7 20. b4 Rh8 21.
Re1 Rae8 22. Rxe8 Rxe8 23. axb6 Re1+ 24. Kb2
Rxb1+ 25. Kxb1 cxb6 26. Nxd3 Kc6 27. Kc2 Ne4
28. Kd1 Kb5 29. d5 Kc4 30. Ke2 Ng5 31. Bc3
Ne4 32. Bb2 Ng5 33. Ne1 Kxb4 34. Kd3 Kc5 35.
Bf6 Nh7 36. Bc3 Kxd5 37. Bh8 Ng5 38. Ng2 Ne6
39. Nh4 Nxh4 40. gxh4 Nf4+ 41. Kc2 Ke4 42.
Bf6 b5 43. Kb3 a5 44. Be7 d5 45. Kc2 a4 46.
Bd6 d4 47. d3+ Nxd3 48. h5 Ne1+ 49. Kd2
Nf3+ 50. Kc2 Kf5 51. h6 Kg6 52. h7 Kxh7 53.
Kd3 Kg8 54. Bb4 Ne5+ 55. Kxd4 Nc6+ 56. Kc3
Nxb4 57. Kxb4 Kg7 58. Kc3 Kf6 59. Kb4 Kg5 60.
Kc3 a3 61. Kc2 b4 62. Kb3 Kf4 63. Ka2 Kf3 64.
Kb1 b3 65. Kc1 Kxf2 66. Kd1 a2 67. Kd2 a1=Q
68. Kd3 g3 69. Kc4 Qe5 70. Kb4 Qg7 71. Kc4 b2
72. Kb4 g2 73. Kc4 b1=Q 74. Kc5 Qd7 75. Kc4

0Z0Z0Z0Z
Z0ZqZ0Z0
6
0Z0Z0Z0Z
5
Z0Z0Z0Z0
4
0ZKZ0Z0Z
3
Z0Z0Z0Z0
2
0Z0Z0jpZ
1
ZqZ0Z0Z0
8
7

a

b

c

d

e

f

g

h

75...g1=R Like in the traditional chess game
23, MAVâ€“MCTS once again shows its preference for rook underpromotions. 76. Kc3 Rc1#
0â€“1

Game 6
A knight on the rim...
Date: 2024-11-14
White: MAVâ€“MCTS( ğ‘€ = 1000)
Black: Stockfishâ€“L17
Result: 1 â€“ 0
Online PGN: https://lichess.org/zurqClYv

ANSNLBJR
1. d4 d5 2. h4 b6 3. h5 Nd7 4. c4 e6 5. cxd5
exd5 6. h6 g6

bZrmqaks
o0onZpZp
6
0o0Z0ZpO
5
Z0ZpZ0Z0
4
0Z0O0Z0Z
3
Z0Z0Z0Z0
2
PO0ZPOPZ
1
ANSNLBJR
8
7

a

b

c

d

e

f

g

h

7. e4 MAVâ€“MCTS pushes a pawn on the most

55

Mastering Board Games by External and Internal Planning with Language Models

protected square on the board to secure the
piece activity. Qxe4 8. Qxe4 dxe4 9. Nbc3 Bd6
10. Ne3 Bb7 11. Nb5 Bf4 12. g3 Bxe3 13. fxe3
Ne6 14. b3 O-O 15. a4 a6

0ZrZ0skZ
ZbonZpZp
6
po0ZnZpO
5
ZNZ0Z0Z0
4
PZ0OpZ0Z
3
ZPZ0O0O0
2
0Z0Z0Z0Z
1
A0S0ZBJR
8
7

a

b

c

d

e

f

g

Game 7
Complications never end
Date: 2024-11-14
White: MAVâ€“MCTS( ğ‘€ = 100)
Black: Stockfishâ€“L19
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/iSEAtCyD

h

16. Na7 Not your everyday knight route. Rce8
17. Nc6 Nf6 18. Ne5 Rd8 19. Bc4 Ng5 20. Kf2 c6
21. Bb2 b5 22. Be2 Nd5 23. Nxc6 Rd6 24. Ne5
Rf6+ 25. Ke1 Rd8 26. axb5 axb5 27. Rc5 Nxe3
28. Rxb5 Ba8 29. Kd2 Nf5 30. Ng4 Rfd6 31. Rc1
e3+ 32. Ke1 Bf3 33. d5 Bxg4 34. Bxg4 Nxh6 35.
Be2 Ne4 36. Be5 R6d7 37. Rb4 Nd6 38. Bf6 Re8
39. g4 Kf8 40. Rb6 Ng8 41. Bb2 Red8 42. Ba3
Kg7 43. Bf3 Ne7 44. Bb2+ Kf8 45. Ba3 Kg8 46.
Rc3 h5 47. gxh5 g5 48. Rxe3 Nxd5 49. Bxd5 Nf5
50. Bc6 Nxe3 51. Bxd7 Nc2+ 52. Kd2 Nxa3 53.
Rd6 Rb8 54. Ba4 Nb1+ 55. Kc2 Na3+ 56. Kc1
Kh8

0s0Z0Z0j
Z0Z0ZpZ0
6
0Z0S0Z0Z
5
Z0Z0Z0oP
4
BZ0Z0Z0Z
3
mPZ0Z0Z0
2
0Z0Z0Z0Z
1
Z0J0Z0Z0
8
7

a

b

c

d

e

f

g

Nc2 64. Kxg4 Kf6 65. Be8 Ne3+ 66. Kf4 Nd5+
67. Ke4 Nc7 68. Bg6 Na6 69. Kd4 Kg5 70. Kc4
Kh6 71. Kb5 Nc7+ 72. Kc6 Na6 73. Kb5 Nc7+
74. Kc5 Kg7 75. Bd3 Kh6 76. Kd6 Ne8+ 77. Ke7
Ng7 78. Bg6 Nxh5 79. Bxh5 Kg5 80. Bd1 Kh4
81. Ke6 Kg5 82. Ke5 Kg6 83. b4 Kg5 84. b5 Kh6
85. Kf6 Kh7 86. b6 Kg8 87. b7 Kh7 88. b8=R
Kh6 89. Rh8# 1 â€“ 0

h

SKLBSNAN
1. e4 Nhg6 2. d4 c5 3. dxc5 Qxc5 4. Nhg3 Qa5 5.
c3 Bc7 6. Ne3 Nf4 7. Bc2 e6 8. a4 O-O-O 9. f3
Qa6 10. Rd1 f5 11. a5 d5 12. exd5 g6 13. Ba4
Re7 14. Nc2 Nxd5 15. Na3 e5 16. Nb5 Ne6 17.
Nxa7+ Kb8 18. Bb5

0j0s0ZbZ
Mpa0s0Zp
6
qZ0ZnZpZ
5
OBZnopZ0
4
0Z0Z0Z0Z
3
Z0O0ZPM0
2
0O0Z0ZPO
1
SKLRZ0A0
8
7

a

57.

b

c

d

e

f

g

h

Black queen is nearly trapped. 18...Qd6 19.
Ne2 Nc5 20. Ra3 MAVâ€“MCTS finds the time
for a prophylactic move in the middle of the
complications. e4 21. fxe4 fxe4 22. a6 Bb6 23.
axb7 Bxa7 24. c4 Rxb7

Rd5 The black knight is trapped on the edge
of the board! f5 58. Rxf5 g4 59. Rg5 Rg8 60.
Rxg8+ Kxg8 61. Kd2 Kf8 62. Ke3 Kg7 63. Kf4

56

Mastering Board Games by External and Internal Planning with Language Models

0j0s0ZbZ
7
arZ0Z0Zp
6
0Z0l0ZpZ
5
ZBmnZ0Z0
4
0ZPZpZ0Z
3
S0Z0Z0Z0
2
0O0ZNZPO
1
ZKLRZ0A0
8

a

b

c

d

e

f

g

h

25. Nd4 MAVâ€“MCTS adds fuel to the fire. Rc7
26. cxd5 Bxd5 27. Qg5 Bb6 28. Be3 Kb7 29.
Bf4 Qe7 30. Qxe7 Rxe7 31. Bg5 Red7 32. Bxd8
Rxd8 33. b4 Nd3 34. Nc2 Nf2 35. Ba6+ Kc7
36. Rd2 e3 37. Nxe3 Be4+ 38. Kc1 Nd3+ 39.
Bxd3 Bxe3 40. Kc2 Bxd2 41. Bxe4 The dust has
finally settled. Bxb4 42. Ra7+ Kb6 43. Rxh7
g5 44. Rb7+ Ka5 45. Bc6 Rd2+ 46. Kb3 Rd3+
47. Kc4 Rc3+ 48. Kd5 Ba3 49. Rb5+ Ka6 50.
Rb1 g4 51. Bd7 Rc2 52. Ra1 Rd2+ 53. Ke5 Kb6
54. Rxa3 Rxg2 55. Rb3+ Kc7 56. Ba4 Rxh2 57.
Rc3+ Kb8 58. Kd6 Rd2+ 59. Kc6 Rd8 60. Rb3+
Kc8 61. Bb5 Rd1 62. Re3 Rc1+ 63. Kb6 Rd1
64. Rc3+ Kb8 65. Re3 Rc1 66. Re7 Rc2 67. Re1
Rc3 68. Re4 Rc1 69. Bc4 Rb1+ 70. Bb5 Rc1 71.
Bc4 Rb1+ 72. Bb5 Rc1 (threefold repetition).
MAVâ€“MCTS decides to call it a day. 1/2 â€“ 1/2

Game 8
Only active pieces count
Date: 2024-11-14
White: Stockfishâ€“L20
Black: MAVâ€“MCTS( ğ‘€ = 100)
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/Nwy9BFqS

bsksqZna
o0o0Zpop
6
0o0onZ0Z
5
Z0Z0Z0Z0
4
0Z0ZPo0Z
3
ZPZPZ0Z0
2
PZPZNZPO
1
ARJRLNZB
8
7

a

b

c

d

e

f

g

h

6. g3 MAVâ€“MCTS sacrifices a pawn for a rapid
development. fxg3 7. Qxg3 Ne7 8. Ne3 d5 9.
exd5 Nxd5 10. Bxd5 Bxd5 11. Rf1 Bb7 12. Kd2
Rd7 13. Rbe1 g6 14. Bxh8 Qxh8 15. Nc3 O-O-O
16. Ng4 Qg7 17. Nf6 Rd4 18. Nb5 Rb4

0Zks0Z0Z
obo0Zplp
6
0o0ZnMpZ
5
ZNZ0Z0Z0
4
0s0Z0Z0Z
3
ZPZPZ0L0
2
PZPJ0Z0O
1
Z0Z0SRZ0
8
7

a

b

c

d

e

f

g

h

19. Nxc7 A stunning piece sacrifice that is
hard to grasp. Nxc7 20. Re7 Qh6+ 21. Kd1 Ne6

ARJRLNMB
1. e4 e5 2. b3 b6 3. d3 d6 4. f4 exf4 5. Ne2 Ne6

57

Mastering Board Games by External and Internal Planning with Language Models

0Zks0Z0Z
obZ0SpZp
6
0o0ZnMpl
5
Z0Z0Z0Z0
4
0s0Z0Z0Z
3
ZPZPZ0L0
2
PZPZ0Z0O
1
Z0ZKZRZ0
8
7

a

b

c

d

e

f

g

h

22. c4 MAVâ€“MCTS point is finally revealed â€“
the black rook is isolated from the rest of the
board! Qg5 23. Qxg5 Nxg5 24. Kc2 Nf3 25. Kc3
a5 26. Rxb7 Nxh2 27. Rf2 Kxb7 28. Rxh2 b5 29.
a3

0Z0s0Z0Z
ZkZ0ZpZp
6
0Z0Z0MpZ
5
opZ0Z0Z0
4
0sPZ0Z0Z
3
ZPJPZ0Z0
2
PZ0Z0Z0S
1
Z0Z0Z0Z0
8
7

a

b

c

d

e

f

g

Ke3 78. Na7 Kf4 79. Kc6 Rh6+ 80. Kb5 Rh1 81.
Kc6 Rh6+ 82. Kb5 Ke4 83. Kb4 Kd5 84. Nc8
Rh1 85. Rg5+ Kd4 86. Kb5 Rh8 87. Na7 Ke3
88. Kb6 Rh1 89. Rg8 Ra1 90. Rg4 Rc1 91. Rg6
Rb1+ 92. Kc6 Ra1 93. Rg7 Ke2 94. Rg2+ Kf1
95. Rg7 Rb1 96. Rg4 Rc1+ 97. Kb7 Rb1+ 98.
Ka6 Ra1+ 99. Kb5 Rxa7 100. Rg6 Ra8 101. Kc5
Kf2 102. Rb6 Ke3 103. Rb1 Ra5+ 104. Kd6 Ke4
105. Rb4+ Kf5 106. Rb6 Ra1 107. Kd5 Rd1+
108. Kc4 Ra1 109. Kd4 Ra4+ 110. Kd5 Ra5+
111. Kd4 Ra1 112. Rh6 Ra4+ 113. Kd3 Kg5
114. Rh7 Ra1 115. Ke4 Kg6 116. Rh2 Re1+ 117.
Kd3 Ra1 118. Ke4 Kf7 119. Rh7+ Kg6 120. Rh2
(threefold repetition). An extraordinary game
despite the outcome! 1/2 â€“ 1/2

Game 9
Returning knight
Date: 2024-11-14
White: Stockfishâ€“L19
Black: MAVâ€“MCTS( ğ‘€ = 500)
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/4VVNz4wX

MBANSQJR
1. e4 e5 2. f4 exf4 3. Qxf4 d5 4. O-O Ne6 5. Qh4
d4 6. c3 c5 7. b4 dxc3 8. dxc3 Nb6 9. Ne3 cxb4
10. cxb4 Qxb4 11. Nb3 h5 12. Qf2 f6 13. e5
Bxe5 14. Nf5 Nc4 15. Bd3 Bd7 16. Bxc4 Qxc4
17. Rxe5 fxe5 18. Nd6 Qg4 19. Qf7+ Kh7

h

The black rook gets trapped by a pawn.
29...Rxd3+ 30. Kxd3 Rxb3+ 31. Kd4 bxc4 32.
Rxh7 Kc6 33. Ne4 Rd3+ 34. Kxc4 Rxa3 35. Nc3
Ra1 36. Rxf7 Kd6 37. Rf6+ Ke5 38. Rxg6 Kf5
39. Rg8 Ke5 40. Rg4 Ke6 41. Rh4 a4 42. Rh2
Rg1 43. Ne2 Rb1 44. Rh5 a3 45. Ra5 Ra1 46.
Nd4+ Kd6 47. Rd5+ Ke7 48. Kb3 a2 49. Nc6+
Ke6 50. Rh5 Rg1 51. Kxa2 Rg2+ 52. Ka3 Kf6 53.
Rh1 Rg3+ 54. Ka4 Kf5 55. Ka5 Ra3+ 56. Kb6
Ra8 57. Rh5+ Ke4 58. Rh6 Ra1 59. Rh8 Rb1+
60. Ka6 Rb2 61. Na7 Ra2+ 62. Kb7 Rb2+ 63.
Kc8 Rb1 64. Rh6 Kf4 65. Ra6 Rh1 66. Kd8 Ke3
67. Ra5 Rh7 68. Ra1 Kd3 69. Nc8 Kc3 70. Rg1
Rh5 71. Kd7 Rh7+ 72. Ke6 Kc2 73. Rg8 Kd2 74.
Rg5 Rh6+ 75. Kd7 Rh7+ 76. Kd6 Rh4 77. Rg8

0Z0ZrZ0s
opZbZQok
6
0Z0MnZ0Z
5
Z0Z0o0Zp
4
0Z0Z0ZqZ
3
ZNZ0Z0Z0
2
PZ0Z0ZPO
1
Z0A0ZRJ0
8
7

a

b

c

d

e

f

g

h

20. Ne4 White finds a cute resource to force
the draw. Qxe4 21. Qxh5+ Kg8 22. Qf7+

58

Mastering Board Games by External and Internal Planning with Language Models

Kh7 23. Qh5+ Kg8 24. Qf7+ Kh7 25. Qh5+
(threefold repetition). 1/2 â€“ 1/2

7

Game 10
Harrysâ€™ deadlock
Date: 2024-11-14
White: Stockfishâ€“L19
Black: MAVâ€“MCTS( ğ‘€ = 1000)
Result: 0 â€“ 1
Online PGN: https://lichess.org/yBlOcUgM

AQSBMNJR
1. h4 h5

blranmks
opopopo0
6
0Z0Z0Z0Z
5
Z0Z0Z0Zp
4
0Z0Z0Z0O
3
Z0Z0Z0Z0
2
POPOPOPZ
1
AQSBMNJR
8
7

a

b

c

d

e

f

0Z0ZnZkZ
Z0opZ0o0
6
0Z0Z0o0Z
5
ZpS0M0Z0
4
0Z0Z0Z0Z
3
ZNZ0O0O0
2
rZ0Z0O0Z
1
Z0Z0Z0J0
8

g

a

b

c

d

e

f

g

h

25...d6 This zwischenzug, instead of immediately recapturing the knight, is the only way
to secure the advantage. 26. Rxb5 fxe5 27. f4
exf4 28. exf4 c5 29. Na5 Kf7 30. Rb7+ Ke6 31.
Nc4 Kd5 32. Ne3+ Ke4 33. Re7+ Kf3 34. Nf5
Ra1+ 35. Kh2 Nf6 36. Nh4+ Kf2 37. Nf5 d5 38.
Rc7 d4 39. Rxc5 d3 40. Rc3 d2 41. Rc2 Ne4 42.
Nxg7 Kf3 43. Rxd2 Nxd2 44. Nf5 Nf1+ 45. Kh3
Ne3 46. Kh4 Nxf5+ 47. Kg5 Nxg3 48. Kf6 Kxf4
49. Ke7 Nf5+ 50. Kd7 Rg1 51. Kc7 Ke5 52. Kc6
Ne7+ 53. Kc5 Rc1+ 54. Kb4 Kd4 55. Kb3 Re1
56. Kc2 Nc8 57. Kb3 Ra1 58. Kc2 Nb6 59. Kb2
Rg1 60. Ka3 Kc3 61. Ka2 Nc8 62. Ka3 Ra1#
0â€“1

h

Pushing h-pawns is one of the best ways to
start the game with this piece configuration
according to strong engines. 2. b4 b5 3. d3 a5
4. c3 e6 5. Nd2 Ng6 6. e3 axb4 7. cxb4 Bxh4 8.
Rh3 Qb6 9. g3 Bg5 10. Bd4 Qd6 11. Rxh5 e5 12.
Ba1 Rxh5 13. Bxh5 Qe6 14. Bf3 Bxf3 15. Nexf3
Be7 16. Qb2 Ra8 17. Rc2 Qd5 18. Qb3 Qxb3 19.
Nxb3 f6 20. Bc3 Ra4 21. d4 Bxb4 22. dxe5 Bxc3
23. Rxc3 Rxa2 24. Rc5 Nxe5 25. Nxe5

Game 11
Fianchettoing the rook
Date: 2024-11-14
White: Stockfishâ€“L20
Black: MAVâ€“MCTS( ğ‘€ = 2000)
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/S9V6YA1i

LBMRAKSN

59

Mastering Board Games by External and Internal Planning with Language Models

qansbjrm
opopopop
6
0Z0Z0Z0Z
5
Z0Z0Z0Z0
4
0Z0Z0Z0Z
3
Z0Z0Z0Z0
2
POPOPOPO
1
LBMRAKSN
8

Rc7+ Kf8 67. Rc8+ Ke7 (threefold repetition).
1/2 â€“ 1/2

7

a

b

c

d

e

f

g

0Z0sbjrZ
7
o0Z0opZ0
6
pa0m0Zpo
5
l0Z0Z0Z0
4
PZ0Z0S0Z
3
ZBZNZ0M0
2
0Z0ZPOPO
1
L0S0Z0J0
8

b

c

d

e

f

g

Bishops vs knights
Date: 2024-11-14
White: Stockfishâ€“L20
Black: MAVâ€“MCTS( ğ‘€ = 2000)
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/zYVQjKBA

ABMRLNJR

h

1. O-O Once in a lifetime opportunities should
be taken. Ng6 2. c4 c5 3. Ng3 Nb6 4. d4 cxd4 5.
Ba5 Ne5 6. c5 Nc6 7. b4 Nxa5 8. bxa5 Nc4 9. a6
d5 10. cxd6 Nxd6 11. Rxd4 Bc7 12. Rh4 h6 13.
a4 bxa6 14. Nd3 Qd5 15. Ba2 Qa5 16. Rc1 Bb6
17. Bb3 g6 18. Rf4

a

Game 12

h

18...Rg7 MAVâ€“MCTS decides to fianchetto the
rook. 19. Ne5 Kg8 20. e3 Kh7 21. h4 h5 22. Nc6
Bxc6 23. Rxc6 e6 24. Bc2 Kg8 25. Ne4 Nxe4 26.
Rxe4 Qd2 27. Qf6 Kh7 28. Re5 Kg8 29. Qf4 a5
30. Qf6 Qd7 31. Rc4 Rc8 32. Ree4 Kh7 33. g3
Rc7 34. Rxc7 Qxc7 35. Bd3 Qd7 36. Bb5 Qd5
37. Rc4 Qd8 38. Qxd8 Bxd8 39. Rd4 Bb6 40.
Rd7 Kg8 41. Rb7 Kf8 42. Rb8+ Ke7 43. Rb7+
Kf8 44. Rb8+ Ke7 45. Re8+ Kf6 46. Rh8 Ke7 47.
Re8+ Kf6 48. Kh2 Rh7 49. Rg8 Rg7 50. Rh8 Ke7
51. Re8+ Kd6 52. Kh3 Ke5 53. Kg2 Kd6 54. Rh8
Ke5 55. Bc4 Kd6 56. Bd3 Ke7 57. e4 f6 58. f4 e5
59. Kf3 exf4 60. gxf4 Bd4 61. Bb5 Bb2 62. Rc8
Ba1 63. Ke3 a6 64. Rc7+ Kf8 65. Rc8+ Ke7 66.

1. d4 d5 2. b3 h5 3. h4 b6 4. c4 e6 5. Nd3 dxc4
6. bxc4 c5 7. dxc5 Qc6 8. Ne3 bxc5 9. O-O Bc7
10. Ne5 Qe8 11. Rxd8 Qxd8 12. g3 f6 13. Nf3
Kf7 14. Bc2 Nd6 15. Qc3 Qc8 16. Ng5+ Ke7 17.
Nh3 Ne4 18. Qa3 Nd7 19. Nf4 Bxf4 20. gxf4
Qc7 21. f5 e5 22. Nd5+ Bxd5 23. cxd5 Nd6

0Z0Z0Z0s
7
o0lnj0o0
6
0Z0m0o0Z
5
Z0oPoPZp
4
0Z0Z0Z0O
3
L0Z0Z0Z0
2
PZBZPO0Z
1
A0Z0ZRJ0
8

a

b

c

d

e

f

g

h

Bishop pair against two knights imbalance
guarantees a complex middlegame 24. Kh2
Rg8 25. e4 g5 26. fxg6 Rxg6 27. Qh3 Kd8 28.
Bd1 Rg7 29. Qe3 Qa5 30. a3 Rg8 31. Re1

60

Mastering Board Games by External and Internal Planning with Language Models

0Z0j0ZrZ
o0ZnZ0Z0
6
0Z0m0o0Z
5
l0oPo0Zp
4
0Z0ZPZ0O
3
O0Z0L0Z0
2
0Z0Z0O0J
1
A0ZBS0Z0
8
7

a

b

c

d

e

f

g

h

31...f5 MAVâ€“MCTS breaks the rule of thumb
that the side with knights should keep the
position closed because open positions favour
a bishop pair. 32. Bxh5 Nxe4 33. Bf3 Nd2 34.
Bd1 Ne4 35. Rg1 Rxg1 36. Kxg1 c4 37. Bf3
Qxd5 38. h5 Qd6 39. Kg2 Qf6 40. Bxe4 fxe4 41.
Bc3 Qh4 42. h6 Ke7 43. Qh3 Qxh3+ 44. Kxh3
Kf6 45. h7 Kg7 46. Kg4 Kxh7 47. Kf5 Kg8 48.
Kxe4 Kf7 49. Kd5 Ke7 50. Bb4+ Kf7 51. Kxc4
Ke6 52. Kb5 Kd5 53. Bd2 Nf6 54. Be3 Ne4 55.
Bxa7 Nc3+ 56. Kb4 Ne4 57. Be3

0Z0Z0Z0Z
Z0Z0Z0Z0
6
0Z0Z0Z0Z
5
Z0Zko0Z0
4
0J0ZnZ0Z
3
O0Z0A0Z0
2
0Z0Z0O0Z
1
Z0Z0Z0Z0
8
7

a

b

c

d

e

f

g

Bg1 Ka8 82. Bc5 Kb8 83. a7+ Ka8 84. Kd5 Kb7
85. Ke5 Ka8 86. Kf6 Kb7 87. Bf2 Ka8 88. Ke5
Kb7 89. Kd6 Ka8 90. Bg1 Kb7 91. Bb6 Ka8 92.
Ke6 Kb7 93. Kf5 Ka8 94. Kg4 Kb7 95. Bc5 Ka8
96. Kf3 Kb7 97. Bb6 Ka8 98. Kf4 Kb7 99. Be3
Ka8 100. Ke5 Kb7 101. Kd6 Ka8 102. Ke6 Kb7
103. Kd5 Ka8 104. Ke5 Kb7 105. Bf2 Ka8 106.
Kf6 Kb7 107. Bd4 Ka8 108. Bf2 Kb7 109. Be3
Ka8 110. Bf2 (threefold repetition). This a draw
because the queening square is the opposite
color of the bishop. 1/2 â€“ 1/2

Game 13
The last resource
Date: 2024-11-14
White: Stockfishâ€“L17
Black: MAVâ€“MCTS( ğ‘€ = 100)
Result: 1/2 â€“ 1/2
Online PGN: https://lichess.org/QMfa5J52

SKSBANMQ
1. a4 a5 Like in Game 10, pushing the flank
pawns on the first move seems to be the
preferred choice when rooks are on the a/h
files with kings on the adjacent b/g files. 2.
e4 e5 3. Ne3 Ne6 4. g3 g6 5. f4 exf4 6. gxf4
Nxf4 7. Bg3 Ne6 8. Nc4 Ra6 9. Bf3 Ne7 10. e5
Nc6 11. Ne2 f5 12. d4 Ng5 13. d5 Nb4 14. Bg2
h5 15. Nc3 h4 16. Bf4 h3 17. Bf1 Nf7 18. Ra3
g5 19. Bg3 f4 20. Bf2 Nxe5 21. Nxe5 Qxe5 22.
Bxa6 bxa6 23. Rb3 c5 24. dxc6 Bf7 25. cxd7 Rc7
26. Na2 Bxb3 27. Nxb4 axb4 28. cxb3 Bf6 29.
d8=Q+ Bxd8 30. Re1 Qf5+ 31. Ka1

h

57...Nxf2 MAVâ€“MCTS correctly decides to
sacrifice a knight to steer the game towards a
theoretically drawn endgame. 58. Bxf2 Kd6
59. Ka5 Kc7 60. Ka6 Kb8 61. Be3 e4 62. Bf4+
Ka8 63. a4 e3 64. Bxe3 Kb8 65. Kb6 Ka8 66.
Bc5 Kb8 67. a5 Ka8 68. Bf2 Kb8 69. Ka6 Ka8 70.
Kb6 Kb8 71. Ka6 Ka8 72. Bd4 Kb8 73. Bg1 Ka8
74. Kb6 Kb8 75. Be3 Ka8 76. a6 Kb8 77. Bc1
Ka8 78. Ba3 Kb8 79. Bc5 Ka8 80. Kc6 Kb8 81.

61

Mastering Board Games by External and Internal Planning with Language Models

0j0a0Z0Z
7
Z0s0Z0Z0
6
pZ0Z0Z0Z
5
Z0Z0Zqo0
4
Po0Z0o0Z
3
ZPZ0Z0Zp
2
0O0Z0A0O
1
J0Z0S0ZQ
8

a

b

c

d

e

f

g

h

It is hard to believe that this position in equal
despite White effectively being two pawns
down and and all the pieces stuck at the first
two rows. 31...Rc2 32. Bd4 f3 33. Re8 Qd7 34.
Rxd8+ Qxd8

0j0l0Z0Z
Z0Z0Z0Z0
6
pZ0Z0Z0Z
5
Z0Z0Z0o0
4
Po0A0Z0Z
3
ZPZ0ZpZp
2
0OrZ0Z0O
1
J0Z0Z0ZQ
8
7

a

b

c

d

e

f

g

h

0Z0Z0Z0Z
Z0Z0Z0Z0
6
pZ0Z0L0Z
5
j0Z0A0o0
4
Po0Z0Z0Z
3
ZPZ0Z0Zp
2
KO0Z0Z0O
1
Z0sqZ0Z0
8
7

a

b

c

d

e

f

g

h

The drawing mechanism is mesmerizing.
41. Bc7+ Rxc7 42. Qb6+ Kxb6 43. a5+ Ka7
(stalemate).

0Z0Z0Z0Z
j0s0Z0Z0
6
pZ0Z0Z0Z
5
O0Z0Z0o0
4
0o0Z0Z0Z
3
ZPZ0Z0Zp
2
KO0Z0Z0O
1
Z0ZqZ0Z0
8
7

a

b

c

d

e

f

g

h

The final position speaks for itself! 1/2 â€“ 1/2

It is even harder to understand the equality
in this position. 35. Be5+ Ka7 36. Qxf3 Rc1+
37. Ka2 Qd1 38. Qf2+ Kb7 39. Qf7+ Kb6 40.
Qf6+ Ka5

62

Mastering Board Games by External and Internal Planning with Language Models

Opening Book
In each match-up between two agents, a specific opening is used, and agents swap seats to ensure
each agent plays each opening both as black and as white. The openings are listed in Table 4.
Table 4 | Table of the opening book used for chess. Openings were collected from various TCEC (Top
Chess Engine Championship) seasons. The scores were computed with Stockfish 16 with 1.5B nodes
per position. The scores are all from whiteâ€™s perspective (so negative values mean black is better) and
centipawns
were computed via:
100
Opening
QGD
Sicilian
Kingâ€™s Indian
KGA
Catalan opening
French
Nimzo-Indian
Robatsch (modern) defence
Budapest
Ruy Lopez
English
Sicilian defence
QGD
Pirc defence
Dutch
Caro-Kann
Kingâ€™s Indian
French
Trompovsky attack (Ruth, Opovcensky opening)
KGA
QGD
Sicilian
English
Scandinavian defence
Benoni defence
Giuoco Pianissimo
QGD Slav
Pirc defence
Kingâ€™s Indian
Sicilian
Queenâ€™s pawn
French
Queenâ€™s Indian
KGA
Bird
Robatsch defence
Benko gambit
Ruy Lopez
Benoni
Sicilian
QGD Slav
Caro-Kann
Kingâ€™s Indian
Scandinavian
Dutch, 2.Bg5 variation
French
English
KGA
Old Benoni defence
Sicilian
Kingâ€™s Indian
Sicilian
Dutch, 2.Bg5 variation
KGA
Benoni defence
French
English
Robatsch defence
Kingâ€™s Indian

FEN

Score

rnbqkbnr/pp3ppp/4p3/3P4/3p4/2N5/PP2PPPP/R1BQKBNR w KQkq - 0 5
rnbqkb1r/5ppp/p2ppn2/1p6/3NP3/P1N1B3/1PP2PPP/R2QKB1R w KQkq - 0 8
r1bq1rk1/ppp2pbp/n2p2p1/3Pp2n/2P1P3/2N2NPP/PP3P2/R1BQKB1R w KQ - 1 9
rnbqkb1r/pppp1ppp/8/4P2n/5p2/5N2/PPPP2PP/RNBQKB1R w KQkq - 1 5
rnbqkb1r/p2p1ppp/5n2/1ppP4/8/6P1/PP2PP1P/RNBQKBNR w KQkq - 0 6
r1bqkb1r/pppn1ppp/2n1p3/3pP3/3P4/1N3N2/PPP2PPP/R1BQKB1R b KQkq - 2 6
r2q1rk1/pb1p1ppp/1pn1p3/2b4n/1PP2B2/P1N2N2/2Q1PPPP/3RKB1R w K - 1 11
rnbqk1nr/1pp1ppbp/p2p2p1/8/3PP3/2N1B3/PPPQ1PPP/R3KBNR b KQkq - 1 5
r1bqk2r/pppp1ppp/2n5/4P3/1bP2Bn1/2N2N2/PP2PPPP/R2QKB1R b KQkq - 6 6
r1bq1rk1/2p1bppp/pnnp4/1p2p3/3PP3/1BP2N1P/PP3PP1/RNBQR1K1 w - - 1 11
rnbqkb1r/p1pp1ppp/5n2/1p4N1/2P1p3/2N5/PP1PPPPP/R1BQKB1R w KQkq - 0 5
r1b1kb1r/pp1p1ppp/1qn1pn2/8/4P3/1NN5/PPP2PPP/R1BQKB1R w KQkq - 0 7
rnbqkbnr/pp4pp/2p1p3/3p1p2/2PP4/2N1P3/PP3PPP/R1BQKBNR w KQkq - 0 5
r1bqkb1r/pppnppp1/3p1n1p/8/3PP1P1/2N5/PPP2P1P/R1BQKBNR w KQkq - 0 5
rnbqkbnr/ppp1p2p/6p1/3p1pB1/3P4/2N5/PPP1PPPP/R2QKBNR w KQkq - 0 4
rn1qkbnr/pp1bppp1/2p4p/3pP3/3P2PP/8/PPP2P2/RNBQKBNR w KQkq - 1 6
r1bq1rk1/pp2ppb1/3p1np1/2pPn3/2P1P2p/2N1BP2/PP2B1PP/R2QKN1R b KQ - 1 11
r1bqkbnr/ppp2ppp/2n1p3/3p4/3PP3/2N5/PPP2PPP/R1BQKBNR w KQkq - 2 4
r1b1kb1r/pp2pppp/2np1n2/q5B1/7Q/2N5/PPP1PPPP/2KR1BNR w kq - 2 7

0.47
0.67
0.62
-0.28
0.71
0.63
0.57
0.52
0.36
0.63
0.59
0.67
0.62
0.63
0.82
0.82
0.24
0.77
0.55

r1bqkbnr/pppp1ppp/2n5/8/2B1Pp2/8/PPPP2PP/RNBQK1NR w KQkq - 2 4
r1bqkbnr/ppp1pppp/2n5/3P4/2p5/2N5/PP2PPPP/R1BQKBNR b KQkq - 0 4
r1b2rk1/1pq1bppp/p1nppn2/8/3NP3/1BN1B3/PPP1QPPP/2KR2R1 b - - 5 11
r2qk2r/pb1nbppp/1p1ppn2/8/2PQP3/2N2NP1/PP3PBP/R1B2RK1 w kq - 1 10
rn2kb1r/pp2pppp/2p2n2/q3Nb2/3P4/2N5/PPP2PPP/R1BQKB1R w KQkq - 0 7
rn2k2r/ppqb1pbp/3p1np1/2pP4/5B2/1QN2N2/PP2PPPP/R3KB1R w KQkq - 6 10
r1bqk2r/ppp2p2/2np1n2/2b1p1pp/2B1P3/3P1NB1/PPP2PPP/RN1Q1RK1 w kq - 0 9
rn2kb1r/ppq2ppp/2p1pn2/3p4/2PP2bN/1QN1P3/PP3PPP/R1B1KB1R w KQkq - 4 8
rnbqkb1r/pp2pp1p/2pp1np1/8/3PP3/2N1B3/PPP2PPP/R2QKBNR w KQkq - 0 5
r1bq1rk1/pppnppb1/3p1np1/7p/2PPP3/2N3N1/PP2BPPP/R1BQK2R w KQ - 0 8
3q1rk1/p2bppb1/3p1np1/1pr1n1Bp/3NP1PP/1BN2P2/PPPQ4/1K1R3R b - - 0 15
rnbqkbnr/p1pp1ppp/1p2p3/8/2PP4/8/PP2PPPP/RNBQKBNR w KQkq - 0 3
rnbq1k1r/ppp2pp1/4p2p/3pP3/1b1Pn1Q1/2N1B3/PPP2PPP/R3KBNR w KQ - 4 8
rn1qk2r/p1p2ppp/bp1bp3/3n4/2NP4/1P4P1/P3PPBP/RNBQ1K1R w kq - 1 10
rnbqkbnr/ppp2ppp/3p4/8/2B1Pp2/5N2/PPPP2PP/RNBQK2R b KQkq - 1 4
rnbqk1nr/ppp2ppp/3b4/8/8/5N2/PPPPP1PP/RNBQKB1R b KQkq - 1 4
rnbqk1nr/pp2ppbp/2pp2p1/8/2BPP3/2N5/PPP2PPP/R1BQK1NR w KQkq - 0 5
rnbqkb1r/p2ppp1p/5np1/1ppP4/2P5/5N2/PP2PPPP/RNBQKB1R w KQkq - 0 5
r1bq1rk1/2p1bpp1/p1np1n1p/1p2p3/4P3/1BP2N1P/PP1P1PP1/RNBQR1K1 w - - 0 10
r1bqr1k1/pp3pbp/3p1np1/2pPn3/P3P3/R1N5/1P1NBPPP/2BQ1RK1 b - - 2 12
rnb1k2r/1pq2pbp/p2ppnp1/8/2PNP3/2NB4/PP2QPPP/R1B2RK1 w kq - 2 10
rnbqk2r/p3bppp/2p1p3/1p1nP3/P1pP4/2N2N2/1P2BPPP/R1BQK2R w KQkq - 2 9
rn1qkbnr/pp4pp/2p1ppb1/3pP3/3P2PP/2N5/PPP1NP2/R1BQKB1R b KQkq - 0 7
rnb2rk1/ppp2pbp/3p2p1/3Pp3/2n1P2Q/2N2P2/PP2K2P/R5NR w - - 0 13
rnb1kbnr/ppp1pppp/3q4/8/8/2N5/PPPP1PPP/R1BQKBNR w KQkq - 2 4
rnbqkbnr/ppppp2p/6p1/5pB1/3P4/8/PPP1PPPP/RN1QKBNR w KQkq - 0 3
r1b1k1r1/ppq1np1Q/2n1p3/3pP3/5P1P/P1p5/2P1N1P1/R1B1KB1R b KQq - 0 12
rnbqkb1r/pp2pppp/4n3/8/1pB1P3/2N2N2/P2P1PPP/R1BQ1K1R w kq - 0 10
rnbqkbnr/ppp2p1p/3p4/8/3PP1pN/2N2pP1/PPP4P/R1BQKB1R b KQkq - 1 7
rnbqkb1r/pp1ppppp/5n2/2pP4/8/5N2/PPP1PPPP/RNBQKB1R b KQkq - 0 3
r1b1k2r/2q1bppp/p2pp3/1pn2PP1/3NP3/2N2Q2/PPP4P/2KR1B1R w kq - 1 14
rnbq1rk1/ppp2pbp/3p1np1/3Pp3/2P1P3/2N1B3/PP2BPPP/R2QK1NR b KQ - 0 7
1rb1r1k1/2q1bppp/ppnppn2/8/P3PPP1/1NN1BB2/1PPQ3P/R4R1K w - - 1 16
rnbqkbnr/ppppp1pp/8/5pB1/3P4/8/PPP1PPPP/RN1QKBNR b KQkq - 1 2
rnbqkbnr/ppp2p1p/3p4/6p1/3PPp2/5N2/PPP3PP/RNBQKB1R w KQkq - 0 5
rnbqkb1r/pp1p1ppp/4pn2/2pP4/2P5/8/PP2PPPP/RNBQKBNR w KQkq - 0 4
r1b1k2r/pp1nbppp/1qn1p3/2ppP3/3P1P2/2P2NP1/PP3K1P/R1BQ1BNR b kq - 2 9
r3k2r/1bqnbppp/pp1ppn2/8/2PNP3/2N1B1P1/PP3PBP/R2QR1K1 w kq - 3 12
r1bqk1nr/ppp1ppbp/2np2p1/8/3PPP2/2N5/PPP3PP/R1BQKBNR w KQkq - 1 5
r1bq1rk1/ppp1n1bp/3p1np1/2PPpp2/1P2P3/2N5/P2NBPPP/R1BQ1RK1 w - - 2 12

-0.52
0.73
0.25
0.33
0.71
0.70
0.55
0.81
0.74
0.55
0.05
0.43
0.33
0.57
-0.42
0.52
0.69
0.55
0.53
0.62
0.84
0.00
0.63
0.51
0.81
0.70
0.14
0.58
-0.55
0.39
1.21
0.57
0.53
0.41
-0.26
0.78
0.37
0.37
0.95
1.14

63

Mastering Board Games by External and Internal Planning with Language Models

Sicilian
QGD
Ruy Lopez
Queenâ€™s Indian
Scandinavian defence
Kevitz-Trajkovich defence
Evans gambit
Kingâ€™s Indian
Sicilian
English opening
French
Kingâ€™s Indian
two knights defence
Queenâ€™s Indian accelerated
Caro-Kann
Kingâ€™s Indian
Sicilian
Dutch
Robatsch (modern) defence
Benoni
Danish gambit
Trompovsky attack (Ruth, Opovcensky opening)
French
Kingâ€™s Indian
Sicilian
QGD semi-Slav
Vienna gambit
Benko gambit
Pirc
QGD semi-Slav
Ruy Lopez
Kingâ€™s Indian
Sicilian
Dutch
Modern defence
Benoni defence
KGA
Queenâ€™s pawn game, Chigorin
variation
French
Kingâ€™s Indian
Sicilian
Kingâ€™s Indian
Sicilian
Dutch
KGA
Benoni
French
Robatsch defence
Kingâ€™s Indian
Sicilian
QGD semi-Slav
Ruy Lopez
Queenâ€™s Indian
Scandinavian
QGD
Vienna game
Kingâ€™s Indian
Sicilian
English opening
French
Neo-Gruenfeld defence
Two knights defence
English opening
Caro-Kann
Kingâ€™s Indian
Sicilian
Dutch defence
Robatsch (modern) defence
Old Benoni defence
Ruy Lopez
Trompovsky attack (Ruth, Opovcensky opening)
French

r2qkb1r/pp1bpppp/2np1n2/6B1/3NP3/2N5/PPPQ1PPP/R3KB1R b KQkq - 3 7
r1bqk2r/pp1n2pp/2pbp2n/3p1p2/2PP4/2N1PN2/PPQ1BPPP/R1B1K2R w KQkq - 4 8
r2qr1k1/1bpnbppp/p1np4/1p6/3PP3/1B3N1P/PP1N1PP1/R1BQR1K1 w - - 1 13
rn1q1rk1/p2nbppp/bpp1p3/3p4/2PP4/1PBN2P1/P3PPBP/RN1Q1RK1 b - - 5 11
rnbqkb1r/ppp1pppp/5n2/3P4/8/8/PPPP1PPP/RNBQKBNR w KQkq - 1 3
r1bqkb1r/pppppppp/2n2n2/8/2PP4/8/PP2PPPP/RNBQKBNR w KQkq - 1 3
r1b1k1nr/pppq1ppp/1bnp4/4p3/2BPP3/1QP2N2/P2N1PPP/R1B2RK1 b kq - 5 9
r1bq1rk1/ppp1ppbp/2np1np1/8/2PPP3/2N1BP2/PP4PP/R2QKBNR w KQ - 3 7
rnr3k1/1pq1bppp/p2pbn2/4p3/4P1P1/1NN1BP2/PPPQ3P/2KR1B1R w - - 1 12
r1bq1rk1/ppp3bp/2np1np1/4pp2/2P5/2NP1NP1/PP2PPBP/1RBQ1RK1 w - - 6 9
r1bq1rk1/pp2nppp/2n1p3/2ppP3/3P2Q1/P1PB4/2P2PPP/R1B1K1NR w KQ - 5 9
r1bqkb1r/pppn1ppp/3p1n2/4p3/2PP4/2N2N2/PP2PPPP/R1BQKB1R w KQkq - 2 5
r1bqkb1r/ppp2ppp/2n5/3np1N1/2B5/8/PPPP1PPP/RNBQK2R w KQkq - 0 6
r1bqkb1r/p1pppppp/1pn2n2/8/2PP4/5P2/PP2P1PP/RNBQKBNR w KQkq - 1 4
r2qkb1r/pp1nnppb/2p1p2p/3pP3/3P4/2P2N2/PP1NBPPP/R1BQ1RK1 w kq - 1 9
rnbq1rk1/ppp3bp/3p1pp1/4p3/2PPP1nB/2N2N2/PP2BPPP/R2QK2R b KQ - 1 9
r1bqkbnr/3p1ppp/p1n1p3/1p6/4P3/1BN2N2/PP3PPP/R1BQ1RK1 b kq - 1 8
rnbq1rk1/ppppb1pp/4pn2/5p2/2PP4/5NP1/PP2PPBP/RNBQK2R w KQ - 3 6
rnbqk1nr/pp1pppbp/6p1/2p5/3PP3/5N2/PPP2PPP/RNBQKB1R w KQkq - 0 4
r1bqr1k1/pp3pbp/3p1np1/2pPn3/P3P3/2N5/1P1NBPPP/R1BQ1RK1 w - - 1 12
rnbqkbnr/pppp1ppp/8/8/2B1P3/8/PB3PPP/RN1QK1NR b KQkq - 0 5
rnb1kb1r/pp1ppppp/1q3n2/2pP4/8/2P2P2/PP2P1PP/RNBQKBNR b KQkq - 2 7

0.36
0.38
0.85
0.53
0.77
0.50
-0.07
0.60
0.75
0.47
1.13
0.80
0.69
0.51
0.52
0.51
-0.43
0.53
0.91
0.87
-0.49
0.57

r1bqk2r/pp1nbppp/2n1p3/2ppP3/3P4/2PB1N2/PP1N1PPP/R1BQ1RK1 b kq - 2 8
rnbq1rk1/ppp2pbp/3p1np1/3Pp3/2P1P3/2N2N1P/PP3PP1/R1BQKB1R b KQ - 0 7
r1b2rk1/1pqp1ppp/p1n1pn2/8/1b1NP3/2N1BP2/PPPQ2PP/2KR1B1R w - - 1 10
rnbqkb1r/p4p2/2p1p3/4N2p/NppPn1pP/6B1/PP2BPP1/R2QK2R w KQkq - 0 13
r1bqkbnr/pppp1ppp/2n5/8/4Pp2/2N5/PPPP2PP/R1BQKBNR w KQkq - 0 4
rn1qkb1r/3ppp1p/b4np1/2pP4/8/2N5/PP2PPPP/R1BQKBNR w KQkq - 0 7
rnbqkb1r/pp2pp1p/2pp1np1/6B1/3PP3/2N5/PPPQ1PPP/R3KBNR b KQkq - 1 5
rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1
r2qkbnr/1ppb1ppp/p1np4/4p3/B3P3/2P2N2/PP1P1PPP/RNBQK2R w KQkq - 1 6
rnbq1rk1/ppp2pbp/3p1np1/4p3/2PPP3/2N1BP2/PP4PP/R2QKBNR w KQ - 0 7
1r1q1rk1/p4pbp/2p1b1p1/3np3/2B5/2N1BP2/PPP3PP/1K1RQ2R w - - 4 15
r1bq1rk1/ppp1p1bp/2np1np1/5p2/2PP4/2N2NP1/PP2PPBP/R1BQ1RK1 w - - 2 8
rnbqk1nr/ppp1ppbp/3p2p1/8/2PPP3/8/PP3PPP/RNBQKBNR w KQkq - 0 4
rnbq1rk1/1p3pbp/p2p1np1/2pP4/P4B2/2N1PN1P/1P3PP1/R2QKB1R b KQ - 0 10
rnb1kbnr/pppp1ppp/8/8/2B1Pp1q/8/PPPP2PP/RNBQ1KNR b kq - 3 4
r1bqkbnr/ppp1pppp/2n5/3p4/3P4/5N2/PPP1PPPP/RNBQKB1R w KQkq - 2 3

0.32
0.33
0.65
0.16
-0.53
0.80
0.49
0.27
0.58
0.77
0.75
0.91
0.60
0.62
-0.62
0.54

rnbqk2r/pppnbppp/4p3/3pP1B1/3P3P/2N5/PPP2PP1/R2QKBNR b KQkq - 0 6
r1bq1rk1/pppnn1bp/3p2p1/3Ppp2/2P1P3/2NN4/PP2BPPP/R1BQ1RK1 w - - 0 11
r1bqkbnr/1p3pp1/p1npp2p/8/3NP1PP/2N5/PPP2P2/R1BQKB1R w KQkq - 0 8
r1bq1rk1/pppnnpbp/3p2p1/3Pp3/2P1P3/2N5/PP2BPPP/R1BQNRK1 w - - 3 10
r1b1k2r/1pq1bppp/p1nppn2/8/3NPP2/P1N1BQ2/1PP3PP/2KR1B1R b kq - 3 10
rnbqkb1r/ppppp2p/5np1/5p2/3P1B2/2N1P3/PPP2PPP/R2QKBNR b KQkq - 1 4
rnbqkbnr/ppp2p1p/3p4/8/3PPppP/5N2/PPP3P1/RNBQKB1R w KQkq - 0 6
rnbqk2r/1p3pbp/p2p1np1/2pP4/4P3/2N3N1/PP3PPP/R1BQKB1R w KQkq - 0 9
rnbqk2r/pp2nppp/4p3/2ppP3/3P2Q1/P1P5/2P2PPP/R1B1KBNR b KQkq - 2 7
r1bqk1nr/2pnppbp/p2p2p1/1p6/3PPP2/2NB1N2/PPP3PP/R1BQK2R w KQkq - 2 7
r1b2rk1/pp1n1pbp/1qpp1np1/8/2PNP3/2N3PP/PP3PB1/R1BQR1K1 b - - 0 11
r1bqkb1r/pp3ppp/3p2n1/1N1Pp3/2P5/8/PP3PPP/R1BQKB1R w KQkq - 1 10
r1b2rk1/pp1nqppp/2p1p3/3p4/2PPn1P1/4PN2/PPQ2P1P/2KRBBR1 b - - 4 12
r1bqk2r/1pp1bppp/p1np1n2/4p3/B3P3/2P2N2/PP1P1PPP/RNBQR1K1 b kq - 0 7
r2q1rk1/pb1pbppp/np2pn2/2p5/2PP4/P1N2NP1/1PQBPPBP/R3K2R w KQ - 0 10
rnb1kb1r/ppp1pppp/3q1n2/8/3P4/2N2N2/PPP2PPP/R1BQKB1R b KQkq - 2 5
r2q1rk1/pb1nbppp/1p3n2/2pp2B1/3P4/2NBPN2/PPQ2PPP/2KR3R w - - 0 11
N2k1b1r/pb1p4/1pnn1qp1/4pp1p/8/1B1Q4/PPPPNPPP/R1B1K2R w KQ - 0 13
rnbq1rk1/ppp2pbp/3p2p1/3Pp2n/2P1P3/2NB4/PP2NPPP/R1BQK2R w KQ - 3 8
rnbqk1nr/1p1pbppp/p3p3/8/4P3/1N1B4/PPP2PPP/RNBQK2R w KQkq - 4 7
r1bq1rk1/1ppp1ppp/2n2n2/p3p3/1bP1P3/2NP2P1/PP3PBP/R1BQK1NR w KQ - 1 7
r1bq1rk1/1p1n1ppp/p1n1p3/2bpP3/3N1P2/2N1B3/PPPQ2PP/2KR1B1R w - - 0 11
r1bq1rk1/ppp1p1bp/1nn3p1/4P3/3P1p2/2N1BP2/PP1Q2PP/2KR1BNR w - - 0 11
r1bqkb1r/p4ppp/2p5/n3p1N1/5n1P/3B4/PPPP1PP1/RNBQK2R w KQkq - 1 10
rnbqkbnr/p1pp1ppp/1p2p3/8/2P5/2N5/PP1PPPPP/R1BQKBNR w KQkq - 0 3
rnbqkb1r/pp2pppp/2p2n2/3p4/4P3/2N2Q2/PPPP1PPP/R1B1KBNR w KQkq - 2 4
r1bq1rk1/pp1nppbp/3p1np1/2pP4/2P1P3/2N1BP1N/PP4PP/R2QKB1R b KQ - 0 8
rnb1kb1r/2qp1ppp/pp2pn2/8/2PNP3/P1N5/1P3PPP/R1BQKB1R w KQkq - 0 8
rnbq1rk1/pp4pp/2pbpn2/3p1p2/2PP4/6PN/PPQ1PPBP/RNB2RK1 w - - 4 8
rnbqk1nr/2p1ppbp/p2p2p1/1p6/3PP2P/2N1B3/PPPQ1PP1/R3KBNR b KQkq - 0 6
rnb1kb1r/p2ppppp/1q3n2/1ppP2B1/8/5N2/PPP1PPPP/RN1QKB1R w KQkq - 2 5
r2q1rk1/1ppbbppp/p1np1n2/4p3/B2PP3/2P2N2/PP3PPP/RNBQR1K1 w - - 5 9
rnb1kb1r/pp1ppppp/1q3n2/2pP4/4PB2/2P2P2/PP4PP/RN1QKBNR b KQkq - 0 7

0.17
0.50
0.93
0.57
0.72
0.68
-0.26
0.70
0.46
0.87
0.51
0.50
0.36
0.30
0.94
0.58
0.50
0.72
0.67
0.80
0.23
0.76
0.42
0.17
0.49
0.63
0.42
0.64
0.57
0.39
0.67
0.57
0.00

r1b1kb1r/pp1n1ppp/2n1p3/q1ppP3/N2P1P2/2P1BN2/PP4PP/R2QKB1R b KQkq - 0 9

0.74

64

Mastering Board Games by External and Internal Planning with Language Models

Kingâ€™s Indian
Sicilian
QGD
Giuoco Pianissimo
Benko gambit
Pirc defence
Old Indian
Ruy Lopez
Kingâ€™s Indian
Sicilian
Dutch
Robatsch defence
Queenâ€™s pawn game
KGA
QGD
French
Kingâ€™s Indian
Sicilian
QGD semi-Slav
Sicilian
Kingâ€™s Indian
Vienna game
Dutch defence
French
Benoni
Robatsch (modern) defence
Budapest defence
Sicilian defence
Kingâ€™s Indian
Ruy Lopez
QGD Slav
Owen defence
Queenâ€™s Indian
Sicilian
Kingâ€™s Indian
Sicilian
English opening
French
Semi-Benoni (â€˜blockade variationâ€™)
Scandinavian
Benko gambit
Caro-Kann
Kingâ€™s Indian
Sicilian
Dutch defence, Blackburne variation
Pirc defence
Benoni defence
two knights defence
Trompovsky attack (Ruth, Opovcensky opening)
Reti
Kingâ€™s Indian
Sicilian
QGD Slav
KP
Benoni
Pirc defence
QGD
Ruy Lopez
Sicilian defence
Dutch
Kingâ€™s Indian
Nimzo-Indian
two knights defence
Queenâ€™s pawn game, Chigorin
variation
French
Kingâ€™s Indian
Sicilian
Sicilian
Kingâ€™s Indian
French
QGD

r1bq1rk1/pppnppbp/3p1np1/8/2PPP3/2N2N2/PP2BPPP/R1BQK2R w KQ - 4 7
r1b1k2r/1p1nbppp/pq1ppn2/6B1/4PP2/1NN2Q2/PPP3PP/2KR1B1R b kq - 6 10
r1bqkb1r/ppp2ppp/2n1pn2/3p4/2PP4/2N2N2/PP2PPPP/R1BQKB1R w KQkq - 2 5
r1bqk2r/bppn1p2/2np3p/p3p1p1/2B1P3/2PP1NB1/PP1N1PPP/R2Q1RK1 w kq - 2 11
rn1qkb1r/pb1ppppp/5n2/1ppP4/2P5/5N2/PP2PPPP/RNBQKB1R w KQkq - 2 5
rnbqk2r/pp2ppbp/2pp1np1/8/3PP3/2N1B2P/PPP2PP1/R2QKBNR w KQkq - 1 6
rn1qkbnr/ppp1pppp/3p4/8/3P2b1/5N2/PPP1PPPP/RNBQKB1R w KQkq - 2 3
r1bq1rk1/2pnbppp/p1np4/1p2p3/4P3/1BP2N1P/PP1P1PP1/RNBQR1K1 w - - 1 10
r1b1qrk1/1pp2pbp/n2p1np1/p2Pp1B1/2P1P3/2N4P/PP1NBPP1/R2QK2R b KQ - 5 10
rn1qk2r/1b1nbppp/p2pp3/1p4P1/3NP2P/P1N5/1PP2P2/R1BQKB1R w KQkq - 1 11
r1bq1rk1/ppp1p1bp/5np1/3Ppp2/2P5/2N3P1/PP2PPBP/R1BQ1RK1 w - - 0 10
rnbqk1nr/pp2ppb1/2p3p1/3pP2p/3P1P2/2N5/PPP3PP/R1BQKBNR w KQkq - 0 6
rnbqkb1r/pp1p1ppp/4pn2/2pP4/2P5/5N2/PP2PPPP/RNBQKB1R b KQkq - 0 4
rnbqkb1r/pppp1p1p/8/4P1pn/5p2/5N2/PPPPB1PP/RNBQ1RK1 b kq - 1 6
r1bqr1k1/p2nbppp/2p2n2/1p1p2B1/3P4/2NBP3/PPQ1NPPP/2KR3R w - - 0 11
rnb1k2r/pppn1ppp/4p3/3pP1q1/3P4/2N5/PPP2PP1/R2QKBNR w KQkq - 0 8
rnbq1rk1/ppp2pbp/3p1np1/3Pp3/2P1P3/2N1B2P/PP3PP1/R2QKBNR b KQ - 0 7
2rq1rk1/pp1bppbp/3p1np1/4n3/3NP3/1BN1BP2/PPPQ2PP/1K1R3R b - - 6 12
rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR b KQkq - 0 1
rnbqkb1r/1p3ppp/p2ppn2/8/3NP1P1/2N5/PPP2P1P/R1BQKB1R w KQkq - 0 7
r1bq1rk1/ppp1n1bp/3p1np1/3Pp3/2P1Pp2/2NN1P2/PP1BB1PP/R2Q1RK1 w - - 0 13
r1bqkb1r/pppp3p/2nn2p1/1N2pp2/8/1B3Q2/PPPP1PPP/R1B1K1NR w KQkq - 0 8
rnbq1rk1/ppp3bp/3ppnp1/5p2/2PP4/2N2NP1/PP2PPBP/R1BQ1RK1 w - - 0 8
rnbqk1nr/p1p2ppp/1p2p3/3pP3/1b1P4/2N5/PPP2PPP/R1BQKBNR w KQkq - 0 5
rnbqkb1r/pp3p1p/3p1np1/2pP4/8/2N5/PP1NPPPP/R1BQKB1R b KQkq - 1 7
rnbqkbnr/1pp1pp1p/p2p2p1/8/3PP3/2N5/PPP2PPP/R1BQKBNR w KQkq - 0 4
rnbqkb1r/pppp1ppp/8/4P3/2P3n1/8/PP2PPPP/RNBQKBNR w KQkq - 1 4
r1b1kb1r/pp1p1ppp/1qn1pn2/8/4P3/1NN5/PPP1QPPP/R1B1KB1R b KQkq - 1 7
1r1q1rk1/1ppbppbp/p1np1np1/8/2PPP3/2N1BP2/PP1QN1PP/2R1KB1R w K - 4 10
r1bqkbnr/ppp3pp/2n5/1B1pp3/4N3/5N2/PPPP1PPP/R1BQK2R w KQkq - 0 6
rn1qkb1r/pp1npppp/2p5/7b/P1NP4/2N2P2/1P2P1PP/R1BQKB1R b KQkq - 0 8
rn1qkbnr/pbpp1ppp/1p2p3/8/3PP3/3B1N2/PPP2PPP/RNBQK2R b KQkq - 1 4
rnbqkb1r/p2p1ppp/1p2pn2/2p5/2PP4/P4N2/1P2PPPP/RNBQKB1R w KQkq - 0 5
rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1
r1b1nrk1/pp1n1pbp/1qp3p1/2p1P3/4P3/2N2NPP/PP3PB1/R1BQ1RK1 w - - 1 12
r4rk1/pp1bppbp/2np1np1/q7/2BNP3/2N1BP2/PPPQ2PP/2KR3R w - - 7 11
r1bqkbnr/pppppppp/2n5/8/2P5/8/PP1PPPPP/RNBQKBNR w KQkq - 1 2
r2qkb1r/1b1n1ppp/p1n1p3/1pppP3/3P1P2/4BN2/PPPQ2PP/R2NKB1R w KQkq - 2 10
rnbqkbnr/pp3ppp/3p4/2pPp3/4P3/8/PPP2PPP/RNBQKBNR w KQkq - 0 4

0.76
-0.05
0.54
0.45
0.56
0.73
0.89
0.64
0.21
0.43
0.87
0.69
0.46
-0.78
-0.32
0.32
0.61
0.89
0.11
1.39
0.85
0.58
0.78
1.07
0.59
0.65
0.78
0.43
0.66
0.63
1.00
0.86
0.91
0.15
0.87
0.84
0.56
0.54
1.43

rnb1kb1r/1pp1pppp/p2q1n2/8/3P4/2N2NP1/PPP2P1P/R1BQKB1R b KQkq - 0 6
r1bqkb1r/p2ppppp/n4n2/1ppP4/2P5/8/PPQ1PPPP/RNB1KBNR w KQkq - 2 5
rn1qkbnr/pp3ppp/4p1b1/2ppP3/3P2P1/2N5/PPP1NP1P/R1BQKB1R w KQkq - 0 7
rnb2rk1/pp2ppbp/3p1np1/8/2P1P3/1NP1p2P/P4PP1/R2QKB1R w KQ - 0 11
rnb1kb1r/1pqp1ppp/p3pn2/8/3NP3/3B4/PPP2PPP/RNBQ1RK1 w kq - 4 7
rnbqkb1r/ppp3pp/4pn2/3p1p2/3P4/6PN/PPP1PPBP/RNBQK2R w KQkq - 0 5

0.97
0.57
0.00
-0.30
0.58
0.53

r1bqkb1r/pppn1pp1/3p1n1p/4p3/3PP1P1/2N4P/PPP2P2/R1BQKBNR w KQkq - 0 6
rnbq1rk1/pp1p1ppp/3b1n2/2pP4/4PP2/2N5/PP4PP/R1BQKBNR b KQ - 0 7
r1bq1b1r/ppp3pp/4k3/3np3/1nB5/2N2Q2/PPPP1PPP/R1B1K2R w KQ - 4 9
rnb1kb1r/pp1ppppp/1q3n2/2pP2B1/8/2N5/PPP1PPPP/R2QKBNR b KQkq - 2 4

0.74
0.61
0.64
0.32

r1bq1rk1/p2nbppp/2n1p3/1pppP3/8/3P1NP1/PPP2PBP/R1BQRNK1 b - - 2 10
rnbqk2r/ppppppbp/5np1/8/2PP4/2N5/PP2PPPP/R1BQKBNR w KQkq - 2 4
rqb1k1nr/1p1p1ppp/1Bn1p3/1N6/1b2P3/8/PPP2PPP/R2QKB1R w KQkq - 1 10
rnbqkb1r/p3pppp/2p2n2/1p6/2pPP3/2N2N2/PP3PPP/R1BQKB1R w KQkq - 0 6
r1bqkbnr/pppppppp/2n5/8/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 1 2
rnbqk2r/pp1n1pbp/3p2p1/2pP4/4PP2/2N5/PP2B1PP/R1BQK1NR b KQkq - 4 9
rnbqk2r/ppp1ppbp/3p1np1/8/3PP3/2N1B3/PPPQ1PPP/R3KBNR b KQkq - 3 5
r3kbnr/ppp2ppp/2n5/3qp3/3P4/4PP2/PP3P1P/RNBQKB1R w KQkq - 0 7
r2qrbk1/1bp2pp1/p2p1n1p/8/pn1PP3/5N1P/1P1N1PP1/RBBQR1K1 w - - 0 16
rnb2rk1/1p2bppp/pq1ppn2/8/4PB2/1NN5/PPPQ1PPP/2KR1B1R w - - 6 10
rnbqkb1r/pp2p1pp/2pp1n2/5p2/2PP4/2N2N2/PP2PPPP/R1BQKB1R w KQkq - 2 5
rnbqkbnr/pp1ppp1p/2p3p1/8/3PP3/8/PPP2PPP/RNBQKBNR w KQkq - 0 3
rn1q1rk1/pbpp1ppp/1p2pn2/4P3/1bPP4/2NB4/PP3PPP/R1BQK1NR b KQ - 0 7
r1bqk2r/pppp1ppp/2n2n2/2b1p1N1/2B1P3/8/PPPP1PPP/RNBQK2R w KQkq - 6 5
2kr1bnr/pppqpppp/2n5/3p4/3P2b1/2P2NP1/PP2PPBP/RNBQ1RK1 b - - 0 6

-0.23
0.62
-0.41
0.00
0.48
0.70
0.46
0.84
0.39
1.00
0.69
0.84
0.49
1.21
0.85

rnbqkbnr/p1p2ppp/1p2p3/3pP3/3P4/8/PPP2PPP/RNBQKBNR w KQkq - 0 4
r1bq1rk1/pppnn1bp/3p4/3Pp1p1/2P1Pp2/2N2P2/PP2BBPP/R2QNRK1 w - - 0 13
r1bq1rk1/1p2bppp/p1nppn2/8/3NP3/2N1BP2/PPPQ2PP/2KR1B1R w - - 5 10
rnbqkbnr/pp1ppppp/8/2p5/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2
r1bq1rk1/ppp1npbp/3p1np1/3Pp3/2P1P3/2N1BN2/PP2BPPP/R2QK2R w KQ - 1 9
rnb1k1nr/ppq3pp/4p3/2ppPp2/3P2Q1/P1P5/2P2PPP/R1B1KBNR w KQkq f6 0 8
rnbqkbnr/p5pp/2p1pp2/1p6/2pP4/2N2N2/PP1BPPPP/R2QKB1R w KQkq - 0 7

1.00
0.52
0.78
0.38
0.89
1.45
0.69

65

Mastering Board Games by External and Internal Planning with Language Models

KGA
Dutch defence
Robatsch (modern) defence
Budapest
Sicilian
Kingâ€™s Indian
Ruy Lopez
Queenâ€™s Indian
Caro-Kann
Blackmar gambit
Pirc
Benoni defence
Sicilian
Kingâ€™s Indian
French
Trompovsky attack (Ruth, Opovcensky opening)
Scotch
Nimzo-Indian
Robatsch defence
QGD semi-Slav
Dunst (Sleipner, Heinrichsen)
opening
Sicilian
Kingâ€™s Indian
Philidor
Dutch, 2.Bg5 variation
KP
Czech Benoni defence
French
Bogo-Indian defence, Gruenfeld
variation
Sicilian
Kingâ€™s Indian
Latvian counter-gambit
QGD Slav
Scandinavian defence
English
Robatsch defence
Kingâ€™s Indian
Sicilian
QGD
KGA
Benoni
French
Dutch
Petrov
Sicilian
Sicilian
Kingâ€™s Indian
French
QGD Slav
KGA
Dutch, 2.Bg5 variation
Robatsch defence
Gruenfeld defence
Ruy Lopez
Queenâ€™s Indian
Scandinavian defence
Blumenfeld counter-gambit accepted
Pirc defence
Benoni
Sicilian
Kingâ€™s Indian
French
Trompovsky attack (Ruth, Opovcensky opening)
Ruy Lopez
Nimzo-Indian
Robatsch (modern) defence
Queenâ€™s Indian accelerated
Bird
Sicilian
Kingâ€™s Indian

r1bqkbnr/ppp2p1p/2np4/1B6/3PPB2/2N2Q2/PPP3PP/R3K2R b KQkq - 2 8
r1b1qrk1/ppp1p1bp/n2p1np1/5p2/2PP4/1P3NP1/PB2PPBP/RN1Q1RK1 w - - 1 9
r1bqk2r/ppp1ppbp/2np1np1/4P3/2BP4/2N5/PPP1QPPP/R1B1K1NR b KQkq - 0 6
rnbqkb1r/pppp1p1p/8/4P1p1/2P2Bn1/8/PP2PPPP/RN1QKBNR w KQkq - 0 5
r1b1kb1r/2q2p1p/p2ppP2/1pn5/3NP3/2N2Q2/PPP4P/2KR1BR1 b kq - 2 16
r1b1qrk1/ppp2pbp/n2p1np1/3Pp1B1/2P1P1P1/2N2N1P/PP3P2/R2QKB1R b KQ - 0 9
r1bqk2r/ppppnppp/2n5/1Bb1p3/4P3/2P2N2/PP1P1PPP/RNBQK2R w KQkq - 1 5
rn2kb1r/pbnpqppp/1p6/2p5/4P3/P2B1N2/1PQ2PPP/RNB2RK1 w kq - 2 11
rnb1kb1r/pp3ppp/1q2p3/2ppP3/3P4/3B1NP1/PPP3PP/R1BQK2R b KQkq - 0 9
rnbqkb1r/pp2pppp/2p2n2/8/3P4/2N2N2/PPP3PP/R1BQKB1R w KQkq - 0 6
rnb1kb1r/pp3ppp/2pp1n2/q3p3/3PPP2/2NB1N2/PPP3PP/R1BQK2R b KQkq - 1 6
rnbq1rk1/pp1p1ppp/3b1n2/2pP4/8/2N3P1/PP2PP1P/R1BQKBNR w KQ - 1 7
r1bq1rk1/pp1nppbp/2np2p1/8/2BNP3/2N1BP2/PPPQ2PP/R3K2R w KQ - 5 10
r1bq1rk1/ppp2pb1/3p1npp/2nPp3/2P1P3/2N1B3/PP1QBPPP/R3K1NR w KQ - 3 10
r1bqk2r/2pnbppp/1pn1p3/p2pP3/P2P4/1NP2N2/1P3PPP/R1BQKB1R w KQkq - 0 9
rnb1kb1r/pp1ppp1p/1q3np1/2pP4/8/2P2P2/PP2P1PP/RNBQKBNR w KQkq - 0 8

-0.73
0.71
-0.07
1.17
0.99
0.99
0.71
0.96
0.68
-0.53
0.93
0.74
1.17
0.83
1.16
0.87

r1b1kbnr/pppp1ppp/2n5/8/3NP2q/8/PPP2PPP/RNBQKB1R w KQkq - 1 5
rn1q1rk1/pb1p2pp/4pn2/1Pp5/1b6/2NBP3/PP3PPP/R1BQK1NR w KQ - 1 9
r1bqk2r/ppp1ppbp/2np1np1/8/3PPP2/2N1BN2/PPP3PP/R2QKB1R b KQkq - 4 6
r1bq1rk1/pp1nbpp1/2p1pn1p/3p4/2PP1BP1/2N1PN2/PPQ2P1P/R3KB1R b KQ - 0 9
rn1qkbnr/ppp3pp/4bp2/4p3/3pP3/5NN1/PPPP1PPP/R1BQKB1R w KQkq - 0 6

0.97
0.53
0.79
0.36
-0.60

rnbqk2r/pp1p1ppp/4pn2/8/1b1NP3/2N5/PPP2PPP/R1BQKB1R w KQkq - 3 6
r1bqnrk1/ppp1n1bp/3p2p1/3Pp3/2P1Pp2/2N2P2/PP2BBPP/R2QNRK1 b - - 1 12
rnbqk2r/ppp2pbp/3p1np1/8/3NP3/2N1B3/PPP2PPP/R2QKB1R w KQkq - 2 7
rnbqk1nr/ppp1p1bp/6p1/3p1pB1/3P4/2N2P2/PPPQP1PP/R3KBNR b KQkq - 0 5
r2qkbnr/ppp1pppp/2np4/8/3PP1b1/5N2/PPP2PPP/RNBQKB1R w KQkq - 1 4
r1bqkb1r/pp1n1p1p/3p1np1/2pPp3/2P1P3/2N2N2/PP3PPP/R1BQKB1R w KQkq - 0 7
r1bqkb1r/ppp1nppp/2n1p3/3pP3/3P4/2N5/PPP2PPP/R1BQKBNR w KQkq - 1 5
rnbq1rk1/pp1nbppp/4p3/2ppP3/2PP3P/P2B1N2/1P1N1PP1/R1BQK2R b KQ - 0 9

0.92
0.74
1.08
0.67
1.41
1.26
1.05
0.34

r1b1kb1r/p1qp1pp1/1pn1p2p/2p1P2P/5B2/2P2N2/PPPQ1PP1/R3KB1R w KQkq - 0 10
r1bq1rk1/pp3pbp/3ppnp1/2pPn3/2P1P3/2N1BPN1/PP4PP/R2QKB1R w KQ - 0 10
rnbqkbnr/pppp2pp/8/4pp2/4P3/2N2N2/PPPP1PPP/R1BQKB1R b KQkq - 1 3
rnbqkbnr/pp4pp/2p1p3/3p1p2/2PP4/2N2N2/PP2PPPP/R1BQKB1R w KQkq - 0 5
rn1qkb1r/ppp1pppp/1n6/8/2PP2b1/5N2/PP3PPP/RNBQKB1R w KQkq - 1 6
r1b1kb1r/pp1p1p1p/4p3/1N2n1p1/Q1P2Bn1/2N3P1/PP1KPq1P/R4B1R w kq - 0 11
rnbqk1nr/1pp2pbp/p2pp1p1/8/3PPP2/2N2N2/PPP3PP/R1BQKB1R w KQkq - 0 6
rnbq1rk1/ppp3bp/3p2p1/3Ppp1n/2P1P3/2N1BP2/PP1Q2PP/R3KBNR w KQ - 0 9
rnb1kb1r/2q2ppp/p3pn2/1p2P1B1/3N4/2N5/PPP3PP/R2QKB1R w KQkq - 1 10
r3kbnr/pppq1ppp/2n1p3/8/3P4/2N1PP2/PP3P1P/R1BQKB1R w KQkq - 2 8
r1b1k1nr/ppppqp1p/2n5/3P4/1b2P1pN/2N2pP1/PPP4P/R1BQKB1R w KQkq - 1 9
r1bqr1k1/pp3pbp/n2p1np1/2pP4/4P3/2N5/PP1NBPPP/R1BQ1RK1 w - - 7 11
rnb1k1nr/pppq2pp/4p3/3pPp2/1b1P2Q1/2N5/PPP2PPP/R1B1KBNR w KQkq f6 0 6
rnb1qrk1/ppp1b1pp/3ppn2/5p2/2PP4/2N2NP1/PP2PPBP/R1BQ1RK1 w - - 2 8
rnbq3r/ppp1bkpp/3p1n2/8/3PP3/8/PPP2PPP/RNBQKB1R w KQ - 1 6
r1bqkb1r/1p3pp1/p1nppn2/7p/3NP1PP/2N1B3/PPP2P2/R2QKBR1 w Qkq - 0 10
rnbqkb1r/1p2pppp/p2p1n2/8/3NP3/2N5/PPP2PPP/R1BQKB1R w KQkq - 0 6
r1bq1rk1/ppp1npbp/3p1np1/3Pp3/2P1P3/2N2N2/PP2BPPP/R1BQ1RK1 w - - 1 9
rnbqkbnr/ppp2ppp/4p3/3pP3/3P4/2N5/PPP2PPP/R1BQKBNR w KQkq - 1 5
rn1qkb1r/pb3ppp/2p1p3/1p1nP3/P1pPN3/5N2/1P2BPPP/R1BQK2R b KQkq - 3 9
rnbqkbnr/pppp1p1p/8/6p1/4Pp2/2N2N2/PPPP2PP/R1BQKB1R b KQkq - 1 4
rnbqk1nr/ppppp1b1/6pp/5pB1/3P4/2N2N2/PPP1PPPP/R2QKB1R w KQkq - 0 5
rnbqk2r/ppp1npbp/3pp1p1/8/3PPP2/2N2N2/PPP3PP/R1BQKB1R w KQkq - 2 6
r2q1rk1/ppp1ppbp/1nn3p1/8/3PP1b1/1QN1BN2/PP3PPP/3RKB1R w K - 7 11
rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2
rn1qk2r/p1p2ppp/bp1bpn2/4N3/2pP4/1P4P1/P3PPBP/RNBQ1K1R w kq - 4 9
rnbqkbnr/ppp1pppp/8/3p4/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2
rnbqkb1r/p2p2pp/4pn2/1Pp5/8/5N2/PP2PPPP/RNBQKB1R b KQkq - 0 6

1.19
0.46
1.28
1.17
1.33
-0.13
0.95
0.77
0.68
0.93
1.08
0.89
1.33
0.94
-0.47
0.86
0.32
0.73
1.16
-0.29
-0.68
1.15
0.87
1.02
0.25
0.97
0.66
0.58

rnbq1rk1/ppp1ppbp/3p1np1/8/3PP3/2N1BP2/PPP3PP/R2QKBNR w KQ - 3 6
rnbqkb1r/pp3p1p/3p1np1/2pP4/8/2N2N2/PP2PPPP/R1BQKB1R w KQkq - 0 7
1rb2rk1/2qp1ppp/p2bpn2/1p2n3/3BPP2/1NN3Q1/PPP3PP/2KR1B1R b - - 0 14
r1bq1rk1/pp1n1pbp/2pp1np1/4p3/2PPP3/2N2N2/PPQ1BPPP/R1B2RK1 w - - 0 9
rnbqk1nr/ppp2ppp/4p3/3pP3/1b1P4/2N5/PPP2PPP/R1BQKBNR b KQkq - 0 4
rnb1kb1r/pp1ppppp/1q6/2pP4/4nB2/8/PPPNPPPP/R2QKBNR b KQkq - 4 5

0.62
0.72
0.88
0.85
0.49
-0.29

r2qkbnr/2p2pp1/p2p4/1p2p2p/3nP1b1/1B3N1P/PPP2PP1/RNBQ1RK1 w kq - 0 9
rnbq1bk1/pp1p1ppp/3Prn2/8/8/P1N3P1/1P2NP1P/R1BQKB1R w KQ - 1 12
rnbqkbnr/pppppp1p/6p1/8/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2
rn1qkb1r/pbpp1ppp/1p2pn2/8/2PP4/2N2P2/PP2P1PP/R1BQKBNR w KQkq - 0 5
rnbqkbnr/pppp1ppp/8/4p3/5P2/8/PPPPP1PP/RNBQKBNR w KQkq - 0 2
r1bqkb1r/pp3ppp/2nppn2/8/3NP1P1/2N5/PPP2P1P/R1BQKB1R w KQkq - 1 7
r1bq1rk1/pppn2bp/3p1pp1/4p1B1/2PPP1n1/2N2N2/PP2BPPP/R2Q1RK1 w - - 0 10

0.89
0.49
0.69
0.91
0.66
1.20
0.92

66

Mastering Board Games by External and Internal Planning with Language Models

KGD
Dutch defence
Alekhineâ€™s defence
Czech Benoni defence
French
Benko gambit
Sicilian
Kingâ€™s Indian
Four knights
QGD Slav
Caro-Kann
English
Robatsch defence
Kingâ€™s Indian
Sicilian
QGD
Ruy Lopez
Benoni defence
French
Dutch
Vienna
Kingâ€™s Indian
Sicilian
Latvian
Nimzo-Indian
Robatsch (modern) defence
Robatsch (modern) defence
Ruy Lopez
Dutch, 2.Bg5 variation
Budapest
Sicilian
Kingâ€™s Indian
QGD semi-Slav
French
Kingâ€™s Indian
Trompovsky attack (Ruth, Opovcensky opening)
Queenâ€™s pawn
Bird
Sicilian
Robatsch (modern) defence
Dutch defence
Ruy Lopez
Caro-Kann
Kingâ€™s Indian
QGD semi-Slav
Queenâ€™s Indian
QGD
Benoni
Queenâ€™s Indian accelerated
Benoni
Owen defence
Robatsch (modern) defence
Philidor
French
QGD Slav
Old Indian
Sicilian
French
Dutch defence
Sicilian
Scandinavian
Kingâ€™s Indian
Sicilian
Sicilian
Ruy Lopez
Sicilian
Old Benoni defence
Sicilian
Benoni defence
QGD semi-Slav
Czech Benoni defence
Sicilian
French
English

rnb1kbnr/pppp1ppp/5q2/4p3/4PP2/8/PPPP2PP/RNBQKBNR w KQkq - 1 3
r1bqkb1r/ppppp2p/2n2np1/5p2/3P4/6PN/PPP1PPBP/RNBQK2R w KQkq - 2 5
rn1qk2r/ppp1bppp/3pp3/3nP3/3P2b1/5N2/PPP1BPPP/RNBQ1RK1 w kq - 2 7
rnbqkb1r/pp1p1ppp/5n2/2pPp3/2P5/8/PP2PPPP/RNBQKBNR w KQkq e6 0 4
rnbqkb1r/ppp2pp1/4pn1p/3p4/3PP3/2NB4/PPP2PPP/R1BQK1NR w KQkq - 2 5
rn1qkb1r/4pp1p/3p1np1/2pP4/4P3/2N5/PP3PPP/R1BQ1KNR w kq - 0 9
r1b1kb1r/pp3ppp/1q1ppn2/4n3/4PB2/1NN5/PPP2PPP/R2QKB1R w KQkq - 2 9
r1bq1rk1/ppp1ppbp/2np1np1/8/2PPP3/2N2N1P/PP3PP1/R1BQKB1R w KQ - 3 7
r1bqkb1r/pppp1ppp/2n2n2/8/3PP3/2N5/PPP2PPP/R1BQKB1R w KQkq - 1 6
r1bqkb1r/pp2pppp/n1p2n2/8/P1pP4/2N2N2/1P2PPPP/R1BQKB1R w KQkq - 1 6
2kr1b1r/ppqnnpp1/2p1p2p/3pPb2/3P4/2P2N2/PP1NBPPP/R1BQR1K1 w - - 4 10
rnbqkb1r/p1n2ppp/4p3/1p6/1pBPP2P/5N2/P3NPP1/R1BQ1K1R w kq - 0 13
rnbqk1nr/pp2ppbp/2pp2p1/8/3PPP2/2N5/PPP3PP/R1BQKBNR w KQkq - 0 5
r1bq1rk1/1p1n1pbp/p2p1np1/3Pp3/4P1P1/2N1BP2/PP1QN2P/R3KB1R b KQ - 0 11
r1b2rk1/1pq1bppp/p1nppn2/8/3NPP2/P1N1BQ2/1PP3PP/2KR1B1R w - - 4 11
r1bqkbnr/ppp1pppp/2n5/8/2pP4/2N5/PP2PPPP/R1BQKBNR w KQkq - 0 4
r2qr1k1/1bpn1ppp/p1np1b2/1p6/3PP3/1B3N1P/PP1N1PP1/1RBQR1K1 w - - 3 14
rnbqk2r/pp1p1ppp/3b1n2/2pP4/8/2N2N2/PP2PPPP/R1BQKB1R b KQkq - 2 6
rnb1k1nr/pppq1ppp/4p3/3pP3/1b1P4/2N5/PPP2PPP/R1BQKBNR w KQkq - 1 5
rnbqkb1r/pppp3p/4pnp1/5p2/3P4/5NP1/PPP1PPBP/RNBQK2R w KQkq - 0 5
N1bk1b1r/p2pq2p/1pnn2p1/3Qpp2/8/1B6/PPPP1PPP/R1B1K1NR w KQ - 0 11
r1bq2k1/pppnn1bp/3p1r2/3Pp1p1/2P1Pp2/2N2P2/PP2BBPP/2RQNRK1 w - - 2 14
r1bqkb1r/pp2pp2/2np1np1/7p/3NP3/2N1BP2/PPP3PP/R2QKB1R w KQkq - 0 8
rnbqkbnr/pppp2pp/8/4pp2/2B1P3/5N2/PPPP1PPP/RNBQK2R b KQkq - 1 3
rn1q1rk1/pbp2p1p/1p2pPp1/6B1/1bpP2Q1/2N5/PPB2P1P/2KR2N1 w - - 2 13
rnbqkbnr/pp2pp1p/2pp2p1/8/3PPP2/2N5/PPP3PP/R1BQKBNR b KQkq - 0 4
r1bqk2r/2pnppbp/p2p1np1/1p6/3PP1PP/2N1BP2/PPPQ4/R3KBNR b KQkq - 0 8
r2qk2r/ppp2ppp/2p5/2b1p3/4P1b1/3P1N2/PPP2P2/RNBQ1RK1 w kq - 0 10
rnbqkbnr/ppppp1pp/8/5p2/3P4/8/PPP1PPPP/RNBQKBNR w KQkq - 0 2
rnbqkb1r/pppp1ppp/8/4P3/2P1P1n1/8/PP3PPP/RNBQKBNR b KQkq - 0 4
rnbqkbnr/pp1ppppp/8/8/1p2P3/P7/2PP1PPP/RNBQKBNR b KQkq - 0 3
r1bq1rk1/ppp1n1bp/3p1n2/3Pp1p1/2P1Pp2/2NN1P2/PP2B1PP/R2QBRK1 w - - 0 14
r2qk2r/pb1n1ppp/2pbpn2/1p6/3P2P1/2N1PN2/PPQ1BP1P/R1B1K2R w KQkq - 2 10
rnbqk1nr/ppp1bppp/4p3/3pP3/3P4/2N5/PPP2PPP/R1BQKBNR b KQkq - 0 4
rnbqk2r/ppp1ppbp/3p1np1/8/2PPP3/2N5/PP3PPP/R1BQKBNR w KQkq - 0 5
rnb1kb1r/pp2pppp/1q1p1n2/2pP4/8/2P2P2/PP2P1PP/RNBQKBNR w KQkq - 0 8

1.08
0.77
0.91
1.27
1.27
0.92
1.28
0.83
-0.54
0.84
0.78
1.12
0.95
0.72
0.81
0.83
0.92
1.27
1.01
0.84
0.89
0.82
0.66
0.00
1.21
0.35
0.56
0.00
0.59
0.64
-0.48
0.59
0.48
0.44
0.60
0.69

rn1qk1nr/pbpp1ppp/1p2p3/8/1bPPP3/3B4/PP3PPP/RNBQK1NR w KQkq - 3 5
rnbqk1nr/ppp2p1p/3b4/6p1/8/5NP1/PPPPP2P/RNBQKB1R b KQkq - 0 5
r1b1kbnr/pp1ppppp/1qn5/1Bp5/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 4 4
r1bqk1nr/pppnppbp/3p2p1/8/3PP3/2N1B3/PPP2PPP/R2QKBNR w KQkq - 2 5
rnbqkbnr/ppppp2p/6p1/5p2/3P4/6P1/PPP1PP1P/RNBQKBNR w KQkq - 0 3
r1b1k2r/2q1bppp/p2p1n2/npp1p3/3PP3/2P2N2/PPB2PPP/RNBQR1K1 w kq - 1 11
rn1qkbnr/pp1b1pp1/4p2p/2ppP2P/3P1PP1/2P5/PP6/RNBQKBNR b KQkq - 0 8
rnbq1rk1/1pp2pbp/3p1np1/p2Pp3/2P1P3/2N1B3/PP2BPPP/R2QK1NR w KQ - 0 8
r3kb1Q/pb1n1p1p/2p1p3/q7/3P4/8/P2NBPPP/q1BQK2R b Kq - 2 14
rn1qkb1r/p2p1ppp/bp2pn2/2pP4/2P5/P4N2/1PQ1PPPP/RNB1KB1R b KQkq - 2 6
r3k1nr/p1p2ppp/1pnq4/4p3/3P4/2P1PP2/P2B1P1P/1R1QKB1R w Kkq - 0 11
rnbqk2r/pp3pbp/3p1np1/2pP4/4PP2/2N5/PP4PP/R1BQKBNR w KQkq - 1 8
r1bqkb1r/p1ppnppp/1p3n2/3Pp3/2P3P1/2N2P2/PP2P2P/R1BQKBNR b KQkq - 0 6
r1bqkb1r/pp1n1p1p/3p1np1/2pP4/8/2N5/PP1NPPPP/R1BQKB1R w KQkq - 2 8
rnbqkbnr/p1pppppp/1p6/8/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2
rnbqkbnr/pp2pp1p/2pp2p1/8/2PPP3/8/PP3PPP/RNBQKBNR w KQkq - 0 4
r2q1rk1/1pp1bppp/p2pbn2/8/3QPB2/2N2P2/PPP3PP/2KR1B1R w - - 0 11
rnb1kbnr/p1pq1ppp/1p2p3/3pP3/3P3P/8/PPP2PP1/RNBQKBNR w KQkq - 1 5
rn1qkb1r/pp2pppp/2p2n2/4N2b/P1pP4/2N5/1P2PPPP/R1BQKB1R w KQkq - 3 7
r1bq1rk1/pp1nbppp/2pp1n2/4p3/2PPP3/2N2N2/PP2BPPP/R1BQ1RK1 w - - 0 8
r1bq1rk1/1p1nbppp/p1npp3/8/3NP1P1/2N1BP2/PPPQ3P/2KR1B1R w - - 1 11
rnbqk1nr/p1p2ppp/1p2p3/3pP3/1b1P3P/2N5/PPP2PP1/R1BQKBNR b KQkq - 0 5
rnb1qrk1/ppp1p1b1/3p1npp/3P1p2/2P5/2N2NP1/PP2PPBP/R1BQ1RK1 w - - 0 9
r1r3k1/pp1bppbp/2np1np1/q7/3NP3/1BN1BP2/PPPQ2PP/2KR3R w - - 9 12
rnb1kb1r/1pp1pppp/p2q1n2/8/3P4/2N2N2/PPP2PPP/R1BQKB1R w KQkq - 0 6
r1b2rk1/pp1n1pbp/1qpp1np1/4p3/2PPP3/2N2NPP/PP3PB1/R1BQ1RK1 w - - 1 10
rnbqk2r/pp2bppp/3ppn2/8/3NP1P1/2N5/PPP2P1P/R1BQKB1R w KQkq - 1 7
2rq1rk1/pp1bppbp/3p1np1/4n3/3NP3/1BN1BP2/PPPQ2PP/1K1R3R b - - 10 12
r2qrbk1/1b3p2/p2p1npp/1ppP4/Pn2P3/5N1P/1P1N1PP1/RBBQR1K1 w - - 0 17
rn1q1rk1/1p2bppp/3pbn2/p3p3/4P3/1NN1BP2/PPPQ2PP/2KR1B1R w - - 0 11
rnbqkbnr/pp1p1ppp/8/2pPp3/8/8/PPP1PPPP/RNBQKBNR w KQkq e6 0 3
r2qkb1r/3b1pp1/p2ppn1p/1p2n3/3NP1P1/2N1BP2/PPPQ3P/2KR1B1R w kq - 1 12
r1bq1rk1/pp2ppbp/n2p1np1/2pP4/2P1P3/2N2N1P/PP3PP1/R1BQKB1R w KQ - 1 8
r3kb1r/1bqn1ppp/p4n2/1p1Pp3/2pNP3/2N5/PPB2PPP/R1BQ1RK1 w kq - 0 14
rnbqkb1r/pp3ppp/3p1n2/2pPp3/2P1P3/2N5/PP3PPP/R1BQKBNR b KQkq - 0 5
r2q1rk1/1p1bppbp/p1np1np1/8/3NP1P1/2N1B2P/PPPQ1P2/2KR1B1R w - - 1 11
rnbqk2r/pp1nbppp/4p3/2ppP1B1/3P3P/2N5/PPP2PP1/R2QKBNR w KQkq - 0 7
rnbqkb1r/ppp1pp2/6pp/3n4/7P/2N2N2/PP1PPPP1/R1BQKB1R w KQkq - 0 6

0.92
0.42
0.75
0.67
0.81
0.90
0.71
0.82
0.33
0.75
0.76
1.04
0.79
0.84
0.97
0.85
0.81
1.02
0.75
0.85
0.77
1.10
0.83
0.76
1.11
1.05
1.19
0.72
1.08
1.13
1.39
1.04
1.09
0.69
1.16
0.85
0.88
0.86

67

Mastering Board Games by External and Internal Planning with Language Models

Sicilian
St. George defence
Dutch, 2.Bg5 variation
Robatsch (modern) defence
English opening
French
Sicilian
French
Scandinavian (centre counter) defence
Robatsch defence
French
QGA
Old Indian
Sicilian
QGD Slav
English
Kingâ€™s Indian defence
Queenâ€™s pawn, Mason variation,
Steinitz counter-gambit
Sicilian
Robatsch (modern) defence
Caro-Kann
French
KP
Sicilian
Kingâ€™s Indian
Dutch
Robatsch (modern) defence
Kingâ€™s Indian
Neo-Gruenfeld defence
Vienna
French
Ruy Lopez
Trompovsky attack (Ruth, Opovcensky opening)
KGA
English
Sicilian
English opening
Kingâ€™s Indian
French
Kingâ€™s Indian
QGD
French
Ruy Lopez
Queenâ€™s pawn game
Petrov
English opening
Sicilian
French
Robatsch (modern) defence
Queenâ€™s pawn
Owen defence
Kingâ€™s Indian defence
Pirc
Scandinavian (centre counter) defence
Dutch, Korchnoi attack
QGD
Kingâ€™s Indian
Sicilian, Szen, hedgehog variation
Kingâ€™s Indian
Benoni
Queenâ€™s Indian
French
French
Caro-Kann
Kingâ€™s Indian
Ruy Lopez
Dutch
Kingâ€™s Indian
Polish defence
Ruy Lopez

rnbqkb1r/pp3ppp/3ppn2/8/3NP1P1/2N5/PPP2P1P/R1BQKB1R b KQkq - 0 6
rnbqkbnr/2pp1ppp/p3p3/1P6/3PP3/8/PP3PPP/RNBQKBNR b KQkq - 0 4
rnbqkb1r/ppppp2p/6pn/5pB1/3P4/2N5/PPP1PPPP/R2QKBNR w KQkq - 2 4
r1bqk1nr/2pnppb1/p2p2p1/1p5p/3PP2P/2N1BP1N/PPPQ2P1/R3KB1R b KQkq - 1 8
r1bqkbnr/ppp1np1p/3p4/3Pp3/2P3p1/2N2NP1/PP2PP1P/R1BQKB1R w KQkq - 1 7
rnbqkb1r/p2n1ppp/4p3/1pppP3/3P4/2PB4/PP1N1PPP/R1BQK1NR w KQkq - 0 7
rn1q1rk1/1p2bppp/p2pbn2/4p3/4P1P1/1NN1B3/PPP1BP1P/R2QK2R w KQ - 1 10
rnbqkb1r/ppp1nppp/4p3/3p4/3PP3/8/PPPN1PPP/R1BQKBNR w KQkq - 2 4
rnb1kbnr/ppp1pp1p/6p1/3q4/8/5N2/PPPP1PPP/RNBQKB1R w KQkq - 0 4

0.48
0.74
0.81
0.60
1.09
0.95
0.88
0.78
0.84

rnbqk1nr/2p1ppbp/pp1p2p1/8/P2PP3/2N2N2/1PP2PPP/R1BQKB1R w KQkq - 0 6
r1bqk1nr/pp3ppp/2n1p3/2ppP3/3P4/P1P5/2P2PPP/R1BQKBNR w KQkq - 1 7
r1bqkb1r/ppp1nppp/5n2/3Pp3/2p1P3/2N1B3/PP3PPP/R2QKBNR w KQkq - 1 7
rn1qkbnr/ppp1pppp/3p4/8/2PP4/5P2/PP3PPP/RNBQKB1R b KQkq - 0 4
r1b1kb1r/1pq2pp1/p1nppn1p/8/3NPPP1/2N1B2P/PPP5/R2QKB1R w KQkq - 1 10
rn1qkb1r/1p2pppp/p1p2n2/2Pp4/3P2b1/2N2N2/PP2PPPP/R1BQKB1R w KQkq - 1 6
1qr1k2r/pb1nbppp/1p1ppn2/8/2PNPP2/2N1B1P1/PP4BP/R2QR1K1 w k - 1 13
r1bqkb1r/pp1n1p1p/3p1np1/2pPp3/2P1P3/5P2/PP2N1PP/RNBQKB1R w KQkq - 1 7
r1b1kbnr/pp3ppp/1qn5/3pp3/2pP1B2/2P1P3/PPQ2PPP/RN2KBNR w KQkq - 0 7

0.82
0.71
0.75
0.91
0.85
0.89
0.79
1.10
0.05

r1bqkb1r/1p1npp2/p2p1n1p/6p1/3NP3/2N3B1/PPP1QPPP/R3KB1R b KQkq - 1 9
rnbqk1nr/ppp2pbp/3pp1p1/8/3PP3/2N1B3/PPP2PPP/R2QKBNR w KQkq - 0 5
rn2kbnr/pp2ppp1/1qp5/3pPb1p/3P1B1P/3B4/PPP2PP1/RN1QK1NR b KQkq - 3 6
r1bqkbnr/p1p2ppp/1pn1p3/3pP3/3P4/2N5/PPP2PPP/R1BQKBNR w KQkq - 0 5
r1bqkb1r/pppnpppp/2n5/3pP3/3P4/2N5/PPP2PPP/R1BQKBNR w KQkq - 1 5
rnb1k2r/1pq1bppp/p2ppn2/8/3NP3/2N1B3/PPPQBPPP/R3K2R w KQkq - 4 9
r2q1rk1/1ppbppbp/p1np1np1/6B1/2PPP3/2N2P2/PP1QN1PP/R3KB1R w KQ - 2 9
rnb1qrk1/ppp1b1pp/3ppn2/5p2/1PPP4/2N2NP1/P3PPBP/R1BQ1RK1 b - - 0 8
rnbqk2r/pp2npbp/3pp1p1/2pP4/2P1P3/2N2N2/PP3PPP/R1BQKB1R w KQkq - 2 7
r2q1rk1/ppp1ppbp/3p1np1/n2P4/2P3b1/2N2NP1/PP2PPBP/R1BQ1RK1 w - - 1 9
r1bq1rk1/ppp2pbp/1nn3p1/4p3/3PP3/2N1BP2/PP1Q2PP/2KR1BNR w - - 0 10
1k1r3r/pPp2ppp/5n2/1Nb5/3P1pbq/5N2/PPP1K1PP/R1BQ1B1R w - - 3 11
rnbqk2r/pp3p2/4p1pp/3pP3/3pn1Q1/P1PB4/2P2PPP/R1B1K1NR w KQkq - 0 11
r1bn1rk1/2q1bppp/p2p1n2/1ppPp3/4P3/2P2N1P/PPBN1PP1/R1BQR1K1 w - - 1 14
r1bqkb1r/pp3p1p/2n2p2/2ppp3/3P4/2P1PN2/PP2BPPP/RN1QK2R b KQkq - 1 7

0.86
1.20
0.00
1.11
1.21
1.03
0.99
0.86
1.07
1.01
0.81
0.94
0.76
1.11
-0.67

rnbqkb1r/pppp1p1p/5n2/4N3/3PPppP/8/PPP3P1/RNBQKB1R b KQkq - 0 6
r1bqk1nr/pp1p1pbp/4p1p1/1N6/1pP5/6P1/3PPPBP/R1BQK1NR b KQkq - 1 8
r1bq1rk1/1p2ppbp/p1np1np1/8/2BNP3/2N1BP2/PPPQ2PP/R3K2R w KQ - 0 10
rn1qk2r/pbppppbp/1p4p1/3P4/2P1n3/5NP1/PP2PPBP/RNBQK2R w KQkq - 1 7
r1bq2k1/pppnn1bp/3p1r2/2PPp1p1/1P2Pp2/2NN1P2/P3B1PP/R1BQ1RK1 w - - 1 14
rnb1k1nr/ppp2ppp/4p3/3q4/1b1P4/2N5/PPP2PPP/R1BQKBNR w KQkq - 0 5
r1bq1rk1/ppp2pb1/2np1npp/4p3/2PPP3/2N1BN2/PP2BPPP/R2Q1RK1 w - - 2 9
rnbqkb1r/ppp1pppp/8/3n4/3P4/8/PP2PPPP/RNBQKBNR w KQkq - 0 4
r1bqk2r/ppp1nppp/2n1p3/b2pP3/3P4/P1N5/1PP1NPPP/R1BQKB1R w KQkq - 1 7
r1bq1rk1/pppn1ppp/2np1b2/1B2p3/3PP3/2P2N2/PP3PPP/RNBQR1K1 w - - 1 9
r1bq1rk1/pp3pbp/n2ppnp1/2pP4/2P1P3/2NB1N1P/PP3PP1/R1BQK2R w KQ - 3 9
rnbq1b1r/ppp2k1p/3p1np1/8/3PP3/8/PPP2PPP/RNBQKB1R w KQ - 0 6
rnbqkb1r/ppp1pp1p/5np1/8/7P/2N2N2/PP1PPPP1/R1BQKB1R w KQkq - 1 6
rnb1kb1r/1pq2pp1/p2ppn1p/8/3NP1P1/2N1BQ2/PPP2P1P/R3KB1R w KQkq - 2 9
r1bq1rk1/p2nbppp/1pn1p3/2ppP3/3P1P2/P1N1BN2/1PPQ2PP/2KR1B1R b - - 1 10
r1bqk2r/2p1ppb1/p1np1np1/1p5p/3PP2P/2N1BP2/PPPQ2P1/2KR1BNR w kq - 3 9
rn1qk1nr/pbpp1ppp/1p2p3/8/2PP4/2N5/PP1QPPPP/R3KBNR w KQkq - 2 6
rn1qkb1r/pb1p1ppp/1p2pn2/2p5/3PP3/2PB1N2/PP2QPPP/RNB1K2R b KQkq - 2 6
rnbqkb1r/pppppp1p/6p1/7n/2PP4/5P2/PP2P1PP/RNBQKBNR w KQkq - 1 4
rnbqkb1r/pp2pppp/2pp1n2/8/3PP3/2N5/PPP2PPP/R1BQKBNR w KQkq - 0 4
rn1qkb1r/pp3ppp/2p1pn2/8/3P4/2N1BQ1P/PPP2PP1/R3KB1R w KQkq - 0 9

-0.89
-1.27
1.06
0.77
1.10
0.94
0.96
1.07
1.06
0.92
1.21
-0.73
1.13
1.16
-1.07
0.95
1.09
0.85
0.84
0.96
0.87

rnbqkb1r/ppppp1pp/8/8/3P2n1/8/PPP1PP2/RNBQKBNR w KQkq - 0 5
r1b1k2r/pp1n1ppp/2pb1n2/q2p2B1/3P4/2NBPN2/PP3PPP/R2QK2R w KQkq - 2 9
r1bq1rk1/ppp1n1bp/3p1np1/3Pp3/P1P1Pp2/2N1BP2/1P2B1PP/R2QNRK1 w - - 0 13
rq3rk1/3bbppp/ppnppn2/8/2P1P3/N1N1B3/PP2BPPP/2RQ1RK1 w - - 4 13

1.13
0.95
0.97
0.68

r1bq1rk1/2pnppbp/p2p1np1/1p6/2PPP3/2N1BP2/PP1Q2PP/2KR1BNR w - - 0 9
rnbq1rk1/p4pbp/1p1p1np1/2pP4/4P3/2N3N1/PP2BPPP/R1BQK2R w KQ - 0 10
r2q1rk1/pb1nbppp/1p1ppn2/8/2PNP3/P1N1B3/1PQ1BPPP/2KR3R w - - 6 12
rnbqkb1r/pp3ppp/2n1p3/2ppP3/3P4/2P2N2/PP3PPP/RNBQKB1R w KQkq - 3 6
r1b1kb1r/p2n1ppp/1pn1p3/q1ppP3/N2P1P2/2P1BN2/PP4PP/R2QKB1R w KQkq - 0 10
r2qk1nr/pp1n1ppp/2p1p3/b2pPb2/3P4/5N2/PPPNBPPP/R1BQ1RK1 w kq - 6 8
rnb2rk1/ppp2pbp/3p2p1/3Pp2n/2P1P2q/2N1BP2/PP1Q2PP/R3KBNR w KQ - 3 9
r1bqkb1r/ppppn1pp/5n2/1B2pP2/8/3P1N2/PPP2PPP/RNBQK2R w KQkq - 1 6
r1bq1rk1/ppp1p1b1/5npp/3Ppp2/2P5/1QN3P1/PP2PPBP/R1B2RK1 w - - 0 11
rnbq1rk1/pp1p1pbp/4pnp1/2pP4/2P1P3/2N2P2/PP4PP/R1BQKBNR w KQ - 0 7
rnbqkbnr/p1pppppp/8/1p6/3P4/8/PPP1PPPP/RNBQKBNR w KQkq - 0 2
r1bq1rk1/2p1bppp/p1n2n2/P2pp3/1p2P3/1B3N2/1PPP1PPP/RNBQR1K1 w - - 0 10

1.12
0.81
1.00
0.81
0.82
0.81
1.15
0.81
0.92
0.73
1.19
0.62

68

Mastering Board Games by External and Internal Planning with Language Models

Kingâ€™s Indian
Modern defence
Nimzo-Indian
Old Benoni defence
Old Indian
Ruy Lopez
Sicilian
Nimzo-Indian
French
Kingâ€™s Indian
Sicilian
Nimzo-Indian
Kingâ€™s Indian
French
Budapest
Benoni
Caro-Kann
Alekhineâ€™s defence
Vienna
Sicilian
Sicilian
Benoni defence
QGD Slav
Nimzo-Indian
Sicilian
QGD
Kingâ€™s Indian
Sicilian
Pirc
Kingâ€™s Indian
KGA
Trompovsky attack (Ruth, Opovcensky opening)
Sicilian
Kingâ€™s Indian
St. George (Baker) defence
KP
Dutch
Trompovsky attack (Ruth, Opovcensky opening)
French
Kingâ€™s Indian
Modern defence
Sicilian
Sicilian
Queenâ€™s pawn game
Queenâ€™s Indian accelerated
Sicilian
Kingâ€™s Indian
Caro-Kann
QGA
Philidorâ€™s defence
Caro-Kann
Pirc defence
French
Trompovsky attack (Ruth, Opovcensky opening)
French
Robatsch (modern) defence
Kingâ€™s Indian
Ruy Lopez
Vienna game, Max Lange defence
English
Alekhineâ€™s defence
Kingâ€™s Indian
Caro-Kann
French
Sicilian
Sicilian
Blumenfeld counter-gambit, DusChotimursky variation
Two knights defence
Czech Benoni defence
Kingâ€™s Indian defence, 3.Nc3
Centre game

r1bq1rk1/pp1n1pbp/2pp1np1/4p3/2PPP3/2N1BN2/PP2BPPP/R2Q1RK1 w - - 0 9
rnbqk1nr/ppp3bp/3p4/3Ppp2/2P5/2N5/PP3PPP/R1BQKBNR w KQkq - 0 7
rnbq1rk1/ppp2ppp/3ppn2/8/2PPP3/2P5/P1Q2PPP/R1B1KBNR w KQ - 0 7
rnbqkb1r/pp2pp1p/3p1np1/2pP4/4PP2/2N5/PPP3PP/R1BQKBNR b KQkq - 0 5
rnq1kb1r/pp2pppp/2pp1n2/8/2PP2b1/1QN2N2/PP2PPPP/R1B1KB1R w KQkq - 0 6
r2qr1k1/1b1n1ppp/p2p1b2/1ppP4/2n1P3/5N1P/PPB2PP1/1RBQRNK1 w - - 1 17
rnbqk2r/pp2bpp1/3ppn1p/8/3NP1P1/2N1B3/PPP2P1P/R2QKB1R w KQkq - 0 8
rn1qk2r/p1pp1pp1/bp2pn2/7p/1bPP4/2N1P1N1/PP3PPP/R1BQKB1R w KQkq - 0 7
r3k1nr/pbpq2pp/1pn1p3/3pPp2/P2P4/2P3Q1/2P2PPP/R1B1KBNR w KQkq - 1 10
r1bqr1k1/1pp1ppbp/p1np1np1/6B1/2PPP3/2N2P2/PP1QN1PP/R3KB1R w KQ - 2 9
r1bqk2r/1p1nppbp/p2p1np1/8/3NP3/2N1BP2/PPPQ2PP/R3KB1R w KQkq - 2 9
r1bqk2r/pp1n1ppp/4p3/b1Pp4/3P4/P1N5/1P1QNPPP/R3KB1R w KQkq - 1 11
r1b1qrk1/ppp2pbp/3p1np1/2nPp1B1/2P1P1P1/2N2N1P/PP3P2/R2QKB1R w KQ - 1 10
rnbq1k1r/pp2nppp/4p3/2ppP3/3P2Q1/P1P5/2P2PPP/R1B1KBNR w KQ - 3 8
rnbqkb1r/ppp2ppp/3p4/4P3/2P1P1n1/8/PP3PPP/RNBQKBNR w KQkq - 0 5
rnbqnrk1/pp3pbp/3p2p1/2pP4/4P3/2N5/PP1NBPPP/R1BQK2R w KQ - 3 10
rn1qkb1r/pp2pp1p/2p2p2/5b2/3P4/2P5/PP3PPP/R1BQKBNR w KQkq - 1 7
rnbqkb1r/ppp1pppp/1n1p4/4P3/3P4/5N2/PPP2PPP/RNBQKB1R w KQkq - 2 5
rnbqk2r/pppp1ppp/8/2b1p3/2B1P1n1/P1N2N2/1PPP1PPP/R1BQK2R b KQkq - 4 5
r2q1rk1/1p2bppp/p1bppn2/8/3QP1P1/2N1BP2/PPP4P/2KR1B1R w - - 3 13
r1bq1rk1/pp2bppp/2nppn2/8/3NPP2/2N1BQ2/PPP3PP/R3KB1R w KQ - 3 9
r1bqr1k1/pp1n1pbp/3p1np1/2pP4/4P3/2NB1N1P/PP3PP1/R1BQ1RK1 w - - 5 11
r2qkb1r/pp3ppp/2p1pn2/7b/PnBPP3/2N1BN2/1P3PPP/2RQK2R w Kkq - 4 10
rnbqk2r/p2p1ppp/4pn2/1pp5/1bPP4/2N2NP1/PP2PP1P/R1BQKB1R w KQkq - 0 6
rnbqk2r/3nbppp/p2pp3/1p6/3NP1P1/2N1BP2/PPPQ3P/R3KB1R w KQkq - 1 10
rnbqkbnr/pp4pp/2p1p3/3p4/2PP2Q1/2N1P3/PP3P1P/R1B1KBNR b KQkq - 0 6
r1bq1rk1/1pp2pbp/p1np1np1/4p3/2PPP3/2N1BP2/PP1QN1PP/R3KB1R w KQ - 0 9
r1b1k1nr/pp1pppbp/1qn3p1/1Bp5/4P3/2P2N2/PP1P1PPP/RNBQ1RK1 w kq - 1 6
rnbq1rk1/ppp1ppbp/3p1np1/7P/3PP3/2N5/PPP1BPP1/R1BQK1NR b KQ - 0 6
rnbq1rk1/pp4bp/3ppnp1/2p5/2P1PPP1/2N5/PP2B2P/R1BQK1NR b KQ - 0 9
rnbqkbnr/pppp2pp/8/4Pp2/2B2p2/8/PPPP2PP/RNBQK1NR b KQkq - 0 4
rnbqkb1r/pppppp1p/8/6p1/3PnB2/8/PPP1PPPP/RN1QKBNR w KQkq - 0 4

1.09
0.76
0.92
0.71
1.07
0.85
1.15
0.89
1.00
0.81
1.14
0.71
1.13
0.79
1.06
1.02
0.91
0.92
-0.89
0.78
1.06
0.93
1.02
0.91
0.92
0.89
0.93
1.07
0.77
-1.05
-0.95
0.82

rnbqk2r/1p2bppp/p2ppn2/8/3NP3/2N1BQ2/PPP2PPP/2KR1B1R b kq - 1 8
1rbqr1k1/ppp1ppbp/2np1np1/6B1/2PPP3/2N2P2/PP1QN1PP/R3KB1R w KQ - 7 9
rn1qkbnr/1bpppppp/p7/1p6/3PP3/3B1N2/PPP2PPP/RNBQK2R b KQkq - 3 4
r1bqkbnr/pppppppp/2n5/8/1P2P3/8/P1PP1PPP/RNBQKBNR b KQkq - 0 2
rnbqk2r/ppp1p1b1/3p1npp/5p2/3P1B1P/2N1PQ2/PPP2PP1/R3KBNR w KQkq - 2 7
rnbqkb1r/pp1p1pp1/4pn1p/8/3pP2B/8/PPPN1PPP/R2QKBNR w KQkq - 0 6

0.94
0.82
0.85
-0.62
1.07
0.74

rnb1kbnr/pppq1ppp/4p3/3pP3/3P2Q1/2N5/PPP2PPP/R1B1KBNR w KQkq - 3 6
rnbq1rk1/ppp1ppb1/3p1npp/6B1/2PPP3/2N4P/PP3PP1/R2QKBNR w KQ - 0 7
rnbqk2r/ppp1npbp/3p2p1/3Pp3/2P1P3/2N5/PP3PPP/R1BQKBNR w KQkq - 1 6
rnbqkbnr/p2ppppp/1p6/2p5/4P3/2N5/PPPP1PPP/R1BQKBNR w KQkq - 0 3
3q1rk1/pp1bppbp/3p1np1/8/2rNP2P/2N1BP2/PPPQ2P1/2KR3R w - - 0 14
r2qkb1r/pppnpppp/3p1n2/5b2/3P4/2N2NP1/PPP1PP1P/R1BQKB1R w KQkq - 1 5
rn1qkb1r/pbpppp1p/1p3np1/8/2PP4/2N5/PPQ1PPPP/R1B1KBNR w KQkq - 0 5
r1bqk1nr/pp1pp1bp/6p1/5p2/2BpP3/2N2Q2/PPPP1PPP/R1B1K2R w KQkq - 0 8
rnbqk2r/ppp3bp/3p2p1/3Pp2n/2P1Pp2/2N2P2/PP1Q1BPP/R3KBNR b KQkq - 1 9
rnbqkbnr/pp2pppp/2p5/7Q/4p3/1B6/PPPP1PPP/RNB1K1NR b KQkq - 1 4
r2qkb1r/ppp1pppp/1nn5/3bP3/3P4/2NBB3/PP3PPP/R2QK1NR w KQkq - 7 9
rn1qkbnr/ppp2ppp/3p4/4p3/2B1P1b1/5N2/PPPP1PPP/RNBQK2R w KQkq - 2 4
rnbqkb1r/pp2pp2/2p2p2/7p/2BP4/8/PPP2PPP/R1BQK1NR w KQkq - 0 7
r1bqkb1r/pppnpp1p/3p1np1/8/3PP1P1/2N5/PPP2P1P/R1BQKBNR w KQkq - 0 5
r1bqkb1r/ppp1nppp/2n1p3/3pP3/3P3P/2N5/PPP2PP1/R1BQKBNR b KQkq - 0 5
rnb1kb1r/pp1ppppp/1q6/2pP4/7P/8/PPPBPPP1/R2QKBNR b KQkq - 0 6

0.95
0.77
1.07
0.76
0.92
0.83
0.99
0.71
0.92
-0.90
0.99
0.90
1.03
0.88
0.84
0.99

rnbqk1nr/pp3ppp/4p3/b2pP3/1p1P4/P1N5/2P2PPP/R1BQKBNR w KQkq - 0 7
r1bqk2r/1ppnnpbp/p2pp1p1/8/3PP3/2PB1N2/PP3PPP/RNBQR1K1 w kq - 2 8
rnbq1rk1/pp3pbp/3ppnp1/2pP4/2P1P1PP/2N5/PP2BP2/R1BQK1NR b KQ - 0 8
r1bq1rk1/2p2ppp/pn1p1b2/np2p3/3PP3/1BP2N1P/PP3PP1/R1BQRNK1 w - - 5 13
r1bqkbnr/pppp2pp/2n5/4pp2/2B1P3/2N5/PPPP1PPP/R1BQK1NR w KQkq - 0 4
r1bqkbnr/ppp3pp/3p4/3Pnp2/2P1p3/2N2NP1/PP2PP1P/R1BQKB1R w KQkq - 1 7
rnbqkb1r/ppp1pp1p/1n1p2p1/4P3/2PP1P2/8/PP4PP/RNBQKBNR w KQkq - 0 6
r1bq1rk1/ppp1n1b1/3p1npp/P2Ppp2/1PP1P3/2N2N2/4BPPP/R1BQR1K1 w - - 0 13
r2qkb1r/pp1nnppp/2p1p1b1/3pP3/P2P4/5N2/1PP1BPPP/RNBQ1RK1 w kq - 1 8
rnbqk2r/ppp1bppp/4pn2/8/8/1PN5/PBPPQPPP/R3KBNR w KQkq - 3 7
rn1qkb1r/pp1b1ppp/3p1n2/4p3/3QP3/1PN5/PBP2PPP/R3KBNR w KQkq - 0 7
r1bqkb1r/pp1ppppp/2n5/2p1P3/8/2P2N2/PPP2PPP/R1BQKB1R w KQkq - 1 6
rnb1kb1r/p2p1ppp/4pn2/qppP2B1/2P5/5N2/PP2PPPP/RN1QKB1R w KQkq - 2 6

1.04
0.96
-0.82
1.00
0.95
1.05
0.88
1.01
1.05
1.05
1.06
1.12
0.91

r1bqkb1r/p4pp1/2p4p/n2np3/4N3/3B4/PPPP1PPP/RNBQK2R w KQkq - 2 10
r1bq1rk1/pp1nbppp/3p1n2/2pPp3/2P1P3/2N2NP1/PP3PBP/R1BQK2R b KQ - 2 8
rnbq1rk1/pp3pb1/3p1npp/2pPp3/2P4B/2N5/PP1NPPPP/R2QKB1R w KQ e6 0 9
r1bqk2r/ppppnpbp/2n3p1/8/4P3/2N1Q3/PPPB1PPP/R3KBNR w KQkq - 4 7

0.89
0.97
1.22
0.93

69

Mastering Board Games by External and Internal Planning with Language Models

Sicilian
KGA
Kingâ€™s Indian
Pirc
English opening
Dutch defence
French
Sicilian
Kingâ€™s Indian
Budapest
Blackmar gambit
KP
Kingâ€™s Indian
Ruy Lopez
Scandinavian (centre counter) defence
Kingâ€™s Indian defence
French
Giuoco Piano
Queenâ€™s Indian
Kingâ€™s Indian
French
Sicilian
Sicilian
Czech Benoni defence
Ruy Lopez
Dutch
QGA, Smyslov variation
English
Pirc defence
Kingâ€™s Indian
French
Sicilian
Sicilian
Queenâ€™s pawn
KGA
Benoni defence
Gruenfeld defence
Sicilian
Caro-Kann
Kingâ€™s Indian
Dutch, 2.Bg5 variation
Sicilian
Benkoâ€™s opening
Ruy Lopez
Kingâ€™s Indian
Gruenfeld
Giuoco Piano
QGD semi-Slav
Bogo-Indian defence
Queenâ€™s Indian
Kingâ€™s Indian
Vienna
Ruy Lopez
QGA
English opening
French
Sicilian
French
Philidorâ€™s defence
Scandinavian (centre counter) defence
Sicilian
Sicilian
French
QGD semi-Slav
Ruy Lopez
Ponziani
Old Indian defence
Sicilian
QGD semi-Slav
Scandinavian (centre counter) defence
QGD
KGA

r2qkb1r/1b1n1pp1/p2ppn1p/1p6/3NP1P1/2N1BP2/PPPQ3P/2KR1B1R w kq - 2 11
rnbqkbnr/pppp1ppp/8/8/4Pp2/5Q2/PPPP2PP/RNB1KBNR b KQkq - 1 3
r1bq1rk1/ppn1ppbp/3p1np1/2pP2B1/2P1P3/2N5/PP1QBPPP/R3K1NR w KQ - 1 9
rnbq1rk1/p1p1ppbp/1p1p1np1/8/3PPP2/2N2N2/PPPB2PP/R2QKB1R w KQ - 0 7
rnbqkb1r/ppp2pp1/3p1n2/7p/2P1p2N/2N3P1/PP1PPP1P/R1BQKB1R w KQkq - 2 6
rnbqk2r/ppppp1bp/6pn/5p2/2PP4/2N3P1/PP2PP1P/R1BQKBNR w KQkq - 1 5
rnbqkb1r/pp1n1p1p/4p1p1/2ppP3/3P1P2/2P5/PP1N2PP/R1BQKBNR w KQkq - 0 7
r1bqkb1r/pp1npppp/3p1n2/8/3NP3/2N5/PPP2PPP/R1BQKB1R w KQkq - 3 6
r1bq1rk1/ppp2pbp/n2p1np1/3Pp3/2P1P2P/2N5/PP2BPP1/R1BQK1NR w KQ - 1 8
r1b1k2r/pppp1ppp/2n5/3QP3/2P2Bn1/q1P2N2/P3PPPP/R3KB1R w KQkq - 3 9
rn1qkb1r/pp3ppp/2p1pn2/4Nb2/2BP4/2N5/PPP3PP/R1BQK2R w KQkq - 0 8
r1bqkb1r/pppppppp/2n2n2/8/4P3/2N5/PPPP1PPP/R1BQKBNR w KQkq - 3 3
rn1q1rk1/1ppn1pbp/3p2p1/p2Pp3/2P1P1b1/2N1BN2/PP1QBPPP/R3K2R w KQ - 0 10
r1b2rk1/2q1bppp/p2p1n2/np1Pp3/4P3/5N1P/PPBN1PP1/R1BQR1K1 w - - 1 15
rn2kb1r/pp2pppp/2p2n2/q7/2BP2b1/2N2N1P/PPP2PP1/R1BQK2R b KQkq - 0 7

0.98
-1.06
1.05
1.17
1.00
0.92
1.00
0.88
1.13
0.91
-0.78
0.75
1.22
1.00
0.98

rnbqk2r/p2pppbp/5np1/1PpP4/7P/8/PP2PPP1/RNBQKBNR w KQkq - 1 6
rnbqk2r/pp1n1ppp/4p3/2ppP3/1b1P4/2NQ4/PPP1NPPP/R1B1KB1R w KQkq - 0 7
r1bqk1nr/pppp1pp1/2n4p/2b1p3/2BPP3/5N2/PPP2PPP/RNBQ1RK1 b kq - 0 5
r2qkb1r/p1pp1ppp/bpn1pn2/8/2PP4/PQ3N2/1P2PPPP/RNB1KB1R w KQkq - 3 6
r1bqnrk1/pp1n1pbp/2pp2p1/4p3/2PPP3/2N2NPP/PP3PB1/R1BQ1RK1 w - - 1 10
rnbqkb1r/p1p1nppp/1p2p3/3pP3/3P4/5N2/PPP2PPP/RNBQKB1R w KQkq - 2 5
r1bqkb1r/pp1p1ppp/2n1pn2/1Bp5/4P3/2N2N2/PPPP1PPP/R1BQK2R w KQkq - 0 5
rnb1kb1r/1pq2ppp/p2ppn2/8/2PNP3/2N5/PP2BPPP/R1BQK2R w KQkq - 2 8
r1bq1rk1/1p1nbppp/p2p1n2/2pPp3/2P1P3/2N2N2/PP2BPPP/R1BQ1RK1 w - - 0 9
r3r1k1/2qbbppp/p2p1n2/nppPp3/4P3/2P2N1P/PPBN1PP1/R1BQR1K1 w - - 1 14
rnbq1rk1/1pp1b1pp/3ppn2/p4p2/1PPP4/5NP1/P3PPBP/RNBQ1RK1 w - - 0 8
r1bq1rk1/ppp1ppbp/2n2np1/8/2BP4/2N1PN2/PP3PPP/R1BQ1RK1 w - - 5 8
r2q1rk1/2pn1ppp/1p1ppn2/p5B1/2PP4/P1QBP3/1P1N1PbP/R3K2R w KQ - 0 12
r1bqk2r/ppp1ppbp/2np1np1/8/3PP3/2N1B3/PPPQ1PPP/R3KBNR w KQkq - 4 6
r1bq1rk1/ppp1npbp/3p2p1/3Pp3/2P1Pn2/2N2N2/PP1BBPPP/R2QR1K1 w - - 5 11
rnbqkbnr/p1p2ppp/1p2p3/3pP3/3P4/P1N5/1PP2PPP/R1BQKBNR w KQkq - 1 6
r1bqkbnr/4nppp/p2p4/1p1Np3/4P3/N7/PPP2PPP/R1BQKB1R w KQkq - 2 9
r1bq1rk1/1p2bppp/p2ppn2/n7/3NP3/1BN1B3/PPP1QPPP/2KR3R w - - 2 11
r1bqkb1r/pp2pppp/2n2n2/2pp4/3P1P2/2PBP3/PP4PP/RNBQK1NR b KQkq - 0 5
rnbqkbnr/ppp2ppp/8/3N4/4Pp2/8/PPPP2PP/R1BQKBNR b KQkq - 0 4
rnb1kb1r/1p2qp1p/p2p1np1/2pP4/P7/2N2N1P/1P2PPP1/R1BQKB1R w KQkq - 1 9
rnbqk2r/ppp1ppbp/5np1/3P4/3P4/2N5/PP2PPP1/R1BQKBNR w KQkq - 1 7
r1b1kb1r/pp3ppp/1qnppn2/8/4P3/1NN3P1/PPP2P1P/R1BQKB1R w KQkq - 0 8
rn1qkb1r/pp2pppp/2p5/3pPb2/4n3/5N2/PPPPNPPP/R1BQKB1R w KQkq - 3 6
r1bq1rk1/1pp1ppbp/2np1np1/p7/2PPP3/2N1BP2/PP2N1PP/R2QKB1R w KQ - 0 8
rnbqkbnr/pp1pp2p/2p3p1/5pB1/3P4/2N5/PPP1PPPP/R2QKBNR w KQkq - 0 4
rnb1kb1r/ppq1pppp/3p1n2/8/3NP3/2N5/PPP2PPP/R1BQKB1R w KQkq - 3 6
rnbqk1nr/pp1pp1bp/6p1/2pP1p2/8/6P1/PPP1PPBP/RNBQK1NR w KQkq - 0 5
r1bq1rk1/4bppp/p1pp1n2/np2p3/4P3/2P2N1P/PPBP1PP1/RNBQR1K1 w - - 0 11
r1bqn1k1/ppp1n1bp/3p1r2/2PPp1p1/4Pp2/2N2P2/PP2BBPP/R2QNRK1 w - - 1 14
rnbqkb1r/ppp1pp1p/1n4p1/8/3PP3/2N5/PP3PPP/R1BQKBNR w KQkq - 1 6
r1b1k1nr/ppppqppp/2n5/2b1p3/2B1P3/2P2N2/PP1P1PPP/RNBQK2R w KQkq - 1 5
rnbqk2r/p4ppp/2p1pn2/1p4B1/PbpPP3/2N2N2/1P3PPP/R2QKB1R w KQkq - 1 8
r1bq1rk1/1pp1nppp/4pn2/p2p4/2PP4/P2BPN2/1PQN1PPP/R3K2R w KQ - 1 10
rn1q1rk1/p1ppb1pp/1p2p3/5p2/2PP1B1P/3QPN2/PP3PP1/R4K1R w - - 0 13
rnb2rk1/pp3pbp/2pp1np1/q3p1B1/2PPP3/2N2P2/PP1QN1PP/R3KB1R w KQ - 2 9
b1kr1bnr/p1ppqp1p/Ppn5/1N4p1/3PPp2/5N2/1PP2KPP/R1BQ1B1R w - - 1 12
1rbn1rk1/2q1bppp/3p1n2/1p1Pp3/1Pp1P3/2P2N1P/2BN1PP1/R1BQR1K1 w - - 0 17
r1b2rk1/pp1nppbp/2p2np1/7q/2QPP3/2N2NP1/PP3PBP/R1B2RK1 w - - 1 11
rnbqk1nr/ppp3bp/3p4/4pp2/2P5/2N3P1/PP1P1PBP/R1BQK1NR w KQkq - 0 7
rnbqkb1r/1ppn1ppp/p3p3/3pP3/3P4/5N2/PPPN1PPP/R1BQKB1R w KQkq - 1 6
r1b2rk1/pp2bppp/2nppn2/q7/3NP3/1BN1B3/PPP1QPPP/R3K2R w KQ - 6 10
rnbqk2r/pp3ppp/4p3/2ppPn2/3P2Q1/P1P5/2P2PPP/R1B1KBNR w KQkq - 3 8
rn1qkbnr/ppp2ppp/3p4/4p3/3PP1b1/5N2/PPP2PPP/RNBQKB1R w KQkq - 1 4
r1bqkbnr/pp2pppp/2n5/8/8/8/PPPP1PPP/RNBQKBNR w KQkq - 0 4

1.00
1.15
0.95
0.97
0.96
1.06
1.05
1.03
1.29
1.01
0.93
0.90
0.95
0.99
0.90
0.96
0.89
0.88
-0.88
-1.15
1.06
1.10
0.97
1.15
0.78
1.02
1.03
1.14
0.92
0.99
1.22
1.03
0.79
1.27
1.03
1.16
-0.57
1.05
0.88
1.06
1.00
1.08
1.02
1.23
0.89

r1bqk2r/1p1nbppp/p1npp3/6P1/3NP2P/2N1B3/PPP1QP2/R3KB1R b KQkq - 1 10
r1b1kb1r/pp3ppp/2nP4/q1p1p3/1nP1N3/PQ3N2/1P1P1PPP/R1B1KB1R w KQkq - 0 10
r1b1k2r/pp1nbppp/1qn1p3/3pP3/3P4/3B1N2/PP2NPPP/R1BQ1K1R w kq - 3 11
r1bqkb1r/1p1n1ppp/2p1pn2/p1Pp4/1P1P4/2N1PN2/P4PPP/R1BQKB1R w KQkq - 0 8
r2q1rk1/2p1bppp/p1n5/1pnpP3/6b1/2P2N2/PPBN1PPP/R1BQR1K1 w - - 7 13
r1b1kb1r/ppp2ppp/2n2n2/8/3P4/2P1PB1q/PP1N3P/RNBQK2R w KQkq - 2 10
r2qkb1r/pppnpppp/3p1n2/5b2/2PP4/1Q3N2/PP2PPPP/RNB1KB1R w KQkq - 4 5
5rk1/pp1bppbp/3p1np1/q7/2r1P1P1/2N1BP2/PPPQN3/2KR3R w - - 3 17
r1b1kb1r/5ppp/pqp1pn2/3p4/Q2P4/4PN2/PP1B1PPP/R3KB1R w KQkq - 1 11
r1b1kb1r/ppp1pppp/2n2n2/q7/3P4/2N2N2/PPP2PPP/R1BQKB1R w KQkq - 3 6

0.89
1.09
0.85
0.96
0.97
-0.75
0.95
0.86
1.10
1.18

r2q1rk1/pb1nbppp/1p3n2/3p2B1/3p3P/2NBPN2/PPQ2PP1/2KR3R w - - 0 12
rn2kbnr/ppp2ppp/3pb3/8/2B1Pp1q/2N5/PPPPQ1PP/R1B2KNR b kq - 3 6

1.03
-0.76

70

Mastering Board Games by External and Internal Planning with Language Models

QGD
Robatsch (modern) defence
Kingâ€™s Indian
Kingâ€™s Indian
Nimzo-Indian
Ruy Lopez
Ruy Lopez
QGD
QGD
Sicilian, Szen (â€˜anti-Taimanovâ€™)
variation
Kingâ€™s Indian
Pirc
Dutch-Indian, Alekhine variation
Old Indian
Sicilian
Ruy Lopez
Queenâ€™s Indian
Kingâ€™s Indian
Kingâ€™s Indian
Czech Benoni defence
English
Benoni
QGA
Sicilian
French
Queenâ€™s pawn game
Caro-Kann

r1bqrnk1/p4ppp/2pb1n2/1p1p2N1/3P3P/2NBP3/PPQB1PP1/2KR3R b - - 1 12
rn1qk1nr/1bp2pb1/3pp1pp/p7/Pp1PP2P/4BP2/1PPQN1P1/2KR1BNR w kq - 0 11
r1b2rk1/pp1nqpbp/2pp2p1/4p2n/2PPP3/2N1BNPP/PP3PB1/R2Q1RK1 w - - 3 11
r1bq1rk1/ppp2pbp/2np1np1/4p3/2PPP3/2N1BP2/PP2N1PP/R2QKB1R w KQ - 0 8
rnbqk2r/pp3ppp/4p3/2pp4/1bPPn3/2N1PN2/PPQ2PPP/R1B1KB1R w KQkq - 0 7
r1b1k2r/2q1bppp/p1np1n2/1pp1p3/3PP3/2P2N2/PPBN1PPP/R1BQR1K1 w kq - 3 12
r1bqkb1r/pp3ppp/2p3n1/8/3pP3/1B6/PPP2PPP/RNBQ1RK1 w kq - 1 10
r1b1k1nr/pp1n2pp/2pbp2q/3p1p2/2PP4/2N1P3/PP2BPPP/R1BQNRK1 w kq - 6 9
r1bq1rk1/pp2bppp/2n3n1/4P3/2Pp4/3B1N2/PP1N1PPP/R1BQR1K1 w - - 8 11
r2qkb1r/1p3p1p/p2pbp2/4p3/3nP3/N1N5/PPP2PPP/R2QKB1R w KQkq - 2 12

-0.99
0.99
1.20
1.12
1.17
1.02
0.84
1.19
1.10
-0.90

r1bq1rk1/pppnppbp/3p1np1/8/2PPPP2/2N2N2/PP4PP/R1BQKB1R w KQ - 3 7
rnbq1rk1/pp2ppbp/2pp1np1/8/3PPP2/2N2N2/PPP1B1PP/R1BQK2R w KQ - 0 7
rn1q1rk1/pbppb1pp/1p2p3/5p2/2PPn3/2N2NP1/PPQBPPBP/R4RK1 w - - 2 10
r1b2rk1/ppqnbppp/2pp1n2/4p3/2PPP3/2NB1N1P/PP3PP1/R1BQ1RK1 w - - 1 9
r1bq1rk1/ppn3bp/2np2p1/4ppP1/4PP1P/2N1B3/PPP1N3/R2QKB1R w KQ f6 0 13
r3k2r/1bpq1pp1/pbnp1n1p/1p2p3/3PP2B/1BP2N2/PP3PPP/RN1QR1K1 w kq - 2 12
r2qkb1r/2pp1ppp/ppn1p1b1/8/2PP4/P3P1P1/1P1N1P1P/R1BQKB1R w KQkq - 0 10
r1b1qrk1/1ppn1pbn/p2p2pp/3Pp3/2P1P2B/2N5/PP1NBPPP/R2Q1RK1 w - - 4 12
rnbq1rk1/pp1p1pbp/5np1/2pPp3/2P5/2N3P1/PP2PPBP/R1BQK1NR w KQ e6 0 7
r1bqnrk1/pp1nbppp/3p4/2pPp3/2P1P3/P1N2N2/1P2BPPP/R1BQ1RK1 b - - 0 9
rnbqk2r/ppn1ppbp/6p1/2p5/3PP3/5NP1/PP3PBP/RNBQK2R w KQkq - 1 8
r1bqr1k1/pp1n1pbp/3p4/2pP3p/4P3/2N5/PPQN1PPP/R1B2RK1 w - - 0 13
1n1qkbnr/rpp2ppp/p3p3/7b/2BP4/1Q2PN1P/PP3PP1/RNB1K2R w KQk - 3 8
r1b1k2r/1p1pnppp/p1n3q1/4p3/4P3/2N5/PPP2PPP/R1BQKB1R w KQkq - 5 10
r1b1k1r1/pp2np1Q/4p3/2qpn3/8/P1P5/2PBBPPP/R3K1NR w KQq - 0 13
r2qkb1r/pppn1ppp/3p1p2/8/3PP1b1/5N2/PPPN1PPP/R2QKB1R w KQkq - 1 7
r1b2rk1/pp2bppp/2nqpn2/8/3P4/P1NB1N2/1P3PPP/R1BQR1K1 w - - 1 12

0.98
1.06
1.14
1.09
-1.06
1.17
1.16
0.98
1.11
0.98
1.13
1.11
1.04
1.05
1.05
0.91
1.10

71

